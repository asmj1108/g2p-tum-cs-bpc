{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSVOj__GHUUu",
    "outputId": "b4134e14-424c-4415-c738-d3e3aec8a8b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
      "üì¶ Installing...\n",
      "üìå Adjusting configuration...\n",
      "ü©π Patching environment...\n",
      "‚è≤ Done in 0:00:12\n",
      "üîÅ Restarting kernel...\n"
     ]
    }
   ],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRR6Og1K0h7P"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6f4h3J_1Cyt"
   },
   "source": [
    "## Reproduce the basline model from 2021 for Romanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "x8jAWjdjHzIo",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cc9aa248-67e6-4492-c1f1-d6a05c1f3d2d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
      "Solving environment: | \b\b/ \b\bdone\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.11.2\n",
      "    latest version: 25.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/envs/2021-task\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.7\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.4.26  |       hbd8a1cb_0         149 KB  conda-forge\n",
      "    ld_impl_linux-64-2.43      |       h712a8e2_4         656 KB  conda-forge\n",
      "    libffi-3.4.6               |       h2dba641_1          56 KB  conda-forge\n",
      "    libgcc-15.1.0              |       h767d61c_2         810 KB  conda-forge\n",
      "    libgcc-ng-15.1.0           |       h69a702a_2          34 KB  conda-forge\n",
      "    libgomp-15.1.0             |       h767d61c_2         442 KB  conda-forge\n",
      "    liblzma-5.8.1              |       hb9d3cd8_1         110 KB  conda-forge\n",
      "    liblzma-devel-5.8.1        |       hb9d3cd8_1         431 KB  conda-forge\n",
      "    libsqlite-3.49.2           |       hee588c1_0         895 KB  conda-forge\n",
      "    libstdcxx-15.1.0           |       h8f9b012_2         3.7 MB  conda-forge\n",
      "    libstdcxx-ng-15.1.0        |       h4852527_2          34 KB  conda-forge\n",
      "    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n",
      "    openssl-3.5.0              |       h7b32b05_1         3.0 MB  conda-forge\n",
      "    pip-24.0                   |     pyhd8ed1ab_0         1.3 MB  conda-forge\n",
      "    python-3.7.12              |hf930737_100_cpython        57.3 MB  conda-forge\n",
      "    readline-8.2               |       h8c095d6_2         276 KB  conda-forge\n",
      "    setuptools-69.0.3          |     pyhd8ed1ab_0         460 KB  conda-forge\n",
      "    sqlite-3.49.2              |       h9eae976_0         840 KB  conda-forge\n",
      "    wheel-0.42.0               |     pyhd8ed1ab_0          56 KB  conda-forge\n",
      "    xz-5.8.1                   |       hbcc6ac9_1          23 KB  conda-forge\n",
      "    xz-gpl-tools-5.8.1         |       hbcc6ac9_1          33 KB  conda-forge\n",
      "    xz-tools-5.8.1             |       hb9d3cd8_1          94 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        71.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
      "  ca-certificates    conda-forge/noarch::ca-certificates-2025.4.26-hbd8a1cb_0 \n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_4 \n",
      "  libffi             conda-forge/linux-64::libffi-3.4.6-h2dba641_1 \n",
      "  libgcc             conda-forge/linux-64::libgcc-15.1.0-h767d61c_2 \n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.1.0-h69a702a_2 \n",
      "  libgomp            conda-forge/linux-64::libgomp-15.1.0-h767d61c_2 \n",
      "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_1 \n",
      "  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.8.1-hb9d3cd8_1 \n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.49.2-hee588c1_0 \n",
      "  libstdcxx          conda-forge/linux-64::libstdcxx-15.1.0-h8f9b012_2 \n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-15.1.0-h4852527_2 \n",
      "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
      "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
      "  openssl            conda-forge/linux-64::openssl-3.5.0-h7b32b05_1 \n",
      "  pip                conda-forge/noarch::pip-24.0-pyhd8ed1ab_0 \n",
      "  python             conda-forge/linux-64::python-3.7.12-hf930737_100_cpython \n",
      "  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2 \n",
      "  setuptools         conda-forge/noarch::setuptools-69.0.3-pyhd8ed1ab_0 \n",
      "  sqlite             conda-forge/linux-64::sqlite-3.49.2-h9eae976_0 \n",
      "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
      "  wheel              conda-forge/noarch::wheel-0.42.0-pyhd8ed1ab_0 \n",
      "  xz                 conda-forge/linux-64::xz-5.8.1-hbcc6ac9_1 \n",
      "  xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.8.1-hbcc6ac9_1 \n",
      "  xz-tools           conda-forge/linux-64::xz-tools-5.8.1-hb9d3cd8_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "python-3.7.12        | 57.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
      "libstdcxx-15.1.0     | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "openssl-3.5.0        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pip-24.0             | 1.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.49.2     | 895 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.5          | 871 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.49.2        | 840 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-15.1.0        | 810 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.4 | 656 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.0.3    | 460 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-15.1.0       | 442 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-devel-5.8.1  | 431 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 276 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-5.8.1        | 110 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-tools-5.8.1       | 94 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.42.0         | 56 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.6         | 56 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-15.1.0  | 34 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libstdcxx-15.1.0     | 3.7 MB    | :   0% 0.004198490398746398/1 [00:00<00:26, 26.98s/it]\u001b[A\n",
      "\n",
      "openssl-3.5.0        | 3.0 MB    | :   1% 0.005255644910358278/1 [00:00<00:26, 26.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :   0% 0.00027256019984598284/1 [00:00<09:48, 589.10s/it]\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.49.2     | 895 KB    | :   2% 0.017880353110782014/1 [00:00<00:09,  9.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libstdcxx-15.1.0     | 3.7 MB    | :  79% 0.7851177045655764/1 [00:00<00:00,  4.37it/s]  \u001b[A\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :   2% 0.01989689458875675/1 [00:00<00:10, 10.96s/it]    \n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.49.2     | 895 KB    | :  38% 0.3754874153264223/1 [00:00<00:00,  1.68it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pip-24.0             | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.87it/s]                 \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :   6% 0.063506526564114/1 [00:00<00:04,  4.39s/it]  \n",
      "libstdcxx-15.1.0     | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  4.37it/s]               \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.49.2     | 895 KB    | : 100% 1.0/1 [00:00<00:00,  3.35it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.49.2     | 895 KB    | : 100% 1.0/1 [00:00<00:00,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.5.0        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.18it/s]               \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.5          | 871 KB    | :   2% 0.018375108367605347/1 [00:00<00:21, 21.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.49.2        | 840 KB    | :   2% 0.019049789433785005/1 [00:00<00:21, 21.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :  12% 0.12019904813207843/1 [00:00<00:02,  2.85s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.4 | 656 KB    | :   2% 0.02440855729694297/1 [00:00<00:18, 18.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.49.2        | 840 KB    | : 100% 1.0/1 [00:00<00:00, 21.96s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:00<00:00, 21.61s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.4 | 656 KB    | : 100% 1.0/1 [00:00<00:00, 18.64s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.0.3    | 460 KB    | :   3% 0.034818977022535426/1 [00:00<00:14, 14.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:00<00:00, 22.03s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :  17% 0.17443852790142902/1 [00:00<00:01,  2.41s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-15.1.0       | 442 KB    | :   4% 0.03619693572083467/1 [00:00<00:14, 15.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-devel-5.8.1  | 431 KB    | :   4% 0.03710212141524303/1 [00:00<00:14, 15.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:00<00:00, 15.29s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-devel-5.8.1  | 431 KB    | : 100% 1.0/1 [00:00<00:00, 15.28s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 276 KB    | :   6% 0.05800056641178136/1 [00:00<00:09, 10.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    | :  11% 0.10758915965669182/1 [00:00<00:04,  5.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    | : 100% 1.0/1 [00:00<00:00,  5.50s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:00<00:00, 10.08s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :  23% 0.22976824847016356/1 [00:00<00:01,  2.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:00<00:00,  3.72s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-5.8.1        | 110 KB    | :  15% 0.1451903052860118/1 [00:00<00:03,  4.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:00<00:00,  4.47s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.6         | 56 KB     | :  29% 0.2852715337871955/1 [00:00<00:01,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.42.0         | 56 KB     | :  28% 0.284676732750682/1 [00:00<00:01,  2.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:00<00:00,  2.33s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.42.0         | 56 KB     | : 100% 1.0/1 [00:00<00:00,  2.34s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-15.1.0  | 34 KB     | :  47% 0.47288365515051806/1 [00:00<00:00,  1.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-15.1.0  | 34 KB     | : 100% 1.0/1 [00:00<00:00,  1.44s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :  39% 0.38594524298191174/1 [00:00<00:00,  1.55s/it]\n",
      "python-3.7.12        | 57.3 MB   | :  49% 0.48870043832384724/1 [00:00<00:00,  1.32s/it]\n",
      "\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :  81% 0.811684275141337/1 [00:01<00:00,  1.27s/it] \n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :  90% 0.8986309788922054/1 [00:01<00:00,  1.25s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.49.2        | 840 KB    | : 100% 1.0/1 [00:01<00:00,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.49.2        | 840 KB    | : 100% 1.0/1 [00:01<00:00,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | :  99% 0.9902112060404558/1 [00:01<00:00,  1.22s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.4 | 656 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.4 | 656 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:01<00:00,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:01<00:00,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.0.3    | 460 KB    | : 100% 1.0/1 [00:02<00:00,  1.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.0.3    | 460 KB    | : 100% 1.0/1 [00:02<00:00,  1.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:02<00:00,  2.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:02<00:00,  2.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-devel-5.8.1  | 431 KB    | : 100% 1.0/1 [00:02<00:00,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-devel-5.8.1  | 431 KB    | : 100% 1.0/1 [00:02<00:00,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    | : 100% 1.0/1 [00:02<00:00,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | : 100% 1.0/1 [00:02<00:00,  1.22s/it]               \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:02<00:00,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:02<00:00,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:02<00:00,  2.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:02<00:00,  2.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:02<00:00,  2.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:02<00:00,  2.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:02<00:00,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:02<00:00,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.42.0         | 56 KB     | : 100% 1.0/1 [00:02<00:00,  2.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.42.0         | 56 KB     | : 100% 1.0/1 [00:02<00:00,  2.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-15.1.0  | 34 KB     | : 100% 1.0/1 [00:02<00:00,  2.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-15.1.0  | 34 KB     | : 100% 1.0/1 [00:02<00:00,  2.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:03<00:00,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.7.12        | 57.3 MB   | : 100% 1.0/1 [00:15<00:00,  1.22s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \n",
      "                                                                        \u001b[A\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Preparing transaction: - \b\b\\ \b\bdone\n",
      "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate 2021-task\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Cloning into '2021-task1'...\n",
      "remote: Enumerating objects: 301, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 301 (delta 0), reused 0 (delta 0), pack-reused 294 (from 1)\u001b[K\n",
      "Receiving objects: 100% (301/301), 1.38 MiB | 11.36 MiB/s, done.\n",
      "Resolving deltas: 100% (80/80), done.\n"
     ]
    }
   ],
   "source": [
    "!conda create --name 2021-task python=3.7\n",
    "!git clone https://github.com/sigmorphon/2021-task1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3H91zSaINA2",
    "outputId": "4e745fa2-8181-4c16-9084-16b25b7f86a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython==0.29 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (0.29)\n",
      "Requirement already satisfied: dyNET==2.1 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (2.1)\n",
      "Requirement already satisfied: editdistance==0.5.2 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (0.5.2)\n",
      "Requirement already satisfied: numpy==1.15.4 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.15.4)\n",
      "Requirement already satisfied: progressbar==2.5 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (2.5)\n",
      "Requirement already satisfied: scipy==1.5.4 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (1.5.4)\n",
      "Processing /content/2021-task1/baseline\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: dyNET==2.1 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from neural_transducer==0.2) (2.1)\n",
      "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from neural_transducer==0.2) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from neural_transducer==0.2) (1.15.4)\n",
      "Requirement already satisfied: progressbar>=2.5 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from neural_transducer==0.2) (2.5)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /usr/local/envs/2021-task/lib/python3.7/site-packages (from neural_transducer==0.2) (1.5.4)\n",
      "Requirement already satisfied: cython in /usr/local/envs/2021-task/lib/python3.7/site-packages (from dyNET==2.1->neural_transducer==0.2) (0.29)\n",
      "Building wheels for collected packages: neural_transducer\n",
      "  Building wheel for neural_transducer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for neural_transducer: filename=neural_transducer-0.2-py3-none-any.whl size=30393 sha256=61c514de7dc8e9ed829bf53e619917e57f7b71e1cb4d27d22194a97efe4ff739\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ag5rm5ea/wheels/f7/0a/6d/cb8ad4e5613af293846ed75ad5efe9f4b9dfa6dbb302f00d4f\n",
      "Successfully built neural_transducer\n",
      "Installing collected packages: neural_transducer\n",
      "  Attempting uninstall: neural_transducer\n",
      "    Found existing installation: neural_transducer 0.2\n",
      "    Uninstalling neural_transducer-0.2:\n",
      "      Successfully uninstalled neural_transducer-0.2\n",
      "Successfully installed neural_transducer-0.2\n",
      "[dynet] random seed: 2\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] random seed: 4\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] random seed: 8\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] random seed: 3\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] random seed: [dynet] random seed: 1\n",
      "[dynet] allocating memory: 512MB\n",
      "9\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] random seed: 5\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] random seed: [dynet] random seed: [dynet] random seed: 6\n",
      "[dynet] allocating memory: 512MB\n",
      "10\n",
      "[dynet] allocating memory: 512MB\n",
      "7\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "[dynet] memory allocation done.\n",
      "INFO: dynet_seed     : 10\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/10\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: dynet_seed     : 6\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/6\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: dynet_seed     : 1\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/1\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/10/vocabulary.pkl.\n",
      "INFO: dynet_seed     : 4\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/4\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/1/vocabulary.pkl.\n",
      "INFO: Wrote vocabulary to output/low/rum/6/vocabulary.pkl.\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: dynet_seed     : 2\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/2\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/4/vocabulary.pkl.\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/2/vocabulary.pkl.\n",
      "INFO: dynet_seed     : 8\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/8\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: dynet_seed     : 9\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/9\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/8/vocabulary.pkl.\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/9/vocabulary.pkl.\n",
      "INFO: dynet_seed     : 5\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/5\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/5/vocabulary.pkl.\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: dynet_seed     : 3\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/3\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/3/vocabulary.pkl.\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: dynet_seed     : 7\n",
      "INFO: dynet_mem      : 1000\n",
      "INFO: dynet_autobatch: None\n",
      "INFO: train          : ../data/low/rum_train.tsv\n",
      "INFO: dev            : ../data/low/rum_dev.tsv\n",
      "INFO: test           : ../data/low/rum_test.tsv\n",
      "INFO: output         : output/low/rum/7\n",
      "INFO: nfd            : True\n",
      "INFO: char_dim       : 100\n",
      "INFO: action_dim     : 100\n",
      "INFO: enc_hidden_dim : 200\n",
      "INFO: dec_hidden_dim : 200\n",
      "INFO: enc_layers     : 1\n",
      "INFO: dec_layers     : 1\n",
      "INFO: beam_width     : 4\n",
      "INFO: k              : 1\n",
      "INFO: patience       : 12\n",
      "INFO: epochs         : 60\n",
      "INFO: batch_size     : 5\n",
      "INFO: sed_em_iterations: 10\n",
      "INFO: Will perform training on NFD-normalized data.\n",
      "INFO: 68 actions: Vocabulary({‚ü™: 0, ‚ü´: 1, ConditionalDel(): 2, ConditionalCopy(): 3, ConditionalSub(new='a'): 4, ConditionalIns(new='a'): 5, ConditionalSub(new=' '): 6, ConditionalIns(new=' '): 7, ConditionalSub(new='b'): 8, ConditionalIns(new='b'): 9, ConditionalSub(new='t'): 10, ConditionalIns(new='t'): 11, ConditionalSub(new='e'): 12, ConditionalIns(new='e'): 13, ConditionalSub(new='m'): 14, ConditionalIns(new='m'): 15, ConditionalSub(new='i'): 16, ConditionalIns(new='i'): 17, ConditionalSub(new='l'): 18, ConditionalIns(new='l'): 19, ConditionalSub(new='u'): 20, ConditionalIns(new='u'): 21, ConditionalSub(new='r'): 22, ConditionalIns(new='r'): 23, ConditionalSub(new='k'): 24, ConditionalIns(new='k'): 25, ConditionalSub(new='Õ°'): 26, ConditionalIns(new='Õ°'): 27, ConditionalSub(new=' É'): 28, ConditionalIns(new=' É'): 29, ConditionalSub(new='p'): 30, ConditionalIns(new='p'): 31, ConditionalSub(new='s'): 32, ConditionalIns(new='s'): 33, ConditionalSub(new='j'): 34, ConditionalIns(new='j'): 35, ConditionalSub(new='o'): 36, ConditionalIns(new='o'): 37, ConditionalSub(new='d'): 38, ConditionalIns(new='d'): 39, ConditionalSub(new='n'): 40, ConditionalIns(new='n'): 41, ConditionalSub(new='f'): 42, ConditionalIns(new='f'): 43, ConditionalSub(new=' ≤'): 44, ConditionalIns(new=' ≤'): 45, ConditionalSub(new=' í'): 46, ConditionalIns(new=' í'): 47, ConditionalSub(new='z'): 48, ConditionalIns(new='z'): 49, ConditionalSub(new='ÃØ'): 50, ConditionalIns(new='ÃØ'): 51, ConditionalSub(new='w'): 52, ConditionalIns(new='w'): 53, ConditionalSub(new='…°'): 54, ConditionalIns(new='…°'): 55, ConditionalSub(new='v'): 56, ConditionalIns(new='v'): 57, ConditionalSub(new='Àê'): 58, ConditionalIns(new='Àê'): 59, ConditionalSub(new='…ô'): 60, ConditionalIns(new='…ô'): 61, ConditionalSub(new='h'): 62, ConditionalIns(new='h'): 63, ConditionalSub(new='≈ã'): 64, ConditionalIns(new='≈ã'): 65, ConditionalSub(new='…®'): 66, ConditionalIns(new='…®'): 67})\n",
      "INFO: 29 chars: Vocabulary({‚ü™: 0, ‚ü´: 1, '<UNK>': 2, 'a': 3, 'b': 4, 't': 5, 'e': 6, 'm': 7, 'i': 8, 'l': 9, 'u': 10, 'r': 11, 'c': 12, 'p': 13, 's': 14, 'o': 15, 'd': 16, 'n': 17, 'f': 18, 'j': 19, 'g': 20, 'z': 21, 'v': 22, 'h': 23, 'x': 24, 'ÃÜ': 25, 'y': 26, 'ÃÇ': 27, 'Ã¶': 28})\n",
      "INFO: Wrote vocabulary to output/low/rum/7/vocabulary.pkl.\n",
      "INFO: Updating model parameters by maximizing likelihood using EM (10 iterations).\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: Initial weighted LL=-79.1403\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_0=-40.4476\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_1=-33.4368\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_2=-31.5690\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_3=-31.4297\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_4=-31.3949\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_5=-31.3813\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_6=-31.3757\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_7=-31.3743\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_8=-31.3741\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/6/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/5/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/3/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/8/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/7/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/9/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/10/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/1/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/2/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: IT_9=-31.3741\n",
      "INFO: Wrote latest model weights to output/low/rum/4/sed.pkl.\n",
      "INFO: Training for a maximum of 60 with a maximum patience of 12.\n",
      "INFO: Number of train batches: 160.\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.812 sec.\n",
      "INFO: Average train loss: 0.8965.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 314.442 sec.\n",
      "INFO: Average train loss: 0.9149.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.311 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 313.070 sec.\n",
      "INFO: Average train loss: 0.9008.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 313.549 sec.\n",
      "INFO: Average train loss: 0.8849.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.805 sec.\n",
      "INFO: Average train loss: 0.8875.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.321 sec.\n",
      "INFO: Average train loss: 0.8802.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 311.400 sec.\n",
      "INFO: Average train loss: 0.8991.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.027 sec.\n",
      "INFO: Average train loss: 0.9278.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.290 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.051 sec.\n",
      "INFO: Found best dev accuracy 0.3600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.181 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.586 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.676 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 312.905 sec.\n",
      "INFO: Average train loss: 0.9083.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.8965 dev loss: 0.0739 train acc: 0.4500 dev acc: 0.3600 best train acc: 0.4500 best dev acc: 0.3600 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.621 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.454 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.074 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.601 sec.\n",
      "INFO: Found best dev accuracy 0.3600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.484 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.965 sec.\n",
      "INFO: Found best dev accuracy 0.4500.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.280 sec.\n",
      "INFO: Found best dev accuracy 0.4800.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.301 sec.\n",
      "INFO: Average train loss: 0.8724.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.9149 dev loss: 0.0624 train acc: 0.4500 dev acc: 0.3600 best train acc: 0.4500 best dev acc: 0.3600 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.194 sec.\n",
      "INFO: Found best dev accuracy 0.5400.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.185 sec.\n",
      "INFO: Found best dev accuracy 0.4700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.085 sec.\n",
      "INFO: Found best dev accuracy 0.3500.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.781 sec.\n",
      "INFO: Found best dev accuracy 0.3600.\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.8849 dev loss: 0.0692 train acc: 0.6400 dev acc: 0.4800 best train acc: 0.6400 best dev acc: 0.4800 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.9008 dev loss: 0.0891 train acc: 0.5600 dev acc: 0.4500 best train acc: 0.5600 best dev acc: 0.4500 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.8875 dev loss: 0.0837 train acc: 0.6400 dev acc: 0.5400 best train acc: 0.6400 best dev acc: 0.5400 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.8802 dev loss: 0.0858 train acc: 0.6200 dev acc: 0.4700 best train acc: 0.6200 best dev acc: 0.4700 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.8991 dev loss: 0.0750 train acc: 0.4300 dev acc: 0.3500 best train acc: 0.4300 best dev acc: 0.3500 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.811 sec.\n",
      "INFO: Found best dev accuracy 0.3600.\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.9278 dev loss: 0.0779 train acc: 0.4500 dev acc: 0.3600 best train acc: 0.4500 best dev acc: 0.3600 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.448 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.9083 dev loss: 0.0584 train acc: 0.4500 dev acc: 0.3600 best train acc: 0.4500 best dev acc: 0.3600 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.623 sec.\n",
      "INFO: Found best dev accuracy 0.5400.\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 0 / 59: train loss: 0.8724 dev loss: 0.1491 train acc: 0.6600 dev acc: 0.5400 best train acc: 0.6600 best dev acc: 0.5400 best epoch: 0 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.963 sec.\n",
      "INFO: Average train loss: 0.5147.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.527 sec.\n",
      "INFO: Average train loss: 0.4751.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.621 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.945 sec.\n",
      "INFO: Average train loss: 0.4269.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.811 sec.\n",
      "INFO: Average train loss: 0.4140.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.099 sec.\n",
      "INFO: Average train loss: 0.4649.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.207 sec.\n",
      "INFO: Average train loss: 0.4156.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.689 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 312.201 sec.\n",
      "INFO: Average train loss: 0.4758.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.408 sec.\n",
      "INFO: Average train loss: 0.5027.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.849 sec.\n",
      "INFO: Found best dev accuracy 0.5600.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.377 sec.\n",
      "INFO: Average train loss: 0.4269.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.173 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.543 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.335 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.5147 dev loss: 0.1311 train acc: 0.6500 dev acc: 0.5600 best train acc: 0.6500 best dev acc: 0.5600 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.388 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.493 sec.\n",
      "INFO: Found best dev accuracy 0.5500.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.496 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.970 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.866 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.072 sec.\n",
      "INFO: Average train loss: 0.4237.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.734 sec.\n",
      "INFO: Found best dev accuracy 0.5600.\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4751 dev loss: 0.0990 train acc: 0.6400 dev acc: 0.5500 best train acc: 0.6400 best dev acc: 0.5500 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.711 sec.\n",
      "INFO: Found best dev accuracy 0.5400.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.179 sec.\n",
      "INFO: Found best dev accuracy 0.5600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.999 sec.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4156 dev loss: 0.1263 train acc: 0.6600 dev acc: 0.5300 best train acc: 0.6600 best dev acc: 0.5400 best epoch: 0 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4269 dev loss: 0.0992 train acc: 0.6600 dev acc: 0.5600 best train acc: 0.6600 best dev acc: 0.5600 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.357 sec.\n",
      "INFO: Found best dev accuracy 0.5600.\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4649 dev loss: 0.0881 train acc: 0.6600 dev acc: 0.5400 best train acc: 0.6600 best dev acc: 0.5400 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.630 sec.\n",
      "INFO: Found best dev accuracy 0.5600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.792 sec.\n",
      "INFO: Found best dev accuracy 0.5300.\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4140 dev loss: 0.1090 train acc: 0.6300 dev acc: 0.5600 best train acc: 0.6300 best dev acc: 0.5600 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.116 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4758 dev loss: 0.1373 train acc: 0.6300 dev acc: 0.5600 best train acc: 0.6300 best dev acc: 0.5600 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.5027 dev loss: 0.0956 train acc: 0.6400 dev acc: 0.5600 best train acc: 0.6400 best dev acc: 0.5600 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4269 dev loss: 0.0844 train acc: 0.6600 dev acc: 0.5300 best train acc: 0.6600 best dev acc: 0.5300 best epoch: 1 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.341 sec.\n",
      "INFO: Epoch 1 / 59: train loss: 0.4237 dev loss: 0.0883 train acc: 0.6600 dev acc: 0.5400 best train acc: 0.6600 best dev acc: 0.5400 best epoch: 0 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 315.319 sec.\n",
      "INFO: Average train loss: 0.4072.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 313.387 sec.\n",
      "INFO: Average train loss: 0.4229.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.427 sec.\n",
      "INFO: Average train loss: 0.3797.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.240 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.873 sec.\n",
      "INFO: Average train loss: 0.3648.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 313.138 sec.\n",
      "INFO: Average train loss: 0.3911.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 315.942 sec.\n",
      "INFO: Average train loss: 0.4170.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.732 sec.\n",
      "INFO: Average train loss: 0.4038.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.985 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.348 sec.\n",
      "INFO: Average train loss: 0.3815.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.640 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.345 sec.\n",
      "INFO: Average train loss: 0.4343.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.279 sec.\n",
      "INFO: Found best dev accuracy 0.5700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.061 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.461 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.630 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 311.969 sec.\n",
      "INFO: Average train loss: 0.4141.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.4072 dev loss: 0.0846 train acc: 0.6900 dev acc: 0.5700 best train acc: 0.6900 best dev acc: 0.5700 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.554 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.810 sec.\n",
      "INFO: Found best dev accuracy 0.5600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.667 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.070 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.689 sec.\n",
      "INFO: Found best dev accuracy 0.6100.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.100 sec.\n",
      "INFO: Found best dev accuracy 0.5700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.698 sec.\n",
      "INFO: Epoch 2 / 59: train loss: 0.3911 dev loss: 0.1033 train acc: 0.7000 dev acc: 0.5400 best train acc: 0.7000 best dev acc: 0.5400 best epoch: 1 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.4229 dev loss: 0.0951 train acc: 0.6500 dev acc: 0.5600 best train acc: 0.6500 best dev acc: 0.5600 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.650 sec.\n",
      "INFO: Found best dev accuracy 0.5800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.394 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.3797 dev loss: 0.1072 train acc: 0.6700 dev acc: 0.6100 best train acc: 0.6700 best dev acc: 0.6100 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.089 sec.\n",
      "INFO: Found best dev accuracy 0.5700.\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.3648 dev loss: 0.1015 train acc: 0.6800 dev acc: 0.5700 best train acc: 0.6800 best dev acc: 0.5700 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.144 sec.\n",
      "INFO: Found best dev accuracy 0.5500.\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.4170 dev loss: 0.1159 train acc: 0.7000 dev acc: 0.5800 best train acc: 0.7000 best dev acc: 0.5800 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.617 sec.\n",
      "INFO: Epoch 2 / 59: train loss: 0.3815 dev loss: 0.1031 train acc: 0.6800 dev acc: 0.5500 best train acc: 0.6800 best dev acc: 0.5600 best epoch: 1 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.4038 dev loss: 0.0900 train acc: 0.7000 dev acc: 0.5700 best train acc: 0.7000 best dev acc: 0.5700 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.4343 dev loss: 0.1169 train acc: 0.6600 dev acc: 0.5500 best train acc: 0.6600 best dev acc: 0.5500 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.810 sec.\n",
      "INFO: Found best dev accuracy 0.6100.\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 2 / 59: train loss: 0.4141 dev loss: 0.1094 train acc: 0.6700 dev acc: 0.6100 best train acc: 0.6700 best dev acc: 0.6100 best epoch: 2 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.119 sec.\n",
      "INFO: Average train loss: 0.3822.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.852 sec.\n",
      "INFO: Average train loss: 0.3808.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.312 sec.\n",
      "INFO: Average train loss: 0.3845.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.279 sec.\n",
      "INFO: Average train loss: 0.3514.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.626 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.322 sec.\n",
      "INFO: Average train loss: 0.3536.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.528 sec.\n",
      "INFO: Average train loss: 0.3429.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 313.024 sec.\n",
      "INFO: Average train loss: 0.3717.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.830 sec.\n",
      "INFO: Average train loss: 0.3725.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.869 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.448 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.153 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 311.935 sec.\n",
      "INFO: Average train loss: 0.3814.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.825 sec.\n",
      "INFO: Found best dev accuracy 0.6500.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.414 sec.\n",
      "INFO: Average train loss: 0.3430.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t...finished in 8.587 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.863 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3822 dev loss: 0.1082 train acc: 0.6600 dev acc: 0.6500 best train acc: 0.6900 best dev acc: 0.6500 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.846 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.054 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.239 sec.\n",
      "INFO: Found best dev accuracy 0.6500.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.443 sec.\n",
      "INFO: Found best dev accuracy 0.6700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.991 sec.\n",
      "INFO: Found best dev accuracy 0.6400.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.749 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.336 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.817 sec.\n",
      "INFO: Found best dev accuracy 0.6500.\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3845 dev loss: 0.0877 train acc: 0.6700 dev acc: 0.6500 best train acc: 0.7000 best dev acc: 0.6500 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.293 sec.\n",
      "INFO: Found best dev accuracy 0.6400.\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3808 dev loss: 0.0718 train acc: 0.6900 dev acc: 0.6700 best train acc: 0.6900 best dev acc: 0.6700 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3514 dev loss: 0.1081 train acc: 0.6900 dev acc: 0.6400 best train acc: 0.6900 best dev acc: 0.6400 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.938 sec.\n",
      "INFO: Found best dev accuracy 0.6800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.213 sec.\n",
      "INFO: Found best dev accuracy 0.6700.\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3536 dev loss: 0.0974 train acc: 0.6700 dev acc: 0.6500 best train acc: 0.7000 best dev acc: 0.6500 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3429 dev loss: 0.0751 train acc: 0.6900 dev acc: 0.6400 best train acc: 0.6900 best dev acc: 0.6400 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3717 dev loss: 0.1208 train acc: 0.6700 dev acc: 0.6800 best train acc: 0.6800 best dev acc: 0.6800 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 13.149 sec.\n",
      "INFO: Found best dev accuracy 0.6100.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.464 sec.\n",
      "INFO: Found best dev accuracy 0.6700.\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3725 dev loss: 0.0893 train acc: 0.6700 dev acc: 0.6700 best train acc: 0.6700 best dev acc: 0.6700 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3814 dev loss: 0.1024 train acc: 0.7000 dev acc: 0.6100 best train acc: 0.7000 best dev acc: 0.6100 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 3 / 59: train loss: 0.3430 dev loss: 0.0800 train acc: 0.6900 dev acc: 0.6700 best train acc: 0.6900 best dev acc: 0.6700 best epoch: 3 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.265 sec.\n",
      "INFO: Average train loss: 0.2929.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.934 sec.\n",
      "INFO: Average train loss: 0.3000.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.013 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 311.948 sec.\n",
      "INFO: Average train loss: 0.3279.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.379 sec.\n",
      "INFO: Average train loss: 0.3319.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.457 sec.\n",
      "INFO: Average train loss: 0.3300.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.249 sec.\n",
      "INFO: Average train loss: 0.2954.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.694 sec.\n",
      "INFO: Average train loss: 0.3208.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.079 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.753 sec.\n",
      "INFO: Average train loss: 0.3467.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.069 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.995 sec.\n",
      "INFO: Average train loss: 0.3074.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.118 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.2929 dev loss: 0.1455 train acc: 0.7100 dev acc: 0.6300 best train acc: 0.7100 best dev acc: 0.6500 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.892 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.654 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.936 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.805 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.506 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3000 dev loss: 0.4227 train acc: 0.6500 dev acc: 0.6000 best train acc: 0.6900 best dev acc: 0.6700 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 312.098 sec.\n",
      "INFO: Average train loss: 0.3067.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.095 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.569 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3279 dev loss: 0.2309 train acc: 0.7000 dev acc: 0.6400 best train acc: 0.7000 best dev acc: 0.6500 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.725 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.040 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3319 dev loss: 0.1228 train acc: 0.6400 dev acc: 0.6000 best train acc: 0.6900 best dev acc: 0.6400 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.071 sec.\n",
      "INFO: Found best dev accuracy 0.6500.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.527 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.2954 dev loss: 0.1227 train acc: 0.7200 dev acc: 0.6200 best train acc: 0.7200 best dev acc: 0.6700 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.286 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3208 dev loss: 0.2362 train acc: 0.6400 dev acc: 0.6400 best train acc: 0.7000 best dev acc: 0.6500 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.884 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.755 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3467 dev loss: 0.3987 train acc: 0.6800 dev acc: 0.6200 best train acc: 0.6800 best dev acc: 0.6800 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3300 dev loss: 0.1580 train acc: 0.8000 dev acc: 0.6500 best train acc: 0.8000 best dev acc: 0.6500 best epoch: 4 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.451 sec.\n",
      "INFO: Found best dev accuracy 0.6500.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3074 dev loss: 0.1234 train acc: 0.6900 dev acc: 0.6500 best train acc: 0.7000 best dev acc: 0.6500 best epoch: 4 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.954 sec.\n",
      "INFO: Epoch 4 / 59: train loss: 0.3067 dev loss: 0.2223 train acc: 0.7900 dev acc: 0.6500 best train acc: 0.7900 best dev acc: 0.6700 best epoch: 3 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 313.179 sec.\n",
      "INFO: Average train loss: 0.3073.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 312.624 sec.\n",
      "INFO: Average train loss: 0.2717.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.829 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 317.574 sec.\n",
      "INFO: Average train loss: 0.3179.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.981 sec.\n",
      "INFO: Average train loss: 0.2464.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 317.484 sec.\n",
      "INFO: Average train loss: 0.3342.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 314.507 sec.\n",
      "INFO: Average train loss: 0.2710.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 312.881 sec.\n",
      "INFO: Average train loss: 0.3191.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.334 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.021 sec.\n",
      "INFO: Found best dev accuracy 0.6600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.343 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 315.077 sec.\n",
      "INFO: Average train loss: 0.2911.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.220 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 5 / 59: train loss: 0.3073 dev loss: 0.0793 train acc: 0.7200 dev acc: 0.6600 best train acc: 0.7200 best dev acc: 0.6600 best epoch: 5 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.107 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 311.623 sec.\n",
      "INFO: Average train loss: 0.2824.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.082 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.552 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 312.187 sec.\n",
      "INFO: Average train loss: 0.2687.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.002 sec.\n",
      "INFO: Found best dev accuracy 0.6600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.913 sec.\n",
      "INFO: Epoch 5 / 59: train loss: 0.3179 dev loss: 0.1065 train acc: 0.7600 dev acc: 0.6700 best train acc: 0.7600 best dev acc: 0.6700 best epoch: 3 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.712 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 5 / 59: train loss: 0.2717 dev loss: 0.1002 train acc: 0.7100 dev acc: 0.6600 best train acc: 0.7100 best dev acc: 0.6600 best epoch: 5 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.867 sec.\n",
      "INFO: Found best dev accuracy 0.7300.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.427 sec.\n",
      "INFO: Found best dev accuracy 0.6600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.480 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.696 sec.\n",
      "INFO: Epoch 5 / 59: train loss: 0.2710 dev loss: 0.1043 train acc: 0.7000 dev acc: 0.6500 best train acc: 0.7200 best dev acc: 0.6700 best epoch: 3 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.782 sec.\n",
      "INFO: Epoch 5 / 59: train loss: 0.3191 dev loss: 0.0956 train acc: 0.7200 dev acc: 0.6600 best train acc: 0.7200 best dev acc: 0.6800 best epoch: 3 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.758 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 5 / 59: train loss: 0.2464 dev loss: 0.0916 train acc: 0.7800 dev acc: 0.7300 best train acc: 0.7800 best dev acc: 0.7300 best epoch: 5 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 5 / 59: train loss: 0.3342 dev loss: 0.1074 train acc: 0.7200 dev acc: 0.6600 best train acc: 0.7200 best dev acc: 0.6600 best epoch: 5 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.676 sec.\n",
      "INFO: Epoch 5 / 59: train loss: 0.2911 dev loss: 0.1180 train acc: 0.7300 dev acc: 0.6500 best train acc: 0.8000 best dev acc: 0.6500 best epoch: 4 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.812 sec.\n",
      "INFO: Found best dev accuracy 0.6600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.133 sec.\n",
      "INFO: Found best dev accuracy 0.7400.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 5 / 59: train loss: 0.2824 dev loss: 0.1024 train acc: 0.7100 dev acc: 0.6600 best train acc: 0.7100 best dev acc: 0.6600 best epoch: 5 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 5 / 59: train loss: 0.2687 dev loss: 0.0953 train acc: 0.8200 dev acc: 0.7400 best train acc: 0.8200 best dev acc: 0.7400 best epoch: 5 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.850 sec.\n",
      "INFO: Average train loss: 0.3027.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.419 sec.\n",
      "INFO: Average train loss: 0.2577.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.893 sec.\n",
      "INFO: Average train loss: 0.2306.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.325 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.743 sec.\n",
      "INFO: Average train loss: 0.2149.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.599 sec.\n",
      "INFO: Average train loss: 0.2507.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 311.127 sec.\n",
      "INFO: Average train loss: 0.2695.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.704 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.014 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.290 sec.\n",
      "INFO: Average train loss: 0.2829.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.287 sec.\n",
      "INFO: Average train loss: 0.2421.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.635 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.168 sec.\n",
      "INFO: Found best dev accuracy 0.7000.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.819 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.3027 dev loss: 0.0944 train acc: 0.8000 dev acc: 0.7000 best train acc: 0.8000 best dev acc: 0.7000 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.281 sec.\n",
      "INFO: Average train loss: 0.2821.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.623 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.828 sec.\n",
      "INFO: Average train loss: 0.2225.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.256 sec.\n",
      "INFO: Found best dev accuracy 0.7200.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.264 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.261 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.345 sec.\n",
      "INFO: Found best dev accuracy 0.6800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.707 sec.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2149 dev loss: 0.0710 train acc: 0.8300 dev acc: 0.7200 best train acc: 0.8300 best dev acc: 0.7300 best epoch: 5 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.097 sec.\n",
      "INFO: Found best dev accuracy 0.6800.\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2306 dev loss: 0.0579 train acc: 0.8300 dev acc: 0.7200 best train acc: 0.8300 best dev acc: 0.7200 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2577 dev loss: 0.0809 train acc: 0.7800 dev acc: 0.6800 best train acc: 0.7800 best dev acc: 0.6800 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.009 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.897 sec.\n",
      "INFO: Found best dev accuracy 0.7000.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.579 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2507 dev loss: 0.0724 train acc: 0.8000 dev acc: 0.6800 best train acc: 0.8000 best dev acc: 0.6800 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.043 sec.\n",
      "INFO: Found best dev accuracy 0.7600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.350 sec.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2829 dev loss: 0.0717 train acc: 0.7800 dev acc: 0.6600 best train acc: 0.7800 best dev acc: 0.6600 best epoch: 5 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2695 dev loss: 0.0771 train acc: 0.7900 dev acc: 0.7000 best train acc: 0.7900 best dev acc: 0.7000 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2421 dev loss: 0.0643 train acc: 0.8500 dev acc: 0.7600 best train acc: 0.8500 best dev acc: 0.7600 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.102 sec.\n",
      "INFO: Found best dev accuracy 0.7500.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.697 sec.\n",
      "INFO: Found best dev accuracy 0.7200.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2821 dev loss: 0.0940 train acc: 0.8300 dev acc: 0.7200 best train acc: 0.8300 best dev acc: 0.7200 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 6 / 59: train loss: 0.2225 dev loss: 0.0599 train acc: 0.8400 dev acc: 0.7500 best train acc: 0.8400 best dev acc: 0.7500 best epoch: 6 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.776 sec.\n",
      "INFO: Average train loss: 0.2302.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.100 sec.\n",
      "INFO: Average train loss: 0.2124.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.407 sec.\n",
      "INFO: Average train loss: 0.1929.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.373 sec.\n",
      "INFO: Average train loss: 0.2017.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.753 sec.\n",
      "INFO: Average train loss: 0.2179.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.832 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.738 sec.\n",
      "INFO: Average train loss: 0.2101.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.897 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.240 sec.\n",
      "INFO: Average train loss: 0.1795.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.965 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.683 sec.\n",
      "INFO: Average train loss: 0.1817.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.373 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.633 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.457 sec.\n",
      "INFO: Found best dev accuracy 0.7300.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.933 sec.\n",
      "INFO: Average train loss: 0.2134.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.166 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.666 sec.\n",
      "INFO: Average train loss: 0.2087.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.542 sec.\n",
      "INFO: Found best dev accuracy 0.7900.\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.2302 dev loss: 0.0657 train acc: 0.8500 dev acc: 0.7300 best train acc: 0.8500 best dev acc: 0.7300 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.838 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.576 sec.\n",
      "INFO: Found best dev accuracy 0.7700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.836 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.103 sec.\n",
      "INFO: Found best dev accuracy 0.7600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.672 sec.\n",
      "INFO: Found best dev accuracy 0.7400.\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.2124 dev loss: 0.0556 train acc: 0.8400 dev acc: 0.7900 best train acc: 0.8400 best dev acc: 0.7900 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.1929 dev loss: 0.0601 train acc: 0.8800 dev acc: 0.7700 best train acc: 0.8800 best dev acc: 0.7700 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.114 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.621 sec.\n",
      "INFO: Found best dev accuracy 0.7700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.097 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.2179 dev loss: 0.0601 train acc: 0.8100 dev acc: 0.7600 best train acc: 0.8100 best dev acc: 0.7600 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.2017 dev loss: 0.0580 train acc: 0.8200 dev acc: 0.7400 best train acc: 0.8200 best dev acc: 0.7400 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.532 sec.\n",
      "INFO: Found best dev accuracy 0.8000.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.077 sec.\n",
      "INFO: Found best dev accuracy 0.7400.\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.2101 dev loss: 0.0614 train acc: 0.8400 dev acc: 0.7700 best train acc: 0.8400 best dev acc: 0.7700 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.1795 dev loss: 0.0447 train acc: 0.8600 dev acc: 0.8000 best train acc: 0.8600 best dev acc: 0.8000 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.394 sec.\n",
      "INFO: Found best dev accuracy 0.7500.\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.1817 dev loss: 0.0619 train acc: 0.8600 dev acc: 0.7400 best train acc: 0.8600 best dev acc: 0.7400 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.984 sec.\n",
      "INFO: Found best dev accuracy 0.8100.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.2134 dev loss: 0.0595 train acc: 0.8300 dev acc: 0.7500 best train acc: 0.8300 best dev acc: 0.7500 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 7 / 59: train loss: 0.2087 dev loss: 0.0524 train acc: 0.8400 dev acc: 0.8100 best train acc: 0.8400 best dev acc: 0.8100 best epoch: 7 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.408 sec.\n",
      "INFO: Average train loss: 0.2032.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.091 sec.\n",
      "INFO: Average train loss: 0.1705.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.136 sec.\n",
      "INFO: Average train loss: 0.1938.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.885 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.668 sec.\n",
      "INFO: Average train loss: 0.2032.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.671 sec.\n",
      "INFO: Average train loss: 0.1953.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.496 sec.\n",
      "INFO: Average train loss: 0.1819.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.507 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.893 sec.\n",
      "INFO: Average train loss: 0.1511.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.014 sec.\n",
      "INFO: Average train loss: 0.1917.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.322 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.498 sec.\n",
      "INFO: Found best dev accuracy 0.7600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.273 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.938 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.895 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 8 / 59: train loss: 0.2032 dev loss: 0.0539 train acc: 0.8400 dev acc: 0.7600 best train acc: 0.8500 best dev acc: 0.7600 best epoch: 8 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.540 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.023 sec.\n",
      "INFO: Epoch 8 / 59: train loss: 0.1705 dev loss: 0.0416 train acc: 0.8400 dev acc: 0.7700 best train acc: 0.8400 best dev acc: 0.7900 best epoch: 7 patience: 1 / 11\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.414 sec.\n",
      "INFO: Average train loss: 0.2182.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.916 sec.\n",
      "INFO: Average train loss: 0.1973.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.656 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.312 sec.\n",
      "INFO: Found best dev accuracy 0.7900.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.843 sec.\n",
      "INFO: Found best dev accuracy 0.8000.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.061 sec.\n",
      "INFO: Epoch 8 / 59: train loss: 0.1953 dev loss: 0.0551 train acc: 0.8400 dev acc: 0.7600 best train acc: 0.8400 best dev acc: 0.7600 best epoch: 7 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.082 sec.\n",
      "INFO: Epoch 8 / 59: train loss: 0.1819 dev loss: 0.0376 train acc: 0.8400 dev acc: 0.7700 best train acc: 0.8400 best dev acc: 0.7700 best epoch: 7 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 8 / 59: train loss: 0.1938 dev loss: 0.0436 train acc: 0.8600 dev acc: 0.7900 best train acc: 0.8800 best dev acc: 0.7900 best epoch: 8 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.123 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 8 / 59: train loss: 0.2032 dev loss: 0.0533 train acc: 0.9200 dev acc: 0.8000 best train acc: 0.9200 best dev acc: 0.8000 best epoch: 8 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.989 sec.\n",
      "INFO: Found best dev accuracy 0.8100.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.732 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.878 sec.\n",
      "INFO: Found best dev accuracy 0.7600.\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 8 / 59: train loss: 0.1511 dev loss: 0.0363 train acc: 0.8600 dev acc: 0.8100 best train acc: 0.8600 best dev acc: 0.8100 best epoch: 8 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 8 / 59: train loss: 0.1917 dev loss: 0.0420 train acc: 0.8400 dev acc: 0.7600 best train acc: 0.8600 best dev acc: 0.7600 best epoch: 8 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.250 sec.\n",
      "INFO: Found best dev accuracy 0.7600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.238 sec.\n",
      "INFO: Epoch 8 / 59: train loss: 0.1973 dev loss: 0.0396 train acc: 0.8800 dev acc: 0.8100 best train acc: 0.8800 best dev acc: 0.8100 best epoch: 7 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 8 / 59: train loss: 0.2182 dev loss: 0.0489 train acc: 0.8300 dev acc: 0.7600 best train acc: 0.8300 best dev acc: 0.7600 best epoch: 8 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.040 sec.\n",
      "INFO: Average train loss: 0.1812.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.622 sec.\n",
      "INFO: Average train loss: 0.1577.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 299.755 sec.\n",
      "INFO: Average train loss: 0.1581.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.231 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.869 sec.\n",
      "INFO: Average train loss: 0.1849.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.694 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.596 sec.\n",
      "INFO: Average train loss: 0.1736.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.576 sec.\n",
      "INFO: Average train loss: 0.1586.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.243 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 298.969 sec.\n",
      "INFO: Average train loss: 0.1426.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.458 sec.\n",
      "INFO: Found best dev accuracy 0.7900.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.654 sec.\n",
      "INFO: Average train loss: 0.1607.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.810 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.005 sec.\n",
      "INFO: Found best dev accuracy 0.8100.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.133 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.876 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.926 sec.\n",
      "INFO: Found best dev accuracy 0.8000.\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1812 dev loss: 0.0505 train acc: 0.8800 dev acc: 0.7900 best train acc: 0.8800 best dev acc: 0.7900 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.203 sec.\n",
      "INFO: Average train loss: 0.1527.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.697 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1577 dev loss: 0.0395 train acc: 0.9100 dev acc: 0.8100 best train acc: 0.9100 best dev acc: 0.8100 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.416 sec.\n",
      "INFO: Average train loss: 0.1900.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.061 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1581 dev loss: 0.0398 train acc: 0.8700 dev acc: 0.8000 best train acc: 0.8700 best dev acc: 0.8000 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.076 sec.\n",
      "INFO: Found best dev accuracy 0.8400.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.098 sec.\n",
      "INFO: Found best dev accuracy 0.8400.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.675 sec.\n",
      "INFO: Found best dev accuracy 0.8100.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.473 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1849 dev loss: 0.0358 train acc: 0.9400 dev acc: 0.8400 best train acc: 0.9400 best dev acc: 0.8400 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.659 sec.\n",
      "INFO: Found best dev accuracy 0.8800.\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1736 dev loss: 0.0653 train acc: 0.9000 dev acc: 0.8400 best train acc: 0.9000 best dev acc: 0.8400 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.155 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.766 sec.\n",
      "INFO: Found best dev accuracy 0.8100.\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1586 dev loss: 0.0390 train acc: 0.8900 dev acc: 0.8100 best train acc: 0.8900 best dev acc: 0.8100 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1426 dev loss: 0.0366 train acc: 0.9400 dev acc: 0.8800 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.246 sec.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1527 dev loss: 0.0530 train acc: 0.9100 dev acc: 0.7900 best train acc: 0.9100 best dev acc: 0.8100 best epoch: 7 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1607 dev loss: 0.0437 train acc: 0.8600 dev acc: 0.8100 best train acc: 0.8600 best dev acc: 0.8100 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.759 sec.\n",
      "INFO: Found best dev accuracy 0.7900.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 9 / 59: train loss: 0.1900 dev loss: 0.0618 train acc: 0.9000 dev acc: 0.7900 best train acc: 0.9000 best dev acc: 0.7900 best epoch: 9 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.080 sec.\n",
      "INFO: Average train loss: 0.1546.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.612 sec.\n",
      "INFO: Average train loss: 0.1262.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.971 sec.\n",
      "INFO: Average train loss: 0.1509.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.137 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.929 sec.\n",
      "INFO: Average train loss: 0.1422.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.859 sec.\n",
      "INFO: Average train loss: 0.1378.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.483 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.936 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.064 sec.\n",
      "INFO: Average train loss: 0.1361.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.645 sec.\n",
      "INFO: Found best dev accuracy 0.8300.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.572 sec.\n",
      "INFO: Average train loss: 0.1192.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.105 sec.\n",
      "INFO: Average train loss: 0.1315.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1546 dev loss: 0.0678 train acc: 0.8900 dev acc: 0.8300 best train acc: 0.8900 best dev acc: 0.8300 best epoch: 10 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.082 sec.\n",
      "INFO: Average train loss: 0.1421.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.490 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.252 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.797 sec.\n",
      "INFO: Found best dev accuracy 0.8300.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.802 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.625 sec.\n",
      "INFO: Found best dev accuracy 0.8200.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.350 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.733 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1262 dev loss: 0.0485 train acc: 0.9200 dev acc: 0.8300 best train acc: 0.9200 best dev acc: 0.8300 best epoch: 10 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.011 sec.\n",
      "INFO: Average train loss: 0.1508.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1509 dev loss: 0.0563 train acc: 0.8500 dev acc: 0.8200 best train acc: 0.8700 best dev acc: 0.8200 best epoch: 10 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.199 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.313 sec.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1422 dev loss: 0.0458 train acc: 0.9100 dev acc: 0.8000 best train acc: 0.9400 best dev acc: 0.8400 best epoch: 9 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.533 sec.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1378 dev loss: 0.0514 train acc: 0.9000 dev acc: 0.8000 best train acc: 0.9000 best dev acc: 0.8400 best epoch: 9 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.125 sec.\n",
      "INFO: Found best dev accuracy 0.8200.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.880 sec.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1192 dev loss: 0.0360 train acc: 0.8900 dev acc: 0.8300 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 9 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.994 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.002 sec.\n",
      "INFO: Found best dev accuracy 0.8300.\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1361 dev loss: 0.0924 train acc: 0.8600 dev acc: 0.8200 best train acc: 0.8900 best dev acc: 0.8200 best epoch: 10 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.325 sec.\n",
      "INFO: Found best dev accuracy 0.8700.\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1315 dev loss: 0.0534 train acc: 0.9200 dev acc: 0.8300 best train acc: 0.9200 best dev acc: 0.8300 best epoch: 10 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1421 dev loss: 0.0523 train acc: 0.9400 dev acc: 0.8700 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 10 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.255 sec.\n",
      "INFO: Found best dev accuracy 0.8300.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 10 / 59: train loss: 0.1508 dev loss: 0.0666 train acc: 0.8700 dev acc: 0.8300 best train acc: 0.9000 best dev acc: 0.8300 best epoch: 10 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.104 sec.\n",
      "INFO: Average train loss: 0.1363.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.473 sec.\n",
      "INFO: Average train loss: 0.1192.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.757 sec.\n",
      "INFO: Average train loss: 0.1384.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.557 sec.\n",
      "INFO: Average train loss: 0.1049.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.453 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.797 sec.\n",
      "INFO: Average train loss: 0.1352.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.792 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.646 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.932 sec.\n",
      "INFO: Average train loss: 0.1215.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.363 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.832 sec.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1363 dev loss: 0.0454 train acc: 0.9200 dev acc: 0.8300 best train acc: 0.9200 best dev acc: 0.8300 best epoch: 10 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.309 sec.\n",
      "INFO: Average train loss: 0.1122.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.436 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.635 sec.\n",
      "INFO: Average train loss: 0.1201.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.494 sec.\n",
      "INFO: Found best dev accuracy 0.8400.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.667 sec.\n",
      "INFO: Found best dev accuracy 0.8500.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.909 sec.\n",
      "INFO: Average train loss: 0.1238.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.839 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.302 sec.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1049 dev loss: 0.0357 train acc: 0.9200 dev acc: 0.8300 best train acc: 0.9400 best dev acc: 0.8400 best epoch: 9 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.854 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.007 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.017 sec.\n",
      "INFO: Found best dev accuracy 0.8600.\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1192 dev loss: 0.0345 train acc: 0.9000 dev acc: 0.8400 best train acc: 0.9000 best dev acc: 0.8400 best epoch: 11 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1384 dev loss: 0.0388 train acc: 0.9100 dev acc: 0.8500 best train acc: 0.9200 best dev acc: 0.8500 best epoch: 11 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.898 sec.\n",
      "INFO: Average train loss: 0.1136.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1352 dev loss: 0.0375 train acc: 0.9000 dev acc: 0.8600 best train acc: 0.9000 best dev acc: 0.8600 best epoch: 11 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.014 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.259 sec.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1215 dev loss: 0.0458 train acc: 0.9300 dev acc: 0.8300 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 9 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.498 sec.\n",
      "INFO: Found best dev accuracy 0.8400.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.741 sec.\n",
      "INFO: Found best dev accuracy 0.9000.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.091 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1122 dev loss: 0.0418 train acc: 0.9200 dev acc: 0.8400 best train acc: 0.9200 best dev acc: 0.8400 best epoch: 11 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/3/best.model.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1201 dev loss: 0.0342 train acc: 0.9100 dev acc: 0.9000 best train acc: 0.9100 best dev acc: 0.9000 best epoch: 11 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.101 sec.\n",
      "INFO: Found best dev accuracy 0.8900.\n",
      "INFO: Saved new best model to output/low/rum/10/best.model.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1238 dev loss: 0.0366 train acc: 0.9300 dev acc: 0.8900 best train acc: 0.9400 best dev acc: 0.8900 best epoch: 11 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.239 sec.\n",
      "INFO: Found best dev accuracy 0.8400.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 11 / 59: train loss: 0.1136 dev loss: 0.0408 train acc: 0.9200 dev acc: 0.8400 best train acc: 0.9200 best dev acc: 0.8400 best epoch: 11 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.733 sec.\n",
      "INFO: Average train loss: 0.1268.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.322 sec.\n",
      "INFO: Average train loss: 0.1122.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.984 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.286 sec.\n",
      "INFO: Average train loss: 0.1084.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.050 sec.\n",
      "INFO: Average train loss: 0.1102.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 299.585 sec.\n",
      "INFO: Average train loss: 0.1203.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.460 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.179 sec.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1268 dev loss: 0.0419 train acc: 0.9100 dev acc: 0.8000 best train acc: 0.9200 best dev acc: 0.8300 best epoch: 10 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.169 sec.\n",
      "INFO: Average train loss: 0.0940.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.400 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.737 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.688 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.534 sec.\n",
      "INFO: Found best dev accuracy 0.8500.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.598 sec.\n",
      "INFO: Average train loss: 0.1194.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 297.803 sec.\n",
      "INFO: Average train loss: 0.1088.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.908 sec.\n",
      "INFO: Average train loss: 0.1034.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.360 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1122 dev loss: 0.0233 train acc: 0.9300 dev acc: 0.8500 best train acc: 0.9400 best dev acc: 0.8500 best epoch: 12 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.454 sec.\n",
      "INFO: Found best dev accuracy 0.8600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.334 sec.\n",
      "INFO: Found best dev accuracy 0.8700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.314 sec.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1203 dev loss: 0.0307 train acc: 0.9200 dev acc: 0.8600 best train acc: 0.9200 best dev acc: 0.8600 best epoch: 11 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1084 dev loss: 0.0300 train acc: 0.9400 dev acc: 0.8700 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 12 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1102 dev loss: 0.0285 train acc: 0.9400 dev acc: 0.8600 best train acc: 0.9400 best dev acc: 0.8600 best epoch: 12 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.117 sec.\n",
      "INFO: Average train loss: 0.1155.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.315 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.006 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.853 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.594 sec.\n",
      "INFO: Epoch 12 / 59: train loss: 0.0940 dev loss: 0.0288 train acc: 0.9200 dev acc: 0.8600 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 9 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.646 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.599 sec.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1194 dev loss: 0.0305 train acc: 0.9500 dev acc: 0.8300 best train acc: 0.9500 best dev acc: 0.8400 best epoch: 11 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.665 sec.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1088 dev loss: 0.0267 train acc: 0.9400 dev acc: 0.8600 best train acc: 0.9400 best dev acc: 0.8900 best epoch: 11 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.898 sec.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1034 dev loss: 0.0330 train acc: 0.9200 dev acc: 0.8900 best train acc: 0.9200 best dev acc: 0.9000 best epoch: 11 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.346 sec.\n",
      "INFO: Epoch 12 / 59: train loss: 0.1155 dev loss: 0.0327 train acc: 0.9400 dev acc: 0.8400 best train acc: 0.9400 best dev acc: 0.8400 best epoch: 11 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.429 sec.\n",
      "INFO: Average train loss: 0.1025.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.336 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 299.975 sec.\n",
      "INFO: Average train loss: 0.1025.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.642 sec.\n",
      "INFO: Average train loss: 0.1012.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 298.014 sec.\n",
      "INFO: Average train loss: 0.0994.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.127 sec.\n",
      "INFO: Epoch 13 / 59: train loss: 0.1025 dev loss: 0.0411 train acc: 0.9400 dev acc: 0.8100 best train acc: 0.9400 best dev acc: 0.8300 best epoch: 10 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.049 sec.\n",
      "INFO: Average train loss: 0.0968.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.094 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.118 sec.\n",
      "INFO: Average train loss: 0.0993.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.001 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.734 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.049 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 297.800 sec.\n",
      "INFO: Average train loss: 0.0901.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 298.816 sec.\n",
      "INFO: Average train loss: 0.1014.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.753 sec.\n",
      "INFO: Epoch 13 / 59: train loss: 0.1025 dev loss: 0.0333 train acc: 0.9100 dev acc: 0.8100 best train acc: 0.9400 best dev acc: 0.8500 best epoch: 12 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.969 sec.\n",
      "INFO: Average train loss: 0.0921.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.364 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.934 sec.\n",
      "INFO: Found best dev accuracy 0.8800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.760 sec.\n",
      "INFO: Found best dev accuracy 0.8800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.136 sec.\n",
      "INFO: Epoch 13 / 59: train loss: 0.0968 dev loss: 0.0320 train acc: 0.9100 dev acc: 0.8600 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 12 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.093 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.780 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 13 / 59: train loss: 0.0994 dev loss: 0.0287 train acc: 0.9300 dev acc: 0.8800 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 13 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 13 / 59: train loss: 0.1012 dev loss: 0.0355 train acc: 0.9300 dev acc: 0.8800 best train acc: 0.9300 best dev acc: 0.8800 best epoch: 13 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.002 sec.\n",
      "INFO: Average train loss: 0.1045.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.307 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.529 sec.\n",
      "INFO: Epoch 13 / 59: train loss: 0.0993 dev loss: 0.0275 train acc: 0.9400 dev acc: 0.8700 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 9 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.355 sec.\n",
      "INFO: Epoch 13 / 59: train loss: 0.0901 dev loss: 0.0466 train acc: 0.9400 dev acc: 0.8700 best train acc: 0.9400 best dev acc: 0.9000 best epoch: 11 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.621 sec.\n",
      "INFO: Epoch 13 / 59: train loss: 0.1014 dev loss: 0.0325 train acc: 0.9400 dev acc: 0.8800 best train acc: 0.9400 best dev acc: 0.8900 best epoch: 11 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.798 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.110 sec.\n",
      "INFO: Epoch 13 / 59: train loss: 0.0921 dev loss: 0.0303 train acc: 0.9400 dev acc: 0.8400 best train acc: 0.9500 best dev acc: 0.8400 best epoch: 11 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.558 sec.\n",
      "INFO: Found best dev accuracy 0.8700.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 13 / 59: train loss: 0.1045 dev loss: 0.0327 train acc: 0.9100 dev acc: 0.8700 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 13 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.466 sec.\n",
      "INFO: Average train loss: 0.1010.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.217 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.830 sec.\n",
      "INFO: Average train loss: 0.0893.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.809 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.1010 dev loss: 0.0322 train acc: 0.9000 dev acc: 0.8100 best train acc: 0.9400 best dev acc: 0.8300 best epoch: 10 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.092 sec.\n",
      "INFO: Average train loss: 0.0928.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.597 sec.\n",
      "INFO: Average train loss: 0.0942.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.754 sec.\n",
      "INFO: Average train loss: 0.0898.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.061 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.490 sec.\n",
      "INFO: Average train loss: 0.0946.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.591 sec.\n",
      "INFO: Average train loss: 0.0984.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.112 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.795 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.927 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.276 sec.\n",
      "INFO: Average train loss: 0.0955.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.850 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0893 dev loss: 0.0232 train acc: 0.9400 dev acc: 0.8500 best train acc: 0.9400 best dev acc: 0.8500 best epoch: 12 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.100 sec.\n",
      "INFO: Average train loss: 0.0894.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.230 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.646 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.567 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0928 dev loss: 0.0243 train acc: 0.9300 dev acc: 0.8400 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 12 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.413 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0942 dev loss: 0.0218 train acc: 0.9200 dev acc: 0.8700 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 13 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.262 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0898 dev loss: 0.0268 train acc: 0.8900 dev acc: 0.8700 best train acc: 0.9300 best dev acc: 0.8800 best epoch: 13 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.562 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.279 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.757 sec.\n",
      "INFO: Found best dev accuracy 0.8900.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.387 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0984 dev loss: 0.0241 train acc: 0.9200 dev acc: 0.8700 best train acc: 0.9400 best dev acc: 0.9000 best epoch: 11 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.703 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0955 dev loss: 0.0236 train acc: 0.9300 dev acc: 0.8400 best train acc: 0.9400 best dev acc: 0.8900 best epoch: 11 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/9/best.model.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0946 dev loss: 0.0216 train acc: 0.9200 dev acc: 0.8900 best train acc: 0.9400 best dev acc: 0.8900 best epoch: 14 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.913 sec.\n",
      "INFO: Average train loss: 0.1206.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.265 sec.\n",
      "INFO: Found best dev accuracy 0.8700.\n",
      "INFO: Saved new best model to output/low/rum/4/best.model.\n",
      "INFO: Epoch 14 / 59: train loss: 0.0894 dev loss: 0.0238 train acc: 0.9300 dev acc: 0.8700 best train acc: 0.9500 best dev acc: 0.8700 best epoch: 14 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.884 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.396 sec.\n",
      "INFO: Epoch 14 / 59: train loss: 0.1206 dev loss: 0.0233 train acc: 0.9100 dev acc: 0.8600 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 13 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.951 sec.\n",
      "INFO: Average train loss: 0.0845.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.899 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 300.544 sec.\n",
      "INFO: Average train loss: 0.0922.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.836 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0845 dev loss: 0.0248 train acc: 0.9000 dev acc: 0.8200 best train acc: 0.9400 best dev acc: 0.8300 best epoch: 10 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.210 sec.\n",
      "INFO: Average train loss: 0.0830.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.137 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.552 sec.\n",
      "INFO: Average train loss: 0.0826.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.384 sec.\n",
      "INFO: Average train loss: 0.0878.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.015 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.164 sec.\n",
      "INFO: Average train loss: 0.0697.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.995 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0922 dev loss: 0.0208 train acc: 0.9100 dev acc: 0.8300 best train acc: 0.9400 best dev acc: 0.8500 best epoch: 12 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.897 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.273 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.862 sec.\n",
      "INFO: Average train loss: 0.0807.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.972 sec.\n",
      "INFO: Average train loss: 0.0754.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.248 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0830 dev loss: 0.0269 train acc: 0.8800 dev acc: 0.8300 best train acc: 0.9300 best dev acc: 0.8800 best epoch: 13 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.794 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.574 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0826 dev loss: 0.0220 train acc: 0.8900 dev acc: 0.8500 best train acc: 0.9400 best dev acc: 0.8800 best epoch: 13 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.368 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.562 sec.\n",
      "INFO: Average train loss: 0.0715.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.310 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0878 dev loss: 0.0242 train acc: 0.9100 dev acc: 0.8300 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 12 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.338 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.476 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0697 dev loss: 0.0203 train acc: 0.9200 dev acc: 0.8500 best train acc: 0.9400 best dev acc: 0.9000 best epoch: 11 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.068 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.361 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0807 dev loss: 0.0172 train acc: 0.9000 dev acc: 0.8600 best train acc: 0.9400 best dev acc: 0.8900 best epoch: 14 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.166 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0754 dev loss: 0.0222 train acc: 0.9400 dev acc: 0.8400 best train acc: 0.9400 best dev acc: 0.8900 best epoch: 11 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.746 sec.\n",
      "INFO: Average train loss: 0.0871.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.173 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0715 dev loss: 0.0250 train acc: 0.8900 dev acc: 0.8100 best train acc: 0.9500 best dev acc: 0.8700 best epoch: 14 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.774 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.871 sec.\n",
      "INFO: Epoch 15 / 59: train loss: 0.0871 dev loss: 0.0241 train acc: 0.8800 dev acc: 0.8200 best train acc: 0.9400 best dev acc: 0.8700 best epoch: 13 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.699 sec.\n",
      "INFO: Average train loss: 0.0932.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.959 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.629 sec.\n",
      "INFO: Found best dev accuracy 0.8600.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.543 sec.\n",
      "INFO: Average train loss: 0.0792.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0932 dev loss: 0.0383 train acc: 0.9300 dev acc: 0.8600 best train acc: 0.9400 best dev acc: 0.8600 best epoch: 16 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.056 sec.\n",
      "INFO: Average train loss: 0.0724.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.816 sec.\n",
      "INFO: Average train loss: 0.0786.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.614 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.952 sec.\n",
      "INFO: Average train loss: 0.0661.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.017 sec.\n",
      "INFO: Average train loss: 0.0615.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.455 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.255 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.203 sec.\n",
      "INFO: Average train loss: 0.0675.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.944 sec.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0792 dev loss: 0.0207 train acc: 0.9300 dev acc: 0.8500 best train acc: 0.9400 best dev acc: 0.8500 best epoch: 12 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.052 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.152 sec.\n",
      "INFO: Average train loss: 0.0825.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.486 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.704 sec.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0724 dev loss: 0.0235 train acc: 0.9600 dev acc: 0.8700 best train acc: 0.9600 best dev acc: 0.8800 best epoch: 13 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.208 sec.\n",
      "INFO: Found best dev accuracy 0.8900.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.122 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.541 sec.\n",
      "INFO: Average train loss: 0.0616.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.848 sec.\n",
      "INFO: Found best dev accuracy 0.8800.\n",
      "INFO: Saved new best model to output/low/rum/2/best.model.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0786 dev loss: 0.0267 train acc: 0.9500 dev acc: 0.8900 best train acc: 0.9500 best dev acc: 0.8900 best epoch: 16 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.400 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.105 sec.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0615 dev loss: 0.0242 train acc: 0.9500 dev acc: 0.9000 best train acc: 0.9500 best dev acc: 0.9000 best epoch: 11 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0661 dev loss: 0.0242 train acc: 0.9500 dev acc: 0.8800 best train acc: 0.9500 best dev acc: 0.8800 best epoch: 16 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.305 sec.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0675 dev loss: 0.0223 train acc: 0.9600 dev acc: 0.8900 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.692 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.187 sec.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0825 dev loss: 0.0241 train acc: 0.9600 dev acc: 0.8600 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.847 sec.\n",
      "INFO: Average train loss: 0.0812.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.150 sec.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0616 dev loss: 0.0214 train acc: 0.9600 dev acc: 0.8500 best train acc: 0.9600 best dev acc: 0.8700 best epoch: 14 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.617 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.876 sec.\n",
      "INFO: Found best dev accuracy 0.9000.\n",
      "INFO: Saved new best model to output/low/rum/8/best.model.\n",
      "INFO: Epoch 16 / 59: train loss: 0.0812 dev loss: 0.0221 train acc: 0.9400 dev acc: 0.9000 best train acc: 0.9400 best dev acc: 0.9000 best epoch: 16 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.485 sec.\n",
      "INFO: Average train loss: 0.0739.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.526 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.052 sec.\n",
      "INFO: Average train loss: 0.0669.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.060 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0739 dev loss: 0.0287 train acc: 0.9100 dev acc: 0.8400 best train acc: 0.9400 best dev acc: 0.8600 best epoch: 16 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.834 sec.\n",
      "INFO: Average train loss: 0.0675.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.945 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.262 sec.\n",
      "INFO: Average train loss: 0.0736.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.068 sec.\n",
      "INFO: Average train loss: 0.0618.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.553 sec.\n",
      "INFO: Average train loss: 0.0654.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.918 sec.\n",
      "INFO: Average train loss: 0.0509.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.222 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.857 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0669 dev loss: 0.0294 train acc: 0.9600 dev acc: 0.8300 best train acc: 0.9600 best dev acc: 0.8500 best epoch: 12 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.770 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.247 sec.\n",
      "INFO: Average train loss: 0.0709.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.519 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.412 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.006 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.593 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0675 dev loss: 0.0313 train acc: 0.9100 dev acc: 0.8600 best train acc: 0.9600 best dev acc: 0.8800 best epoch: 13 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.415 sec.\n",
      "INFO: Average train loss: 0.0713.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.643 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0736 dev loss: 0.0212 train acc: 0.9300 dev acc: 0.8600 best train acc: 0.9500 best dev acc: 0.8900 best epoch: 16 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.412 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.203 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0618 dev loss: 0.0303 train acc: 0.9400 dev acc: 0.8600 best train acc: 0.9500 best dev acc: 0.9000 best epoch: 11 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.354 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0654 dev loss: 0.0283 train acc: 0.9500 dev acc: 0.8800 best train acc: 0.9500 best dev acc: 0.8800 best epoch: 16 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.544 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0509 dev loss: 0.0288 train acc: 0.9500 dev acc: 0.8700 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.738 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.966 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0709 dev loss: 0.0308 train acc: 0.9400 dev acc: 0.8400 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.254 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0713 dev loss: 0.0226 train acc: 0.9500 dev acc: 0.8200 best train acc: 0.9600 best dev acc: 0.8700 best epoch: 14 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.510 sec.\n",
      "INFO: Average train loss: 0.0807.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.322 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.629 sec.\n",
      "INFO: Epoch 17 / 59: train loss: 0.0807 dev loss: 0.0277 train acc: 0.9500 dev acc: 0.8600 best train acc: 0.9500 best dev acc: 0.9000 best epoch: 16 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.550 sec.\n",
      "INFO: Average train loss: 0.0698.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.772 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.240 sec.\n",
      "INFO: Average train loss: 0.0762.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.450 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0698 dev loss: 0.0373 train acc: 0.9400 dev acc: 0.8500 best train acc: 0.9400 best dev acc: 0.8600 best epoch: 16 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.706 sec.\n",
      "INFO: Average train loss: 0.0707.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.471 sec.\n",
      "INFO: Average train loss: 0.0796.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.707 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.742 sec.\n",
      "INFO: Average train loss: 0.0512.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.338 sec.\n",
      "INFO: Average train loss: 0.0545.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.873 sec.\n",
      "INFO: Average train loss: 0.0598.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.063 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.643 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.829 sec.\n",
      "INFO: Found best dev accuracy 0.8800.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.151 sec.\n",
      "INFO: Average train loss: 0.0684.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Saved new best model to output/low/rum/1/best.model.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0762 dev loss: 0.0191 train acc: 0.9600 dev acc: 0.8800 best train acc: 0.9600 best dev acc: 0.8800 best epoch: 18 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.243 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.791 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.582 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.881 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0707 dev loss: 0.0233 train acc: 0.9500 dev acc: 0.8700 best train acc: 0.9600 best dev acc: 0.8800 best epoch: 13 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.685 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0796 dev loss: 0.0228 train acc: 0.9700 dev acc: 0.8600 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.943 sec.\n",
      "INFO: Average train loss: 0.0626.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.233 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.699 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0512 dev loss: 0.0189 train acc: 0.9400 dev acc: 0.8500 best train acc: 0.9500 best dev acc: 0.9000 best epoch: 11 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.854 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0545 dev loss: 0.0171 train acc: 0.9500 dev acc: 0.8800 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.885 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0598 dev loss: 0.0203 train acc: 0.9700 dev acc: 0.8600 best train acc: 0.9700 best dev acc: 0.8800 best epoch: 16 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.975 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.260 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0684 dev loss: 0.0216 train acc: 0.9600 dev acc: 0.8600 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.923 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0626 dev loss: 0.0209 train acc: 0.9500 dev acc: 0.8400 best train acc: 0.9600 best dev acc: 0.8700 best epoch: 14 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.242 sec.\n",
      "INFO: Average train loss: 0.0707.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.290 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.052 sec.\n",
      "INFO: Epoch 18 / 59: train loss: 0.0707 dev loss: 0.0261 train acc: 0.9300 dev acc: 0.8500 best train acc: 0.9500 best dev acc: 0.9000 best epoch: 16 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.498 sec.\n",
      "INFO: Average train loss: 0.0700.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.444 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.524 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0700 dev loss: 0.0268 train acc: 0.9400 dev acc: 0.8100 best train acc: 0.9400 best dev acc: 0.8600 best epoch: 16 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.531 sec.\n",
      "INFO: Average train loss: 0.0556.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.776 sec.\n",
      "INFO: Average train loss: 0.0627.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.541 sec.\n",
      "INFO: Average train loss: 0.0671.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.263 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.821 sec.\n",
      "INFO: Average train loss: 0.0480.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.617 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.098 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.164 sec.\n",
      "INFO: Average train loss: 0.0489.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 311.092 sec.\n",
      "INFO: Average train loss: 0.0516.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.694 sec.\n",
      "INFO: Average train loss: 0.0608.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.416 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.580 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0556 dev loss: 0.0189 train acc: 0.9700 dev acc: 0.8200 best train acc: 0.9700 best dev acc: 0.8800 best epoch: 18 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.336 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0671 dev loss: 0.0230 train acc: 0.9300 dev acc: 0.8600 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.517 sec.\n",
      "INFO: Average train loss: 0.0596.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.637 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0627 dev loss: 0.0243 train acc: 0.9200 dev acc: 0.8800 best train acc: 0.9600 best dev acc: 0.8800 best epoch: 13 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.595 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.576 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.976 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.793 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0480 dev loss: 0.0181 train acc: 0.9400 dev acc: 0.8700 best train acc: 0.9500 best dev acc: 0.9000 best epoch: 11 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.383 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.605 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0489 dev loss: 0.0179 train acc: 0.9400 dev acc: 0.8400 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.148 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0516 dev loss: 0.0208 train acc: 0.9200 dev acc: 0.8400 best train acc: 0.9700 best dev acc: 0.8800 best epoch: 16 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.004 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0608 dev loss: 0.0226 train acc: 0.9000 dev acc: 0.8300 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.813 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0596 dev loss: 0.0179 train acc: 0.9400 dev acc: 0.8600 best train acc: 0.9600 best dev acc: 0.8700 best epoch: 14 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.458 sec.\n",
      "INFO: Average train loss: 0.0552.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.966 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.085 sec.\n",
      "INFO: Epoch 19 / 59: train loss: 0.0552 dev loss: 0.0213 train acc: 0.9100 dev acc: 0.7800 best train acc: 0.9500 best dev acc: 0.9000 best epoch: 16 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.738 sec.\n",
      "INFO: Average train loss: 0.0492.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.359 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.805 sec.\n",
      "INFO: Found best dev accuracy 0.9100.\n",
      "INFO: Saved new best model to output/low/rum/6/best.model.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0492 dev loss: 0.0191 train acc: 0.9800 dev acc: 0.9100 best train acc: 0.9800 best dev acc: 0.9100 best epoch: 20 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.842 sec.\n",
      "INFO: Average train loss: 0.0449.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.852 sec.\n",
      "INFO: Average train loss: 0.0506.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.957 sec.\n",
      "INFO: Average train loss: 0.0564.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.480 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.942 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.481 sec.\n",
      "INFO: Average train loss: 0.0414.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.654 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.967 sec.\n",
      "INFO: Average train loss: 0.0457.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.256 sec.\n",
      "INFO: Average train loss: 0.0635.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.227 sec.\n",
      "INFO: Average train loss: 0.0588.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.382 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0506 dev loss: 0.0171 train acc: 0.9700 dev acc: 0.8700 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.837 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0449 dev loss: 0.0176 train acc: 0.9900 dev acc: 0.8600 best train acc: 0.9900 best dev acc: 0.8800 best epoch: 18 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.837 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.334 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.241 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0564 dev loss: 0.0224 train acc: 0.9600 dev acc: 0.8600 best train acc: 0.9600 best dev acc: 0.8800 best epoch: 13 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.026 sec.\n",
      "INFO: Average train loss: 0.0419.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.606 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.496 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.662 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0414 dev loss: 0.0179 train acc: 0.9800 dev acc: 0.8700 best train acc: 0.9800 best dev acc: 0.9000 best epoch: 11 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.659 sec.\n",
      "INFO: Found best dev accuracy 0.8900.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.495 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.758 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0635 dev loss: 0.0162 train acc: 0.9600 dev acc: 0.8600 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0457 dev loss: 0.0183 train acc: 0.9600 dev acc: 0.8900 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 20 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.638 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0588 dev loss: 0.0599 train acc: 0.9400 dev acc: 0.7800 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.011 sec.\n",
      "INFO: Average train loss: 0.0587.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.916 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0419 dev loss: 0.0171 train acc: 0.9900 dev acc: 0.8600 best train acc: 0.9900 best dev acc: 0.8700 best epoch: 14 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.282 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.985 sec.\n",
      "INFO: Epoch 20 / 59: train loss: 0.0587 dev loss: 0.0186 train acc: 0.9700 dev acc: 0.8600 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 16 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.282 sec.\n",
      "INFO: Average train loss: 0.0595.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.504 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.347 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0595 dev loss: 0.0177 train acc: 0.9800 dev acc: 0.9000 best train acc: 0.9800 best dev acc: 0.9100 best epoch: 20 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.095 sec.\n",
      "INFO: Average train loss: 0.0517.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.844 sec.\n",
      "INFO: Average train loss: 0.0471.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.965 sec.\n",
      "INFO: Average train loss: 0.0476.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.009 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.348 sec.\n",
      "INFO: Average train loss: 0.0469.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.845 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.260 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.363 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0517 dev loss: 0.0146 train acc: 0.9700 dev acc: 0.8700 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 308.231 sec.\n",
      "INFO: Average train loss: 0.0655.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.446 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.701 sec.\n",
      "INFO: Average train loss: 0.0529.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.570 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0471 dev loss: 0.0133 train acc: 0.9700 dev acc: 0.8800 best train acc: 0.9900 best dev acc: 0.8800 best epoch: 18 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 312.767 sec.\n",
      "INFO: Average train loss: 0.0524.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.593 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0476 dev loss: 0.0201 train acc: 0.9700 dev acc: 0.8800 best train acc: 0.9700 best dev acc: 0.8800 best epoch: 13 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.239 sec.\n",
      "INFO: Average train loss: 0.0439.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.213 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.463 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0469 dev loss: 0.0157 train acc: 0.9800 dev acc: 0.8800 best train acc: 0.9800 best dev acc: 0.9000 best epoch: 11 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.340 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.393 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.716 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.862 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0655 dev loss: 0.0166 train acc: 0.9600 dev acc: 0.8800 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.695 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0524 dev loss: 0.0131 train acc: 0.9600 dev acc: 0.8800 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.893 sec.\n",
      "INFO: Found best dev accuracy 0.9000.\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0529 dev loss: 0.0137 train acc: 0.9700 dev acc: 0.9000 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 21 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.566 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0439 dev loss: 0.0135 train acc: 0.9700 dev acc: 0.8600 best train acc: 0.9900 best dev acc: 0.8700 best epoch: 14 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 310.998 sec.\n",
      "INFO: Average train loss: 0.0512.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.206 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.731 sec.\n",
      "INFO: Epoch 21 / 59: train loss: 0.0512 dev loss: 0.0142 train acc: 0.9500 dev acc: 0.8700 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 16 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 299.380 sec.\n",
      "INFO: Average train loss: 0.0437.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.176 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.780 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0437 dev loss: 0.0182 train acc: 0.9400 dev acc: 0.8500 best train acc: 0.9800 best dev acc: 0.9100 best epoch: 20 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.857 sec.\n",
      "INFO: Average train loss: 0.0470.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.720 sec.\n",
      "INFO: Average train loss: 0.0415.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.026 sec.\n",
      "INFO: Average train loss: 0.0516.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.765 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.059 sec.\n",
      "INFO: Average train loss: 0.0324.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.260 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.652 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.610 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0470 dev loss: 0.0118 train acc: 0.9600 dev acc: 0.8800 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.585 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.621 sec.\n",
      "INFO: Average train loss: 0.0497.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.842 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0415 dev loss: 0.0118 train acc: 0.9600 dev acc: 0.8600 best train acc: 0.9900 best dev acc: 0.8800 best epoch: 18 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 307.808 sec.\n",
      "INFO: Average train loss: 0.0549.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.037 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0516 dev loss: 0.0197 train acc: 0.9600 dev acc: 0.8800 best train acc: 0.9700 best dev acc: 0.8800 best epoch: 13 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.646 sec.\n",
      "INFO: Average train loss: 0.0411.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.734 sec.\n",
      "INFO: Average train loss: 0.0323.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.212 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0324 dev loss: 0.0145 train acc: 0.9600 dev acc: 0.8600 best train acc: 0.9800 best dev acc: 0.9000 best epoch: 11 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.756 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.457 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.870 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.167 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.117 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0497 dev loss: 0.0139 train acc: 0.9600 dev acc: 0.8700 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.775 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0549 dev loss: 0.0148 train acc: 0.9600 dev acc: 0.8700 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.627 sec.\n",
      "INFO: Average train loss: 0.0520.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.379 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0323 dev loss: 0.0129 train acc: 0.9700 dev acc: 0.8700 best train acc: 0.9900 best dev acc: 0.8700 best epoch: 14 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.247 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0411 dev loss: 0.0131 train acc: 0.9600 dev acc: 0.8700 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 21 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.603 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.587 sec.\n",
      "INFO: Epoch 22 / 59: train loss: 0.0520 dev loss: 0.0170 train acc: 0.9500 dev acc: 0.8500 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 16 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.459 sec.\n",
      "INFO: Average train loss: 0.0410.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.430 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.822 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0410 dev loss: 0.0153 train acc: 0.9700 dev acc: 0.9000 best train acc: 0.9800 best dev acc: 0.9100 best epoch: 20 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 303.840 sec.\n",
      "INFO: Average train loss: 0.0423.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 301.335 sec.\n",
      "INFO: Average train loss: 0.0432.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.968 sec.\n",
      "INFO: Average train loss: 0.0284.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.761 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.448 sec.\n",
      "INFO: Average train loss: 0.0365.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.476 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.530 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.003 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0423 dev loss: 0.0120 train acc: 0.9600 dev acc: 0.8800 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 302.358 sec.\n",
      "INFO: Average train loss: 0.0344.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.999 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 305.287 sec.\n",
      "INFO: Average train loss: 0.0415.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.403 sec.\n",
      "INFO: Found best dev accuracy 0.9000.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 304.226 sec.\n",
      "INFO: Average train loss: 0.0319.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 12.595 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0284 dev loss: 0.0135 train acc: 0.9400 dev acc: 0.8400 best train acc: 0.9900 best dev acc: 0.8800 best epoch: 18 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: Saved new best model to output/low/rum/5/best.model.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0432 dev loss: 0.0159 train acc: 0.9600 dev acc: 0.9000 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 23 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.427 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 309.776 sec.\n",
      "INFO: Average train loss: 0.0362.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.920 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.288 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0365 dev loss: 0.0144 train acc: 0.9900 dev acc: 0.8400 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 11 patience: 12 / 11\n",
      "INFO: Out of patience after 24 epochs.\n",
      "|| Time: 2:11:42\n",
      "INFO: Finished training.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.119 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.238 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0344 dev loss: 0.0125 train acc: 0.9600 dev acc: 0.8700 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 14 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.626 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.021 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0415 dev loss: 0.0136 train acc: 0.9600 dev acc: 0.8500 best train acc: 0.9600 best dev acc: 0.8900 best epoch: 11 patience: 12 / 11\n",
      "INFO: Out of patience after 24 epochs.\n",
      "|| Time: 2:11:44\n",
      "INFO: Finished training.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.623 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0319 dev loss: 0.0141 train acc: 0.9700 dev acc: 0.8500 best train acc: 0.9900 best dev acc: 0.8700 best epoch: 14 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 306.973 sec.\n",
      "INFO: Average train loss: 0.0522.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.762 sec.\n",
      "INFO: Dev set accuracy: 0.9000.\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.512 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0362 dev loss: 0.0150 train acc: 0.9600 dev acc: 0.8600 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 21 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.574 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.811 sec.\n",
      "INFO: Dev set accuracy: 0.8900.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.949 sec.\n",
      "INFO: Epoch 23 / 59: train loss: 0.0522 dev loss: 0.0148 train acc: 0.9600 dev acc: 0.8800 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 16 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 37.855 sec.\n",
      "INFO: Dev set accuracy: 0.8600.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.578 sec.\n",
      "INFO: Test set accuracy: 0.8600.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 40.755 sec.\n",
      "INFO: Dev set accuracy: 0.8900.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.276 sec.\n",
      "INFO: Test set accuracy: 0.8300.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 38.302 sec.\n",
      "INFO: Test set accuracy: 0.8700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 38.370 sec.\n",
      "INFO: Test set accuracy: 0.8300.\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 277.528 sec.\n",
      "INFO: Average train loss: 0.0355.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.129 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.849 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0355 dev loss: 0.0188 train acc: 0.9700 dev acc: 0.8800 best train acc: 0.9800 best dev acc: 0.9100 best epoch: 20 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 271.689 sec.\n",
      "INFO: Average train loss: 0.0392.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 269.057 sec.\n",
      "INFO: Average train loss: 0.0413.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.311 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 272.433 sec.\n",
      "INFO: Average train loss: 0.0427.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.997 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.676 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.936 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0392 dev loss: 0.0141 train acc: 0.9700 dev acc: 0.8700 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 269.281 sec.\n",
      "INFO: Average train loss: 0.0318.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 267.808 sec.\n",
      "INFO: Average train loss: 0.0299.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.469 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0427 dev loss: 0.0177 train acc: 1.0000 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.8800 best epoch: 18 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.085 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0413 dev loss: 0.0171 train acc: 0.9900 dev acc: 0.8500 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 23 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.572 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.351 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 266.048 sec.\n",
      "INFO: Average train loss: 0.0388.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.872 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0318 dev loss: 0.0120 train acc: 0.9900 dev acc: 0.8900 best train acc: 0.9900 best dev acc: 0.8900 best epoch: 14 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.175 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0299 dev loss: 0.0128 train acc: 1.0000 dev acc: 0.8400 best train acc: 1.0000 best dev acc: 0.8700 best epoch: 14 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.698 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 261.329 sec.\n",
      "INFO: Average train loss: 0.0327.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.779 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0388 dev loss: 0.0160 train acc: 0.9800 dev acc: 0.8500 best train acc: 0.9800 best dev acc: 0.9000 best epoch: 21 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.276 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.207 sec.\n",
      "INFO: Epoch 24 / 59: train loss: 0.0327 dev loss: 0.0155 train acc: 0.9700 dev acc: 0.8800 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 16 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 235.654 sec.\n",
      "INFO: Average train loss: 0.0385.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.734 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.981 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0385 dev loss: 0.0134 train acc: 0.9600 dev acc: 0.8500 best train acc: 0.9800 best dev acc: 0.9100 best epoch: 20 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 239.937 sec.\n",
      "INFO: Average train loss: 0.0328.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.801 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 239.873 sec.\n",
      "INFO: Average train loss: 0.0332.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 241.001 sec.\n",
      "INFO: Average train loss: 0.0269.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.057 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0328 dev loss: 0.0167 train acc: 0.9600 dev acc: 0.8700 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.871 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.402 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 241.303 sec.\n",
      "INFO: Average train loss: 0.0227.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 241.270 sec.\n",
      "INFO: Average train loss: 0.0210.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.905 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0332 dev loss: 0.0178 train acc: 0.9800 dev acc: 0.8600 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 23 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.395 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0269 dev loss: 0.0135 train acc: 0.9800 dev acc: 0.8600 best train acc: 1.0000 best dev acc: 0.8800 best epoch: 18 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.139 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.716 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 241.795 sec.\n",
      "INFO: Average train loss: 0.0317.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.968 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0227 dev loss: 0.0131 train acc: 0.9800 dev acc: 0.8600 best train acc: 0.9900 best dev acc: 0.8900 best epoch: 14 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.460 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0210 dev loss: 0.0094 train acc: 0.9800 dev acc: 0.8400 best train acc: 1.0000 best dev acc: 0.8700 best epoch: 14 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.960 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 243.488 sec.\n",
      "INFO: Average train loss: 0.0417.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.768 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0317 dev loss: 0.0146 train acc: 0.9700 dev acc: 0.8500 best train acc: 0.9800 best dev acc: 0.9000 best epoch: 21 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.923 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.842 sec.\n",
      "INFO: Epoch 25 / 59: train loss: 0.0417 dev loss: 0.0131 train acc: 0.9600 dev acc: 0.8500 best train acc: 0.9700 best dev acc: 0.9000 best epoch: 16 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 240.100 sec.\n",
      "INFO: Average train loss: 0.0336.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.780 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.885 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0336 dev loss: 0.0125 train acc: 0.9600 dev acc: 0.8500 best train acc: 0.9800 best dev acc: 0.9100 best epoch: 20 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 244.329 sec.\n",
      "INFO: Average train loss: 0.0346.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.445 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 242.070 sec.\n",
      "INFO: Average train loss: 0.0275.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 245.401 sec.\n",
      "INFO: Average train loss: 0.0326.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.125 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0346 dev loss: 0.0147 train acc: 0.9700 dev acc: 0.8800 best train acc: 0.9700 best dev acc: 0.8900 best epoch: 16 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.627 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.243 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 242.344 sec.\n",
      "INFO: Average train loss: 0.0263.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.493 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0275 dev loss: 0.0167 train acc: 0.9900 dev acc: 0.8600 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 23 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 242.874 sec.\n",
      "INFO: Average train loss: 0.0202.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.085 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0326 dev loss: 0.0135 train acc: 0.9900 dev acc: 0.8600 best train acc: 1.0000 best dev acc: 0.8800 best epoch: 18 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.318 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.425 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 243.337 sec.\n",
      "INFO: Average train loss: 0.0277.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.416 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0263 dev loss: 0.0115 train acc: 0.9900 dev acc: 0.8800 best train acc: 0.9900 best dev acc: 0.8900 best epoch: 14 patience: 12 / 11\n",
      "INFO: Out of patience after 27 epochs.\n",
      "|| Time: 2:25:05\n",
      "INFO: Finished training.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.512 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0202 dev loss: 0.0092 train acc: 0.9900 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.8700 best epoch: 14 patience: 12 / 11\n",
      "INFO: Out of patience after 27 epochs.\n",
      "|| Time: 2:24:45\n",
      "INFO: Finished training.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.839 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 243.847 sec.\n",
      "INFO: Average train loss: 0.0347.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.328 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0277 dev loss: 0.0136 train acc: 0.9700 dev acc: 0.8900 best train acc: 0.9800 best dev acc: 0.9000 best epoch: 21 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.588 sec.\n",
      "INFO: Dev set accuracy: 0.8900.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 9.074 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 10.683 sec.\n",
      "INFO: Dev set accuracy: 0.8700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 8.449 sec.\n",
      "INFO: Epoch 26 / 59: train loss: 0.0347 dev loss: 0.0120 train acc: 0.9900 dev acc: 0.8800 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 16 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 32.072 sec.\n",
      "INFO: Dev set accuracy: 0.8800.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 29.345 sec.\n",
      "INFO: Dev set accuracy: 0.8600.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.707 sec.\n",
      "INFO: Test set accuracy: 0.8700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.029 sec.\n",
      "INFO: Test set accuracy: 0.8700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 29.958 sec.\n",
      "INFO: Test set accuracy: 0.8700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 29.546 sec.\n",
      "INFO: Test set accuracy: 0.8800.\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 213.358 sec.\n",
      "INFO: Average train loss: 0.0296.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.748 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.586 sec.\n",
      "INFO: Epoch 27 / 59: train loss: 0.0296 dev loss: 0.0140 train acc: 1.0000 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 20 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 208.952 sec.\n",
      "INFO: Average train loss: 0.0255.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 206.731 sec.\n",
      "INFO: Average train loss: 0.0282.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.205 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 203.841 sec.\n",
      "INFO: Average train loss: 0.0319.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.706 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.412 sec.\n",
      "INFO: Epoch 27 / 59: train loss: 0.0255 dev loss: 0.0102 train acc: 1.0000 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.8900 best epoch: 16 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.637 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.743 sec.\n",
      "INFO: Epoch 27 / 59: train loss: 0.0282 dev loss: 0.0152 train acc: 0.9800 dev acc: 0.8700 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 23 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.243 sec.\n",
      "INFO: Epoch 27 / 59: train loss: 0.0319 dev loss: 0.0101 train acc: 0.9900 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.8800 best epoch: 18 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 198.407 sec.\n",
      "INFO: Average train loss: 0.0235.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.705 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 192.719 sec.\n",
      "INFO: Average train loss: 0.0237.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.835 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.098 sec.\n",
      "INFO: Epoch 27 / 59: train loss: 0.0235 dev loss: 0.0143 train acc: 0.9900 dev acc: 0.8700 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 21 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.523 sec.\n",
      "INFO: Epoch 27 / 59: train loss: 0.0237 dev loss: 0.0140 train acc: 0.9900 dev acc: 0.8400 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 16 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 182.097 sec.\n",
      "INFO: Average train loss: 0.0189.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.918 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.225 sec.\n",
      "INFO: Epoch 28 / 59: train loss: 0.0189 dev loss: 0.0128 train acc: 0.9600 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 20 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 177.607 sec.\n",
      "INFO: Average train loss: 0.0260.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 176.250 sec.\n",
      "INFO: Average train loss: 0.0201.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.077 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.469 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.325 sec.\n",
      "INFO: Epoch 28 / 59: train loss: 0.0260 dev loss: 0.0175 train acc: 0.9700 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.8900 best epoch: 16 patience: 12 / 11\n",
      "INFO: Out of patience after 29 epochs.\n",
      "|| Time: 2:31:25\n",
      "INFO: Finished training.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 180.602 sec.\n",
      "INFO: Average train loss: 0.0200.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.539 sec.\n",
      "INFO: Epoch 28 / 59: train loss: 0.0201 dev loss: 0.0146 train acc: 0.9900 dev acc: 0.8700 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 23 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.644 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.720 sec.\n",
      "INFO: Dev set accuracy: 0.8900.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.951 sec.\n",
      "INFO: Epoch 28 / 59: train loss: 0.0200 dev loss: 0.0112 train acc: 0.9800 dev acc: 0.8600 best train acc: 1.0000 best dev acc: 0.8800 best epoch: 18 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 179.354 sec.\n",
      "INFO: Average train loss: 0.0168.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.269 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 178.745 sec.\n",
      "INFO: Average train loss: 0.0292.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.610 sec.\n",
      "INFO: Epoch 28 / 59: train loss: 0.0168 dev loss: 0.0151 train acc: 0.9700 dev acc: 0.8800 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 21 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.499 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 22.645 sec.\n",
      "INFO: Dev set accuracy: 0.9000.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.931 sec.\n",
      "INFO: Epoch 28 / 59: train loss: 0.0292 dev loss: 0.0203 train acc: 0.9800 dev acc: 0.8700 best train acc: 0.9900 best dev acc: 0.9000 best epoch: 16 patience: 12 / 11\n",
      "INFO: Out of patience after 29 epochs.\n",
      "|| Time: 2:32:10\n",
      "INFO: Finished training.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.797 sec.\n",
      "INFO: Test set accuracy: 0.8900.\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.090 sec.\n",
      "INFO: Dev set accuracy: 0.9000.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 21.072 sec.\n",
      "INFO: Test set accuracy: 0.9000.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 20.111 sec.\n",
      "INFO: Dev set accuracy: 0.8900.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.901 sec.\n",
      "INFO: Test set accuracy: 0.8800.\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 15.991 sec.\n",
      "INFO: Test set accuracy: 0.8900.\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 149.048 sec.\n",
      "INFO: Average train loss: 0.0213.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.940 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.049 sec.\n",
      "INFO: Epoch 29 / 59: train loss: 0.0213 dev loss: 0.0119 train acc: 1.0000 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 20 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 144.006 sec.\n",
      "INFO: Average train loss: 0.0150.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.724 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 144.263 sec.\n",
      "INFO: Average train loss: 0.0189.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.829 sec.\n",
      "INFO: Epoch 29 / 59: train loss: 0.0150 dev loss: 0.0120 train acc: 1.0000 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9000 best epoch: 23 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.579 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.650 sec.\n",
      "INFO: Epoch 29 / 59: train loss: 0.0189 dev loss: 0.0100 train acc: 0.9900 dev acc: 0.8600 best train acc: 1.0000 best dev acc: 0.8800 best epoch: 18 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 133.291 sec.\n",
      "INFO: Average train loss: 0.0239.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.596 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.508 sec.\n",
      "INFO: Found best dev accuracy 0.9100.\n",
      "INFO: Saved new best model to output/low/rum/7/best.model.\n",
      "INFO: Epoch 29 / 59: train loss: 0.0239 dev loss: 0.0109 train acc: 0.9900 dev acc: 0.9100 best train acc: 0.9900 best dev acc: 0.9100 best epoch: 29 patience: 0 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 114.308 sec.\n",
      "INFO: Average train loss: 0.0152.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.648 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.935 sec.\n",
      "INFO: Epoch 30 / 59: train loss: 0.0152 dev loss: 0.0101 train acc: 1.0000 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 20 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 113.427 sec.\n",
      "INFO: Average train loss: 0.0120.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.921 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 114.014 sec.\n",
      "INFO: Average train loss: 0.0117.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.603 sec.\n",
      "INFO: Epoch 30 / 59: train loss: 0.0120 dev loss: 0.0115 train acc: 0.9900 dev acc: 0.8600 best train acc: 1.0000 best dev acc: 0.9000 best epoch: 23 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 5.912 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.305 sec.\n",
      "INFO: Epoch 30 / 59: train loss: 0.0117 dev loss: 0.0096 train acc: 1.0000 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.8800 best epoch: 18 patience: 12 / 11\n",
      "INFO: Out of patience after 31 epochs.\n",
      "|| Time: 2:36:09\n",
      "INFO: Finished training.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 114.954 sec.\n",
      "INFO: Average train loss: 0.0232.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.944 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.075 sec.\n",
      "INFO: Dev set accuracy: 0.8800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.470 sec.\n",
      "INFO: Epoch 30 / 59: train loss: 0.0232 dev loss: 0.0127 train acc: 1.0000 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 1 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 14.180 sec.\n",
      "INFO: Dev set accuracy: 0.8800.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 6.580 sec.\n",
      "INFO: Test set accuracy: 0.8800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 11.911 sec.\n",
      "INFO: Test set accuracy: 0.8800.\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 101.804 sec.\n",
      "INFO: Average train loss: 0.0132.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.095 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.465 sec.\n",
      "INFO: Epoch 31 / 59: train loss: 0.0132 dev loss: 0.0092 train acc: 1.0000 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 20 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 95.060 sec.\n",
      "INFO: Average train loss: 0.0154.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.905 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.450 sec.\n",
      "INFO: Epoch 31 / 59: train loss: 0.0154 dev loss: 0.0108 train acc: 1.0000 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9000 best epoch: 23 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 93.108 sec.\n",
      "INFO: Average train loss: 0.0143.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.267 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.868 sec.\n",
      "INFO: Epoch 31 / 59: train loss: 0.0143 dev loss: 0.0110 train acc: 1.0000 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 2 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 83.960 sec.\n",
      "INFO: Average train loss: 0.0155.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.089 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.085 sec.\n",
      "INFO: Epoch 32 / 59: train loss: 0.0155 dev loss: 0.0081 train acc: 0.9900 dev acc: 0.8600 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 20 patience: 12 / 11\n",
      "INFO: Out of patience after 33 epochs.\n",
      "|| Time: 2:39:24\n",
      "INFO: Finished training.\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.769 sec.\n",
      "INFO: Dev set accuracy: 0.9100.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 84.987 sec.\n",
      "INFO: Average train loss: 0.0114.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.290 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.068 sec.\n",
      "INFO: Epoch 32 / 59: train loss: 0.0114 dev loss: 0.0096 train acc: 0.9900 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9000 best epoch: 23 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.543 sec.\n",
      "INFO: Dev set accuracy: 0.9100.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.843 sec.\n",
      "INFO: Test set accuracy: 0.8700.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 85.314 sec.\n",
      "INFO: Average train loss: 0.0137.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.796 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 7.972 sec.\n",
      "INFO: Test set accuracy: 0.8700.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.962 sec.\n",
      "INFO: Epoch 32 / 59: train loss: 0.0137 dev loss: 0.0081 train acc: 0.9900 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 3 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 58.076 sec.\n",
      "INFO: Average train loss: 0.0118.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.282 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.911 sec.\n",
      "INFO: Epoch 33 / 59: train loss: 0.0118 dev loss: 0.0120 train acc: 0.9800 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9000 best epoch: 23 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 53.727 sec.\n",
      "INFO: Average train loss: 0.0131.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.192 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.276 sec.\n",
      "INFO: Epoch 33 / 59: train loss: 0.0131 dev loss: 0.0091 train acc: 0.9900 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 4 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 51.507 sec.\n",
      "INFO: Average train loss: 0.0098.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.814 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.916 sec.\n",
      "INFO: Epoch 34 / 59: train loss: 0.0098 dev loss: 0.0094 train acc: 1.0000 dev acc: 0.8600 best train acc: 1.0000 best dev acc: 0.9000 best epoch: 23 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 54.394 sec.\n",
      "INFO: Average train loss: 0.0082.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.572 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.408 sec.\n",
      "INFO: Epoch 34 / 59: train loss: 0.0082 dev loss: 0.0132 train acc: 1.0000 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 5 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 55.754 sec.\n",
      "INFO: Average train loss: 0.0070.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.230 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.280 sec.\n",
      "INFO: Epoch 35 / 59: train loss: 0.0070 dev loss: 0.0092 train acc: 0.9900 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9000 best epoch: 23 patience: 12 / 11\n",
      "INFO: Out of patience after 36 epochs.\n",
      "|| Time: 2:42:27\n",
      "INFO: Finished training.\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.261 sec.\n",
      "INFO: Dev set accuracy: 0.9000.\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 53.545 sec.\n",
      "INFO: Average train loss: 0.0079.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.277 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.105 sec.\n",
      "INFO: Dev set accuracy: 0.9000.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.468 sec.\n",
      "INFO: Epoch 35 / 59: train loss: 0.0079 dev loss: 0.0094 train acc: 0.9900 dev acc: 0.8800 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 6 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.954 sec.\n",
      "INFO: Test set accuracy: 0.9100.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 4.766 sec.\n",
      "INFO: Test set accuracy: 0.9100.\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 33.018 sec.\n",
      "INFO: Average train loss: 0.0085.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.714 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.765 sec.\n",
      "INFO: Epoch 36 / 59: train loss: 0.0085 dev loss: 0.0075 train acc: 0.9900 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 7 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 29.447 sec.\n",
      "INFO: Average train loss: 0.0053.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.724 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.774 sec.\n",
      "INFO: Epoch 37 / 59: train loss: 0.0053 dev loss: 0.0053 train acc: 0.9700 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 8 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 32.938 sec.\n",
      "INFO: Average train loss: 0.0114.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.966 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.140 sec.\n",
      "INFO: Epoch 38 / 59: train loss: 0.0114 dev loss: 0.0063 train acc: 1.0000 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 9 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 31.314 sec.\n",
      "INFO: Average train loss: 0.0083.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.015 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.180 sec.\n",
      "INFO: Epoch 39 / 59: train loss: 0.0083 dev loss: 0.0064 train acc: 1.0000 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 10 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 29.278 sec.\n",
      "INFO: Average train loss: 0.0056.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.736 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.782 sec.\n",
      "INFO: Epoch 40 / 59: train loss: 0.0056 dev loss: 0.0082 train acc: 1.0000 dev acc: 0.8700 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 11 / 11\n",
      "INFO: Training...\n",
      "INFO: \t\t...100 batches\n",
      "INFO: \t\t...160 batches\n",
      "INFO: \t...finished in 28.963 sec.\n",
      "INFO: Average train loss: 0.0058.\n",
      "INFO: Evaluating on training data subset...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.719 sec.\n",
      "INFO: Evaluating on development data...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.772 sec.\n",
      "INFO: Epoch 41 / 59: train loss: 0.0058 dev loss: 0.0059 train acc: 1.0000 dev acc: 0.8500 best train acc: 1.0000 best dev acc: 0.9100 best epoch: 29 patience: 12 / 11\n",
      "INFO: Out of patience after 42 epochs.\n",
      "|| Time: 2:45:41\n",
      "INFO: Finished training.\n",
      "INFO: Evaluating best model on dev data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 1.089 sec.\n",
      "INFO: Dev set accuracy: 0.9100.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 3.064 sec.\n",
      "INFO: Dev set accuracy: 0.9000.\n",
      "INFO: Evaluating best model on test data using beam search (beam width 4)...\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 0.736 sec.\n",
      "INFO: Test set accuracy: 0.8800.\n",
      "INFO: \t\t...100 samples\n",
      "INFO: \t...finished in 2.346 sec.\n",
      "INFO: Test set accuracy: 0.8800.\n",
      "INFO: Producing a majority-vote prediction file from 10 system files.\n",
      "INFO: Dev set accuracy: 0.9000.\n",
      "INFO: Producing a majority-vote prediction file from 10 system files.\n",
      "INFO: Test set accuracy: 0.9100.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate 2021-task\n",
    "cd 2021-task1/baseline\n",
    "pip install -r requirements.txt\n",
    "pip install .\n",
    "\n",
    "# Modify the script to set the target language to Romanian\n",
    "sed -i.bak '17 s/\"\"/\"rum\"/' sweep\n",
    "\n",
    "# Modify the script to only train the model and skip evaluation\n",
    "sed -i '107 s/^/#/' sweep\n",
    "\n",
    "# Execute the script to start training\n",
    "./sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlJL4Dp5Xlmr",
    "outputId": "cef8b973-96a0-475c-be1e-db1ba2f03a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev low:\n",
      "output/low/rum/ensemble/dev_10ensemble.tsv WER:\t10.00\n",
      "Macro-average WER:\t10.00\n",
      "\n",
      "test low:\n",
      "output/low/rum/ensemble/test_10ensemble.tsv WER:\t 9.00\n",
      "Macro-average WER:\t 9.00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate 2021-task\n",
    "cd 2021-task1/baseline\n",
    "\n",
    "# Adjust the script that it only evaluate our target language instead of all, which causes error\n",
    "sed -i \\\n",
    "    -e '81 s/\"\\*\"/rum/' \\\n",
    "    -e '97 s/\"\\*\"/rum/' \\\n",
    "    -e '80 s/ medium high//' \\\n",
    "    -e '94 s/ medium high//' sweep\n",
    "\n",
    "# Now only evaluate\n",
    "sed -i \\\n",
    "    -e '104 s/^/#/' \\\n",
    "    -e '105 s/^/#/' \\\n",
    "    -e '106 s/^/#/' \\\n",
    "    -e '107 s/^#//' sweep\n",
    "./sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ebxp0fN_ea6w"
   },
   "source": [
    "# Baseline results for Romanian are given:\n",
    "\n",
    "||WER (dev)|WER (test)|\n",
    "|-|-|-|\n",
    "|rum|10.00|10.00|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSt7j43Zf33q"
   },
   "source": [
    "# Reproduced results for Romanian are:\n",
    "\n",
    "||WER (dev)|WER (test)|\n",
    "|-|-|-|\n",
    "|rum|10.00|9.00|\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
