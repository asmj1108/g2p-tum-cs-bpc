{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDq3n34jihQe",
        "outputId": "2caa53b9-6448-4bcd-d07d-4a2f172350f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:13\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sigmorphon/2020.git\n",
        "!conda env create -f 2020/task1/environment.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zbSeuhKjfol",
        "outputId": "83e8f550-2959-4bbd-8032-72801148ecb8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '2020' already exists and is not an empty directory.\n",
            "Channels:\n",
            " - conda-forge\n",
            " - defaults\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pytorch-1.6.0        | 425.8 MB  | :   0% 0/1 [00:00<?, ?it/s]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.0        | 7.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk2-2.24.32         | 7.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "graphviz-2.42.3      | 7.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-1.19.2         | 5.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-20.1.4   | 3.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.66.3       | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.24.1 | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pynini-2.1.3         | 2.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :   1% 0.012808609745668723/1 [00:00<00:07,  7.83s/it]\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :   1% 0.011041154951755488/1 [00:00<00:08,  9.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :   1% 0.00804465222919985/1 [00:00<00:12, 12.44s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :   0% 0.0038192235843655053/1 [00:00<00:26, 26.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :   3% 0.02610643722467896/1 [00:00<00:07,  7.66s/it] \u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :   3% 0.029020740610898304/1 [00:00<00:06,  6.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :   3% 0.027177879152702193/1 [00:00<00:06,  6.87s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :   5% 0.04774029480456882/1 [00:00<00:03,  3.66s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :   4% 0.04078296922492437/1 [00:00<00:06,  7.26s/it]\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :   5% 0.05181915625115218/1 [00:00<00:04,  5.22s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :   5% 0.05062037707389538/1 [00:00<00:05,  5.57s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  10% 0.09974049283785301/1 [00:00<00:02,  2.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :   8% 0.07660538203841658/1 [00:00<00:04,  4.68s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :   6% 0.0588395510191657/1 [00:00<00:06,  6.54s/it] \u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :   7% 0.06986698051438718/1 [00:00<00:05,  5.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  14% 0.14468981656153934/1 [00:00<00:02,  2.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  10% 0.101753979547717/1 [00:00<00:03,  4.40s/it]  \u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :   8% 0.07569532564975058/1 [00:00<00:05,  6.32s/it]\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :   9% 0.08869124469442932/1 [00:00<00:04,  5.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   0% 3.669179428264493e-05/1 [00:00<4:24:24, 15865.15s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :   9% 0.09339611272883444/1 [00:00<00:05,  6.08s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  24% 0.24193312474807643/1 [00:00<00:01,  2.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  11% 0.10848085575549928/1 [00:00<00:04,  5.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   0% 0.000550376914239674/1 [00:00<15:51, 952.35s/it]     \n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  13% 0.12851180353682617/1 [00:00<00:04,  5.25s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  15% 0.1513264311222458/1 [00:00<00:03,  4.29s/it] \u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  11% 0.10985161830486717/1 [00:00<00:05,  6.28s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  29% 0.2871762349013293/1 [00:00<00:01,  2.30s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  15% 0.14872375385834577/1 [00:00<00:04,  5.16s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  13% 0.1258179061475584/1 [00:00<00:05,  6.28s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  33% 0.33491652970589814/1 [00:00<00:01,  2.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   0% 0.0009172948570661233/1 [00:00<11:45, 706.19s/it]\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  38% 0.38280371772525024/1 [00:00<00:01,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  20% 0.19771001154285756/1 [00:00<00:03,  4.41s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  14% 0.1417841939902496/1 [00:00<00:05,  6.50s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   0% 0.003118802514024819/1 [00:00<02:53, 173.59s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  22% 0.220756853064349/1 [00:01<00:03,  4.39s/it]  \u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  16% 0.15726126409959934/1 [00:01<00:05,  6.49s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   1% 0.005760611702375254/1 [00:01<01:34, 94.76s/it] \n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  19% 0.18588960877791616/1 [00:01<00:04,  5.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  48% 0.4779905209048213/1 [00:01<00:01,  2.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   1% 0.011447839816185218/1 [00:01<00:44, 45.28s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  20% 0.20459320459782981/1 [00:01<00:04,  5.75s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  17% 0.17269385986955435/1 [00:01<00:06,  7.32s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   2% 0.017575369461386922/1 [00:01<00:30, 30.92s/it]\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  52% 0.5242618835615572/1 [00:01<00:01,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  19% 0.1867477511182742/1 [00:01<00:06,  7.47s/it] \u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   3% 0.026968468797744026/1 [00:01<00:19, 20.41s/it]\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  57% 0.5667140226339277/1 [00:01<00:01,  2.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  29% 0.28620118606405587/1 [00:01<00:03,  5.05s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  24% 0.23844067961386714/1 [00:01<00:04,  6.44s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :   4% 0.036324876339818485/1 [00:01<00:15, 16.30s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  31% 0.30736369463095997/1 [00:01<00:03,  4.98s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  61% 0.6082848024175984/1 [00:01<00:01,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  22% 0.21792426303394702/1 [00:01<00:05,  7.27s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   4% 0.04355315981349953/1 [00:01<00:14, 15.53s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  33% 0.3275840367205704/1 [00:01<00:03,  5.08s/it] \u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  23% 0.23202262862206158/1 [00:01<00:05,  7.58s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  65% 0.64677082469082/1 [00:01<00:00,  2.80s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   6% 0.05507438321825004/1 [00:01<00:11, 12.65s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  35% 0.3473695327437376/1 [00:01<00:03,  5.07s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  69% 0.6886353909040572/1 [00:01<00:00,  2.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  25% 0.24549835345865054/1 [00:01<00:05,  7.72s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   6% 0.06421063999462863/1 [00:01<00:11, 12.12s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  37% 0.3671550287669048/1 [00:01<00:03,  5.09s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  73% 0.7321157824799107/1 [00:01<00:00,  2.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   8% 0.07617216493077088/1 [00:01<00:09, 10.73s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  26% 0.25861828358008204/1 [00:01<00:06,  8.26s/it]\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  39% 0.3868680504456648/1 [00:01<00:03,  5.18s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  77% 0.7738334554783647/1 [00:01<00:00,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :   9% 0.0857487232385412/1 [00:01<00:09, 10.75s/it] \n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  27% 0.2709376755924092/1 [00:02<00:06,  9.00s/it] \u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  41% 0.40861035376782656/1 [00:02<00:03,  5.21s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  81% 0.8145228759733356/1 [00:02<00:00,  2.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  10% 0.09543535692915947/1 [00:02<00:09, 10.89s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  28% 0.2833904906229205/1 [00:02<00:06,  8.73s/it]\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  43% 0.43180214397813244/1 [00:02<00:02,  4.93s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  85% 0.8546247236091734/1 [00:02<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  11% 0.10658966239108353/1 [00:02<00:09, 10.26s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  30% 0.29508724188372215/1 [00:02<00:06,  8.83s/it]\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  45% 0.45223990910096445/1 [00:02<00:02,  4.93s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | :  89% 0.8936983187415283/1 [00:02<00:00,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  12% 0.11645975505311501/1 [00:02<00:09, 10.84s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  31% 0.3065616214475504/1 [00:02<00:06,  8.83s/it] \u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  47% 0.4726051998793893/1 [00:02<00:02,  4.98s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  39% 0.3893967981345897/1 [00:02<00:03,  6.55s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  13% 0.12651330668655972/1 [00:02<00:09, 10.58s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  32% 0.31950365421140314/1 [00:02<00:05,  8.49s/it]\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  50% 0.4976088486998753/1 [00:02<00:02,  4.65s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  14% 0.13832806444557139/1 [00:02<00:08,  9.90s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  40% 0.40484234823103454/1 [00:02<00:04,  6.76s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  33% 0.33142277716917823/1 [00:02<00:05,  8.69s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  15% 0.15047304835312686/1 [00:02<00:07,  9.35s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  42% 0.4198052248869655/1 [00:02<00:04,  6.91s/it] \u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  34% 0.34498745068455655/1 [00:02<00:05,  8.34s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | : 100% 1.0/1 [00:02<00:00,  2.87s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   0% 0.0002672386940489985/1 [00:03<3:26:13, 12376.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   0% 0.002939625634538983/1 [00:03<14:03, 846.05s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   1% 0.009353354291714947/1 [00:03<03:31, 213.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   2% 0.021379095523919877/1 [00:05<02:56, 179.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   2% 0.024051482464409864/1 [00:05<02:32, 156.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   3% 0.027258346792997844/1 [00:05<02:04, 127.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  54% 0.5384119046011322/1 [00:05<00:22, 48.58s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   3% 0.030465211121585827/1 [00:05<01:41, 104.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   3% 0.03340483675612481/1 [00:05<01:24, 87.14s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   4% 0.03661170108471279/1 [00:06<01:09, 72.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   4% 0.03981856541330077/1 [00:06<01:07, 70.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   4% 0.043025429741888756/1 [00:06<00:57, 59.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :   5% 0.04569781668237874/1 [00:06<00:57, 60.03s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  43% 0.43434576228244676/1 [00:06<00:45, 80.82s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  16% 0.16126043587222447/1 [00:06<01:36, 115.03s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  55% 0.5520370813496869/1 [00:06<00:23, 51.63s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  12% 0.11838674146370633/1 [00:06<00:05,  6.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  45% 0.451178998520369/1 [00:06<00:31, 57.09s/it]  \u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  17% 0.17024992547147247/1 [00:06<01:13, 88.05s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  57% 0.5662420528534993/1 [00:06<00:17, 40.79s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  19% 0.1945497692676709/1 [00:06<00:02,  3.62s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  47% 0.4660815409962357/1 [00:06<00:22, 42.70s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  18% 0.183422279618942/1 [00:06<00:48, 59.70s/it]  \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  58% 0.5813891908346053/1 [00:06<00:13, 31.68s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  27% 0.2747213774823704/1 [00:06<00:01,  2.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  48% 0.4820097645331945/1 [00:06<00:16, 31.71s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  19% 0.1934758312523867/1 [00:06<00:37, 45.89s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  60% 0.6016095329242157/1 [00:06<00:09, 22.60s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  35% 0.35489298569706995/1 [00:06<00:01,  2.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  41% 0.4056949239582989/1 [00:06<00:18, 30.49s/it] \u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  20% 0.203162464943005/1 [00:06<00:28, 36.13s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  62% 0.6229894645243415/1 [00:06<00:06, 16.51s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  43% 0.4310560135010345/1 [00:07<00:01,  1.77s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  21% 0.2142800786106464/1 [00:07<00:21, 27.70s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  51% 0.5103064949833219/1 [00:07<00:09, 19.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  64% 0.6404557815264781/1 [00:07<00:04, 13.50s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  51% 0.512831053880028/1 [00:07<00:00,  1.58s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  43% 0.4287326317647448/1 [00:07<00:11, 20.05s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  22% 0.22433363024409111/1 [00:07<00:17, 23.11s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  66% 0.6583569445950579/1 [00:07<00:03, 11.22s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  58% 0.5828475917208656/1 [00:07<00:00,  1.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  44% 0.44429865055288387/1 [00:07<00:08, 15.49s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  23% 0.23424041470040524/1 [00:07<00:14, 19.46s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  68% 0.6806790426724773/1 [00:07<00:02,  8.92s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  65% 0.6520624134795563/1 [00:07<00:00,  1.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  46% 0.45657356822581635/1 [00:07<00:07, 13.47s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  24% 0.2438536648024582/1 [00:07<00:12, 16.90s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  70% 0.6997397952515725/1 [00:07<00:02,  7.84s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  74% 0.7442597629264608/1 [00:07<00:00,  1.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  58% 0.5789667918964244/1 [00:07<00:03,  8.93s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  25% 0.25343022311022856/1 [00:07<00:11, 15.65s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  72% 0.7183657017642243/1 [00:07<00:02,  7.46s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  82% 0.8238968937530623/1 [00:07<00:00,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  60% 0.5950156837935116/1 [00:07<00:03,  8.30s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  26% 0.26341039115510795/1 [00:07<00:10, 13.99s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  74% 0.7378613004097627/1 [00:07<00:01,  6.78s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  90% 0.9024650698034679/1 [00:07<00:00,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  27% 0.2740877032913576/1 [00:07<00:09, 12.55s/it] \n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  61% 0.6107025706102134/1 [00:07<00:03,  8.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  76% 0.7559798865115641/1 [00:07<00:01,  6.64s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | :  98% 0.9775591428312363/1 [00:07<00:00,  1.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  51% 0.5068740460812029/1 [00:07<00:04,  9.38s/it] \u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  63% 0.6260877865265939/1 [00:07<00:02,  7.69s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  28% 0.2838110287762585/1 [00:07<00:09, 12.87s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  52% 0.521328206384475/1 [00:07<00:04,  8.60s/it] \u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  64% 0.6423780151439381/1 [00:07<00:02,  7.26s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  29% 0.29474518347248674/1 [00:07<00:08, 11.76s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  66% 0.6576425627001903/1 [00:08<00:02,  7.18s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  53% 0.534225764808933/1 [00:08<00:04,  9.00s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  31% 0.30744054429428186/1 [00:08<00:07, 10.49s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  68% 0.6759841534397185/1 [00:08<00:02,  6.62s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  55% 0.5462783107848921/1 [00:08<00:04,  8.95s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  32% 0.3183746989905101/1 [00:08<00:06, 10.09s/it] \n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  33% 0.32890524394962917/1 [00:08<00:06, 10.38s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  85% 0.8491094190748236/1 [00:08<00:00,  6.07s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  56% 0.5581084850638778/1 [00:08<00:04, 10.10s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  34% 0.3397293232630094/1 [00:08<00:06, 10.04s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  87% 0.8685325433759549/1 [00:08<00:00,  5.87s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  57% 0.5692270699125486/1 [00:08<00:04,  9.85s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  35% 0.35003971745643264/1 [00:08<00:06, 10.04s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  89% 0.887230924233014/1 [00:08<00:00,  5.75s/it] \u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  58% 0.582213577015796/1 [00:08<00:03,  9.26s/it] \u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  36% 0.3625149275125319/1 [00:08<00:05,  9.37s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  91% 0.9099878683768766/1 [00:08<00:00,  5.28s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  59% 0.5934655848826509/1 [00:08<00:03,  9.25s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  37% 0.37388938374015185/1 [00:08<00:05,  9.45s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  93% 0.9328172868651464/1 [00:08<00:00,  5.02s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  61% 0.6056960282161887/1 [00:08<00:03,  8.92s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  38% 0.3846400794649668/1 [00:08<00:05,  9.54s/it] \n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  95% 0.9529651546103497/1 [00:08<00:00,  5.17s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  62% 0.6181488432466999/1 [00:08<00:03,  8.70s/it]\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  40% 0.3952440080126512/1 [00:08<00:05,  9.69s/it]\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | :  97% 0.9725332276002953/1 [00:08<00:00,  5.25s/it]\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  41% 0.40647169706314057/1 [00:08<00:05,  9.55s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | : 100% 1.0/1 [00:09<00:00,  1.49s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   0% 0.000713305081506338/1 [00:09<3:31:14, 12683.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | : 100% 0.9968846073211164/1 [00:11<00:00, 37.95s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   1% 0.009272966059582395/1 [00:11<15:45, 954.69s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  81% 0.8148131017675293/1 [00:11<00:08, 47.86s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   2% 0.01783262703765845/1 [00:11<06:45, 413.33s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   3% 0.026392288015734507/1 [00:11<03:46, 232.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   3% 0.034951948993810565/1 [00:11<02:21, 146.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   4% 0.04351160997188662/1 [00:11<01:33, 97.98s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   5% 0.052071270949962674/1 [00:11<01:05, 68.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   6% 0.060630931928038735/1 [00:11<00:47, 50.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   7% 0.06919059290611479/1 [00:12<00:35, 38.15s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   8% 0.07846355896569718/1 [00:12<00:27, 29.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  64% 0.6414533970895139/1 [00:12<00:32, 90.31s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :   9% 0.08702321994377324/1 [00:12<00:22, 24.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :  10% 0.0955828809218493/1 [00:12<00:18, 20.46s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :  10% 0.10414254189992535/1 [00:12<00:16, 18.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | : 100% 1.0/1 [00:12<00:00, 37.95s/it]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | :   0% 0.001215743402158182/1 [00:12<2:52:00, 10333.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :  11% 0.11341550795950775/1 [00:12<00:14, 16.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | :   2% 0.019451894434530912/1 [00:12<07:36, 466.01s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  42% 0.41700224202225966/1 [00:12<01:03, 108.93s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  65% 0.6496811498775302/1 [00:12<00:28, 82.65s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :  24% 0.2361039819785979/1 [00:12<00:02,  3.03s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | :   7% 0.06929737392301637/1 [00:12<01:33, 100.14s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  43% 0.4295141438726416/1 [00:12<00:43, 75.65s/it]  \n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  66% 0.660799734726201/1 [00:12<00:20, 60.12s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | :  43% 0.4294096590668155/1 [00:12<00:00,  1.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | :  32% 0.32095625816976003/1 [00:12<00:10, 15.31s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  86% 0.8602447393559002/1 [00:12<00:04, 32.01s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  67% 0.671740422217293/1 [00:12<00:14, 44.79s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  44% 0.4384669416776069/1 [00:12<00:34, 60.70s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | :  60% 0.5981457538618256/1 [00:12<00:02,  6.77s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  87% 0.8741216007706749/1 [00:12<00:03, 25.45s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  68% 0.6804573927386509/1 [00:13<00:11, 36.38s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  45% 0.44730966409972434/1 [00:13<00:26, 47.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | :  93% 0.9312594460531674/1 [00:13<00:00,  3.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  89% 0.8913771762690469/1 [00:13<00:02, 19.15s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  69% 0.6911312341933749/1 [00:13<00:08, 28.18s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  46% 0.456335845493255/1 [00:13<00:20, 37.64s/it]  \n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  91% 0.9068227263654917/1 [00:13<00:01, 15.46s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  46% 0.46484834176682865/1 [00:13<00:16, 30.70s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  92% 0.9214235979410372/1 [00:13<00:01, 13.15s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  47% 0.47328745445183695/1 [00:13<00:13, 25.64s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  94% 0.9357831327963257/1 [00:13<00:00, 11.87s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | : 100% 1.0/1 [00:13<00:00,  3.57s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  48% 0.48161649175399734/1 [00:13<00:11, 22.21s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  95% 0.9518923588734772/1 [00:13<00:00, 10.11s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  49% 0.49009229623328837/1 [00:13<00:09, 19.50s/it]\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  97% 0.9663725620888942/1 [00:13<00:00,  9.20s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  75% 0.7485031320125161/1 [00:13<00:03, 12.25s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  50% 0.4980544155926223/1 [00:13<00:08, 17.56s/it] \n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | :  98% 0.9807320969441827/1 [00:13<00:00,  8.92s/it]\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | :  51% 0.5074475149289794/1 [00:13<00:07, 15.40s/it]\n",
            "pytorch-1.6.0        | 425.8 MB  | :  52% 0.5172809157967282/1 [00:13<00:06, 13.71s/it]\n",
            "pytorch-1.6.0        | 425.8 MB  | :  53% 0.5302698109727846/1 [00:13<00:05, 11.44s/it]\n",
            "pytorch-1.6.0        | 425.8 MB  | :  55% 0.5461573578971698/1 [00:14<00:04,  9.43s/it]\n",
            "pytorch-1.6.0        | 425.8 MB  | :  56% 0.5618614458501419/1 [00:14<00:03,  8.33s/it]\n",
            "pytorch-1.6.0        | 425.8 MB  | :  58% 0.5775288420088313/1 [00:14<00:03,  7.71s/it]\n",
            "pytorch-1.6.0        | 425.8 MB  | :  61% 0.611652210691691/1 [00:14<00:02,  6.59s/it] \n",
            "pytorch-1.6.0        | 425.8 MB  | :  63% 0.6272462232618151/1 [00:14<00:02,  6.77s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  91% 0.9097226123182421/1 [00:14<00:00,  6.38s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :   0% 0.0014426562203234724/1 [00:14<2:48:27, 10122.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  64% 0.6423632425062649/1 [00:14<00:02,  7.69s/it]\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  93% 0.9257333745003281/1 [00:14<00:00,  7.12s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.0        | 7.5 MB    | :   0% 0.0020939809422684187/1 [00:14<1:57:28, 7063.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  66% 0.655975898185126/1 [00:14<00:02,  7.61s/it] \n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  94% 0.9438789049733588/1 [00:14<00:00,  6.62s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :   4% 0.038951717948733755/1 [00:14<02:43, 170.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  96% 0.9616686407312319/1 [00:14<00:00,  6.32s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  67% 0.6695518620697047/1 [00:14<00:02,  8.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :   7% 0.0678048423552032/1 [00:15<01:09, 74.92s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | :  98% 0.9805257606345776/1 [00:15<00:00,  6.04s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  69% 0.6851825664341115/1 [00:15<00:02,  7.71s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :  11% 0.11108452896490736/1 [00:15<00:31, 35.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-10.2.89  | 351.3 MB  | : 100% 0.9974260096045572/1 [00:15<00:00,  6.20s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  70% 0.6992722154386471/1 [00:15<00:02,  7.56s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :  19% 0.18610265242172794/1 [00:15<00:12, 15.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  71% 0.7128114875289431/1 [00:15<00:02,  7.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :  29% 0.28997390028501796/1 [00:15<00:05,  7.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  73% 0.7273414380648705/1 [00:15<00:02,  7.57s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :  44% 0.4414528034189825/1 [00:15<00:02,  4.06s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  74% 0.7411375527151449/1 [00:15<00:01,  7.56s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | :  67% 0.6650645175691208/1 [00:15<00:00,  2.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  75% 0.7545300576283104/1 [00:15<00:01,  7.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  77% 0.7676657199814972/1 [00:15<00:01,  8.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | : 100% 1.0/1 [00:15<00:00,  1.46s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | : 100% 1.0/1 [00:15<00:00,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk2-2.24.32         | 7.3 MB    | :   0% 0.0021413645657489366/1 [00:15<2:03:18, 7413.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | : 100% 1.0/1 [00:16<00:00, 60.88s/it]               \u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | : 100% 1.0/1 [00:16<00:00, 60.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk2-2.24.32         | 7.3 MB    | :   7% 0.06638230153821703/1 [00:16<02:49, 181.93s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.0        | 7.5 MB    | :  15% 0.154954589727863/1 [00:16<00:19, 23.50s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "graphviz-2.42.3      | 7.3 MB    | :   0% 0.00215179986685213/1 [00:16<2:09:46, 7803.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.0        | 7.5 MB    | :  59% 0.5905026257196941/1 [00:16<00:01,  2.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  78% 0.7798473956833354/1 [00:16<00:06, 31.41s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "graphviz-2.42.3      | 7.3 MB    | :  10% 0.09898279387519797/1 [00:16<01:48, 120.59s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  79% 0.7886901181054528/1 [00:16<00:05, 27.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  80% 0.8008717938072909/1 [00:17<00:04, 21.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "graphviz-2.42.3      | 7.3 MB    | :  86% 0.8564163470071476/1 [00:17<00:01,  7.70s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.0        | 7.5 MB    | : 100% 1.0/1 [00:17<00:00,  1.70s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.0        | 7.5 MB    | : 100% 1.0/1 [00:17<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  81% 0.8100080505836695/1 [00:17<00:03, 19.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  82% 0.821125664251311/1 [00:17<00:03, 17.02s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-1.19.2         | 5.3 MB    | :   0% 0.002971397937178075/1 [00:17<1:37:11, 5848.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  83% 0.830005078467711/1 [00:17<00:02, 15.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | : 100% 1.0/1 [00:17<00:00, 12.31s/it]                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | : 100% 1.0/1 [00:17<00:00, 12.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-1.19.2         | 5.3 MB    | :  12% 0.118855917487123/1 [00:17<01:31, 103.98s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  84% 0.8406823906039607/1 [00:17<00:02, 14.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  85% 0.8497819555860566/1 [00:17<00:01, 13.31s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-20.1.4   | 3.2 MB    | : 100% 1.0/1 [00:17<00:00, 12.41s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-20.1.4   | 3.2 MB    | : 100% 1.0/1 [00:17<00:00, 12.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  86% 0.8600923497794798/1 [00:17<00:01, 12.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  87% 0.869375373732989/1 [00:17<00:01, 12.05s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.66.3       | 3.0 MB    | : 100% 1.0/1 [00:17<00:00, 12.57s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.66.3       | 3.0 MB    | : 100% 1.0/1 [00:17<00:00, 12.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  88% 0.8785116305093675/1 [00:17<00:01, 12.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-1.19.2         | 5.3 MB    | : 100% 1.0/1 [00:17<00:00,  8.60s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.24.1 | 3.0 MB    | : 100% 1.0/1 [00:18<00:00, 12.69s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  89% 0.8904364636512272/1 [00:18<00:01, 11.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  94% 0.9395300844014061/1 [00:18<00:00,  8.82s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  95% 0.9511246913947219/1 [00:18<00:00,  9.14s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  96% 0.9627559901823204/1 [00:18<00:00,  8.98s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :   0% 0.004276062869398955/1 [00:18<1:12:59, 4397.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  97% 0.9740570628213749/1 [00:18<00:00,  8.98s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | :  99% 0.9853214436661469/1 [00:18<00:00,  9.61s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :   1% 0.012828188608196865/1 [00:18<18:58, 1152.88s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pynini-2.1.3         | 2.0 MB    | : 100% 1.0/1 [00:19<00:00,  6.45s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.6.0        | 425.8 MB  | : 100% 0.9979434208993768/1 [00:19<00:00,  9.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :   3% 0.02565637721639373/1 [00:19<07:19, 451.55s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :   5% 0.04703669156338851/1 [00:19<02:57, 186.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :   8% 0.07696913164918119/1 [00:19<01:20, 87.68s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :  12% 0.1154536974737718/1 [00:19<00:40, 45.41s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :  17% 0.16676645190655925/1 [00:19<00:20, 24.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :  23% 0.2309073949475436/1 [00:19<00:10, 13.78s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :  32% 0.3164286523355227/1 [00:19<00:05,  7.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :  44% 0.43615841267869343/1 [00:19<00:02,  4.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :  59% 0.5943727388464548/1 [00:19<00:01,  2.66s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | :  78% 0.7825195051000088/1 [00:20<00:00,  1.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | : 100% 1.0/1 [00:20<00:00,  1.25s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | : 100% 1.0/1 [00:20<00:00,  1.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | : 100% 1.0/1 [00:23<00:00,  9.20s/it]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "magma-2.5.2          | 58.5 MB   | : 100% 1.0/1 [00:27<00:00,  1.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.14.3.1        | 106.4 MB  | : 100% 1.0/1 [00:35<00:00,  2.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-67.1             | 12.9 MB   | : 100% 1.0/1 [00:37<00:00,  3.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.5         | 21.9 MB   | : 100% 1.0/1 [00:42<00:00,  1.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.3         | 10.8 MB   | : 100% 1.0/1 [00:46<00:00,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "mkl-2020.4           | 215.6 MB  | : 100% 1.0/1 [01:17<00:00, 37.95s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.0        | 7.5 MB    | : 100% 1.0/1 [01:19<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk2-2.24.32         | 7.3 MB    | : 100% 1.0/1 [01:22<00:00,  7.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "graphviz-2.42.3      | 7.3 MB    | : 100% 1.0/1 [01:24<00:00,  7.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | : 100% 1.0/1 [01:24<00:00, 12.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-20.1.4   | 3.2 MB    | : 100% 1.0/1 [01:24<00:00, 12.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.66.3       | 3.0 MB    | : 100% 1.0/1 [01:25<00:00, 12.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-1.19.2         | 5.3 MB    | : 100% 1.0/1 [01:26<00:00,  8.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.24.1 | 3.0 MB    | : 100% 1.0/1 [01:26<00:00, 12.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudnn-7.6.5.32       | 259.0 MB  | : 100% 1.0/1 [01:30<00:00, 60.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pynini-2.1.3         | 2.0 MB    | : 100% 1.0/1 [01:31<00:00,  6.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ngram-1.3.12         | 3.7 MB    | : 100% 1.0/1 [01:33<00:00,  1.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.6.0        | 425.8 MB  | : 100% 1.0/1 [02:41<00:00,  9.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
            "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Installing pip dependencies: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/task1/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/2020/task1/condaenv.p6ptu0_y.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting fairseq==0.10.1\n",
            "  Downloading fairseq-0.10.1-cp38-cp38-manylinux1_x86_64.whl (1.7 MB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting regex\n",
            "  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Collecting cython\n",
            "  Downloading cython-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/task1/lib/python3.8/site-packages (from fairseq==0.10.1->-r /content/2020/task1/condaenv.p6ptu0_y.requirements.txt (line 1)) (1.19.2)\n",
            "Requirement already satisfied: cffi in /usr/local/envs/task1/lib/python3.8/site-packages (from fairseq==0.10.1->-r /content/2020/task1/condaenv.p6ptu0_y.requirements.txt (line 1)) (1.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/envs/task1/lib/python3.8/site-packages (from fairseq==0.10.1->-r /content/2020/task1/condaenv.p6ptu0_y.requirements.txt (line 1)) (1.6.0)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting lxml\n",
            "  Downloading lxml-5.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "Requirement already satisfied: pycparser in /usr/local/envs/task1/lib/python3.8/site-packages (from cffi->fairseq==0.10.1->-r /content/2020/task1/condaenv.p6ptu0_y.requirements.txt (line 1)) (2.22)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "Collecting packaging\n",
            "  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Collecting omegaconf<2.4,>=2.2\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Collecting importlib-resources\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Collecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
            "Collecting zipp>=3.1.0\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: future in /usr/local/envs/task1/lib/python3.8/site-packages (from torch->fairseq==0.10.1->-r /content/2020/task1/condaenv.p6ptu0_y.requirements.txt (line 1)) (1.0.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=6255a9ddcfe712510ce4e609bc9b48f2d7b644232e5a2c0c071d691bbbc04f59\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: zipp, PyYAML, antlr4-python3-runtime, tabulate, regex, portalocker, packaging, omegaconf, lxml, importlib-resources, colorama, tqdm, sacrebleu, hydra-core, dataclasses, cython, fairseq\n",
            "Successfully installed PyYAML-6.0.2 antlr4-python3-runtime-4.9.3 colorama-0.4.6 cython-3.1.0 dataclasses-0.6 fairseq-0.10.1 hydra-core-1.3.2 importlib-resources-6.4.5 lxml-5.4.0 omegaconf-2.3.0 packaging-25.0 portalocker-3.0.0 regex-2024.11.6 sacrebleu-2.5.1 tabulate-0.9.0 tqdm-4.67.1 zipp-3.20.2\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate task1\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate task1\n",
        "python -c \"import torch; print('CUDA available:', torch.cuda.is_available()); print('CUDA device count:', torch.cuda.device_count()); print('PyTorch version:', torch.__version__); print('CUDA version:', torch.version.cuda)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzzoRM3IkWJU",
        "outputId": "6befa1b2-b28c-428e-830c-63fe28a1e931"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "CUDA device count: 1\n",
            "PyTorch version: 1.6.0\n",
            "CUDA version: 10.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate task1\n",
        "\n",
        "cd 2020/task1/baselines/transformer/\n",
        "\n",
        "./preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "au9n1eRLlcYX",
        "outputId": "25046fec-2276-4a16-a511-4ab8179de841"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-14 11:39:01 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/ady', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ady.graphemes', srcdict=None, target_lang='ady.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:01 | INFO | fairseq_cli.preprocess | [ady.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:01 | INFO | fairseq_cli.preprocess | [ady.graphemes] train.ady.graphemes: 3600 sents, 29451 tokens, 0.0034% replaced by <unk>\n",
            "2025-05-14 11:39:01 | INFO | fairseq_cli.preprocess | [ady.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:01 | INFO | fairseq_cli.preprocess | [ady.graphemes] dev.ady.graphemes: 450 sents, 3626 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:01 | INFO | fairseq_cli.preprocess | [ady.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | [ady.graphemes] test.ady.graphemes: 450 sents, 3687 tokens, 0.0271% replaced by <unk>\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | [ady.phonemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | [ady.phonemes] train.ady.phonemes: 3600 sents, 25197 tokens, 0.254% replaced by <unk>\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | [ady.phonemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | [ady.phonemes] dev.ady.phonemes: 450 sents, 3092 tokens, 0.226% replaced by <unk>\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | [ady.phonemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | [ady.phonemes] test.ady.phonemes: 450 sents, 3160 tokens, 0.475% replaced by <unk>\n",
            "2025-05-14 11:39:02 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/ady\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/arm', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='arm.graphemes', srcdict=None, target_lang='arm.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.graphemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.graphemes] train.arm.graphemes: 3600 sents, 28398 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.graphemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.graphemes] dev.arm.graphemes: 450 sents, 3708 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.graphemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.graphemes] test.arm.graphemes: 450 sents, 3597 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.phonemes] train.arm.phonemes: 3600 sents, 28244 tokens, 0.0779% replaced by <unk>\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.phonemes] dev.arm.phonemes: 450 sents, 3652 tokens, 0.11% replaced by <unk>\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | [arm.phonemes] test.arm.phonemes: 450 sents, 3576 tokens, 0.14% replaced by <unk>\n",
            "2025-05-14 11:39:03 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/arm\n",
            "2025-05-14 11:39:04 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/bul', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='bul.graphemes', srcdict=None, target_lang='bul.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:05 | INFO | fairseq_cli.preprocess | [bul.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:05 | INFO | fairseq_cli.preprocess | [bul.graphemes] train.bul.graphemes: 3600 sents, 30158 tokens, 0.0133% replaced by <unk>\n",
            "2025-05-14 11:39:05 | INFO | fairseq_cli.preprocess | [bul.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:05 | INFO | fairseq_cli.preprocess | [bul.graphemes] dev.bul.graphemes: 450 sents, 3805 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:05 | INFO | fairseq_cli.preprocess | [bul.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:05 | INFO | fairseq_cli.preprocess | [bul.graphemes] test.bul.graphemes: 450 sents, 3693 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:05 | INFO | fairseq_cli.preprocess | [bul.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:06 | INFO | fairseq_cli.preprocess | [bul.phonemes] train.bul.phonemes: 3600 sents, 31115 tokens, 0.0803% replaced by <unk>\n",
            "2025-05-14 11:39:06 | INFO | fairseq_cli.preprocess | [bul.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:06 | INFO | fairseq_cli.preprocess | [bul.phonemes] dev.bul.phonemes: 450 sents, 3945 tokens, 0.0507% replaced by <unk>\n",
            "2025-05-14 11:39:06 | INFO | fairseq_cli.preprocess | [bul.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:06 | INFO | fairseq_cli.preprocess | [bul.phonemes] test.bul.phonemes: 450 sents, 3832 tokens, 0.157% replaced by <unk>\n",
            "2025-05-14 11:39:06 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/bul\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/dut', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='dut.graphemes', srcdict=None, target_lang='dut.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.graphemes] Dictionary: 32 types\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.graphemes] train.dut.graphemes: 3600 sents, 35053 tokens, 0.0342% replaced by <unk>\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.graphemes] Dictionary: 32 types\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.graphemes] dev.dut.graphemes: 450 sents, 4267 tokens, 0.0469% replaced by <unk>\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.graphemes] Dictionary: 32 types\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.graphemes] test.dut.graphemes: 450 sents, 4249 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.phonemes] train.dut.phonemes: 3600 sents, 31959 tokens, 0.0344% replaced by <unk>\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.phonemes] dev.dut.phonemes: 450 sents, 3905 tokens, 0.102% replaced by <unk>\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | [dut.phonemes] test.dut.phonemes: 450 sents, 3875 tokens, 0.0258% replaced by <unk>\n",
            "2025-05-14 11:39:07 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/dut\n",
            "2025-05-14 11:39:08 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/fre', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='fre.graphemes', srcdict=None, target_lang='fre.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:08 | INFO | fairseq_cli.preprocess | [fre.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.graphemes] train.fre.graphemes: 3600 sents, 29689 tokens, 0.00674% replaced by <unk>\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.graphemes] dev.fre.graphemes: 450 sents, 3705 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.graphemes] test.fre.graphemes: 450 sents, 3718 tokens, 0.0269% replaced by <unk>\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.phonemes] train.fre.phonemes: 3600 sents, 23556 tokens, 0.0127% replaced by <unk>\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.phonemes] dev.fre.phonemes: 450 sents, 2948 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | [fre.phonemes] test.fre.phonemes: 450 sents, 2951 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:09 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/fre\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/geo', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='geo.graphemes', srcdict=None, target_lang='geo.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.graphemes] train.geo.graphemes: 3600 sents, 30801 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.graphemes] dev.geo.graphemes: 450 sents, 3738 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.graphemes] test.geo.graphemes: 450 sents, 3861 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.phonemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.phonemes] train.geo.phonemes: 3600 sents, 31656 tokens, 0.00948% replaced by <unk>\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.phonemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.phonemes] dev.geo.phonemes: 450 sents, 3863 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.phonemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | [geo.phonemes] test.geo.phonemes: 450 sents, 3952 tokens, 0.0506% replaced by <unk>\n",
            "2025-05-14 11:39:10 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/geo\n",
            "2025-05-14 11:39:11 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/gre', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='gre.graphemes', srcdict=None, target_lang='gre.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.graphemes] train.gre.graphemes: 3600 sents, 33269 tokens, 0.0331% replaced by <unk>\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.graphemes] dev.gre.graphemes: 450 sents, 4246 tokens, 0.0236% replaced by <unk>\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.graphemes] test.gre.graphemes: 450 sents, 4063 tokens, 0.0492% replaced by <unk>\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.phonemes] train.gre.phonemes: 3600 sents, 31824 tokens, 0.0471% replaced by <unk>\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.phonemes] dev.gre.phonemes: 450 sents, 4018 tokens, 0.0498% replaced by <unk>\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.phonemes] Dictionary: 48 types\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | [gre.phonemes] test.gre.phonemes: 450 sents, 3879 tokens, 0.0258% replaced by <unk>\n",
            "2025-05-14 11:39:12 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/gre\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/hin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='hin.graphemes', srcdict=None, target_lang='hin.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | [hin.graphemes] Dictionary: 64 types\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | [hin.graphemes] train.hin.graphemes: 3600 sents, 23230 tokens, 0.0344% replaced by <unk>\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | [hin.graphemes] Dictionary: 64 types\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | [hin.graphemes] dev.hin.graphemes: 450 sents, 2966 tokens, 0.0337% replaced by <unk>\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | [hin.graphemes] Dictionary: 64 types\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | [hin.graphemes] test.hin.graphemes: 450 sents, 2982 tokens, 0.0335% replaced by <unk>\n",
            "2025-05-14 11:39:13 | INFO | fairseq_cli.preprocess | [hin.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:14 | INFO | fairseq_cli.preprocess | [hin.phonemes] train.hin.phonemes: 3600 sents, 23853 tokens, 0.172% replaced by <unk>\n",
            "2025-05-14 11:39:14 | INFO | fairseq_cli.preprocess | [hin.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:14 | INFO | fairseq_cli.preprocess | [hin.phonemes] dev.hin.phonemes: 450 sents, 3039 tokens, 0.23% replaced by <unk>\n",
            "2025-05-14 11:39:14 | INFO | fairseq_cli.preprocess | [hin.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:14 | INFO | fairseq_cli.preprocess | [hin.phonemes] test.hin.phonemes: 450 sents, 3037 tokens, 0.132% replaced by <unk>\n",
            "2025-05-14 11:39:14 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/hin\n",
            "2025-05-14 11:39:14 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/hun', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='hun.graphemes', srcdict=None, target_lang='hun.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.graphemes] train.hun.graphemes: 3600 sents, 29933 tokens, 0.01% replaced by <unk>\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.graphemes] dev.hun.graphemes: 450 sents, 3818 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.graphemes] test.hun.graphemes: 450 sents, 3731 tokens, 0.0268% replaced by <unk>\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.phonemes] train.hun.phonemes: 3600 sents, 28124 tokens, 0.0533% replaced by <unk>\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.phonemes] dev.hun.phonemes: 450 sents, 3621 tokens, 0.11% replaced by <unk>\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | [hun.phonemes] test.hun.phonemes: 450 sents, 3497 tokens, 0.114% replaced by <unk>\n",
            "2025-05-14 11:39:15 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/hun\n",
            "2025-05-14 11:39:16 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/ice', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ice.graphemes', srcdict=None, target_lang='ice.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:16 | INFO | fairseq_cli.preprocess | [ice.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.graphemes] train.ice.graphemes: 3600 sents, 25671 tokens, 0.0195% replaced by <unk>\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.graphemes] dev.ice.graphemes: 450 sents, 3252 tokens, 0.0308% replaced by <unk>\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.graphemes] test.ice.graphemes: 450 sents, 3199 tokens, 0.0313% replaced by <unk>\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.phonemes] train.ice.phonemes: 3600 sents, 26372 tokens, 0.0796% replaced by <unk>\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.phonemes] dev.ice.phonemes: 450 sents, 3319 tokens, 0.0904% replaced by <unk>\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | [ice.phonemes] test.ice.phonemes: 450 sents, 3295 tokens, 0.091% replaced by <unk>\n",
            "2025-05-14 11:39:17 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/ice\n",
            "2025-05-14 11:39:18 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/jpn', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='jpn.graphemes', srcdict=None, target_lang='jpn.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.graphemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.graphemes] train.jpn.graphemes: 3600 sents, 18735 tokens, 0.0374% replaced by <unk>\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.graphemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.graphemes] dev.jpn.graphemes: 450 sents, 2327 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.graphemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.graphemes] test.jpn.graphemes: 450 sents, 2319 tokens, 0.172% replaced by <unk>\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.phonemes] train.jpn.phonemes: 3600 sents, 26642 tokens, 0.128% replaced by <unk>\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.phonemes] dev.jpn.phonemes: 450 sents, 3342 tokens, 0.269% replaced by <unk>\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.phonemes] Dictionary: 72 types\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | [jpn.phonemes] test.jpn.phonemes: 450 sents, 3299 tokens, 0.0303% replaced by <unk>\n",
            "2025-05-14 11:39:19 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/jpn\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/kor', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='kor.graphemes', srcdict=None, target_lang='kor.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | [kor.graphemes] Dictionary: 368 types\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | [kor.graphemes] train.kor.graphemes: 3600 sents, 12455 tokens, 6.86% replaced by <unk>\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | [kor.graphemes] Dictionary: 368 types\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | [kor.graphemes] dev.kor.graphemes: 450 sents, 1544 tokens, 8.42% replaced by <unk>\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | [kor.graphemes] Dictionary: 368 types\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | [kor.graphemes] test.kor.graphemes: 450 sents, 1580 tokens, 7.78% replaced by <unk>\n",
            "2025-05-14 11:39:20 | INFO | fairseq_cli.preprocess | [kor.phonemes] Dictionary: 64 types\n",
            "2025-05-14 11:39:21 | INFO | fairseq_cli.preprocess | [kor.phonemes] train.kor.phonemes: 3600 sents, 25303 tokens, 0.0119% replaced by <unk>\n",
            "2025-05-14 11:39:21 | INFO | fairseq_cli.preprocess | [kor.phonemes] Dictionary: 64 types\n",
            "2025-05-14 11:39:21 | INFO | fairseq_cli.preprocess | [kor.phonemes] dev.kor.phonemes: 450 sents, 3143 tokens, 0.0318% replaced by <unk>\n",
            "2025-05-14 11:39:21 | INFO | fairseq_cli.preprocess | [kor.phonemes] Dictionary: 64 types\n",
            "2025-05-14 11:39:21 | INFO | fairseq_cli.preprocess | [kor.phonemes] test.kor.phonemes: 450 sents, 3215 tokens, 0.0311% replaced by <unk>\n",
            "2025-05-14 11:39:21 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/kor\n",
            "2025-05-14 11:39:21 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/lit', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='lit.graphemes', srcdict=None, target_lang='lit.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.graphemes] train.lit.graphemes: 3600 sents, 36916 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.graphemes] dev.lit.graphemes: 450 sents, 4639 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.graphemes] test.lit.graphemes: 450 sents, 4549 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.phonemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.phonemes] train.lit.phonemes: 3600 sents, 35725 tokens, 0.241% replaced by <unk>\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.phonemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.phonemes] dev.lit.phonemes: 450 sents, 4465 tokens, 0.224% replaced by <unk>\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.phonemes] Dictionary: 80 types\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | [lit.phonemes] test.lit.phonemes: 450 sents, 4420 tokens, 0.271% replaced by <unk>\n",
            "2025-05-14 11:39:22 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/lit\n",
            "2025-05-14 11:39:23 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/rum', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='rum.graphemes', srcdict=None, target_lang='rum.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.graphemes] train.rum.graphemes: 3600 sents, 31568 tokens, 0.162% replaced by <unk>\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.graphemes] dev.rum.graphemes: 450 sents, 3799 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.graphemes] Dictionary: 40 types\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.graphemes] test.rum.graphemes: 450 sents, 3828 tokens, 0.313% replaced by <unk>\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.phonemes] train.rum.phonemes: 3600 sents, 31242 tokens, 0.096% replaced by <unk>\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.phonemes] dev.rum.phonemes: 450 sents, 3747 tokens, 0.0801% replaced by <unk>\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | [rum.phonemes] test.rum.phonemes: 450 sents, 3766 tokens, 0.0531% replaced by <unk>\n",
            "2025-05-14 11:39:24 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/rum\n",
            "2025-05-14 11:39:25 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/vie', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='vie.graphemes', srcdict=None, target_lang='vie.phonemes', task='translation', tensorboard_logdir=None, testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer='space', tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=1)\n",
            "2025-05-14 11:39:25 | INFO | fairseq_cli.preprocess | [vie.graphemes] Dictionary: 96 types\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.graphemes] train.vie.graphemes: 3600 sents, 26383 tokens, 0.0303% replaced by <unk>\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.graphemes] Dictionary: 96 types\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.graphemes] dev.vie.graphemes: 450 sents, 3413 tokens, 0.146% replaced by <unk>\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.graphemes] Dictionary: 96 types\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.graphemes] test.vie.graphemes: 450 sents, 3371 tokens, 0.0297% replaced by <unk>\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.phonemes] train.vie.phonemes: 3600 sents, 33052 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.phonemes] dev.vie.phonemes: 450 sents, 4282 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.phonemes] Dictionary: 56 types\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | [vie.phonemes] test.vie.phonemes: 450 sents, 4196 tokens, 0.0% replaced by <unk>\n",
            "2025-05-14 11:39:26 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/vie\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate task1\n",
        "\n",
        "cd 2020/task1/baselines/transformer/\n",
        "\n",
        "# Only train and evaluate French\n",
        "sed -i.bak '136 s/$(ls data-bin)/fre/' sweep\n",
        "\n",
        "./sweep --cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "epsagKk1l-Lg",
        "outputId": "69b857b4-b1ac-43e4-fb97-c407302db43f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-14 11:44:10 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.1, batch_size=256, batch_size_valid=256, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=128, decoder_embed_path=None, decoder_ffn_embed_dim=512, decoder_input_dim=128, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=128, device_id=0, disable_validation=True, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=128, encoder_embed_path=None, encoder_ffn_embed_dim=512, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=5000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/fre-256-.1-s-s', save_interval=5, save_interval_updates=0, scoring='bleu', seed=1917, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', stop_time_hours=0, target_lang='fre.phonemes', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=1000, weight_decay=0.0, zero_sharding='none')\n",
            "2025-05-14 11:44:10 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:44:10 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:44:10 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:44:10 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:44:10 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:44:10 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(40, 128, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(48, 128, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=128, out_features=48, bias=False)\n",
            "  )\n",
            ")\n",
            "2025-05-14 11:44:10 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
            "2025-05-14 11:44:10 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
            "2025-05-14 11:44:10 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
            "2025-05-14 11:44:10 | INFO | fairseq_cli.train | num. model params: 1863168 (num. trained: 1863168)\n",
            "2025-05-14 11:44:12 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2025-05-14 11:44:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2025-05-14 11:44:12 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.741 GB ; name = Tesla T4                                \n",
            "2025-05-14 11:44:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2025-05-14 11:44:12 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2025-05-14 11:44:12 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 256\n",
            "2025-05-14 11:44:12 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/fre-256-.1-s-s/checkpoint_last.pt\n",
            "2025-05-14 11:44:12 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2025-05-14 11:44:12 | INFO | fairseq.data.data_utils | loaded 3600 examples from: data-bin/fre/train.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:44:12 | INFO | fairseq.data.data_utils | loaded 3600 examples from: data-bin/fre/train.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:44:12 | INFO | fairseq.tasks.translation | data-bin/fre train fre.graphemes-fre.phonemes 3600 examples\n",
            "2025-05-14 11:44:12 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
            "epoch 001:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:12 | INFO | fairseq.trainer | begin training epoch 1\n",
            "/usr/local/envs/task1/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "2025-05-14 11:44:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2025-05-14 11:44:14 | INFO | train | epoch 001 | loss 8.132 | nll_loss 8.133 | ppl 280.72 | wps 22037.8 | ups 14 | wpb 1570.4 | bsz 240 | num_updates 15 | lr 1.50985e-05 | gnorm 6.575 | clip 100 | train_wall 2 | wall 2\n",
            "epoch 002:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:14 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2025-05-14 11:44:15 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2025-05-14 11:44:15 | INFO | train | epoch 002 | loss 7.109 | nll_loss 7.077 | ppl 135.03 | wps 16066.5 | ups 10.23 | wpb 1570.4 | bsz 240 | num_updates 30 | lr 3.0097e-05 | gnorm 4.687 | clip 100 | train_wall 1 | wall 3\n",
            "epoch 003:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:15 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2025-05-14 11:44:16 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2025-05-14 11:44:16 | INFO | train | epoch 003 | loss 6.005 | nll_loss 5.927 | ppl 60.86 | wps 24204.8 | ups 15.41 | wpb 1570.4 | bsz 240 | num_updates 45 | lr 4.50955e-05 | gnorm 2.215 | clip 100 | train_wall 1 | wall 4\n",
            "epoch 004:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:16 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2025-05-14 11:44:17 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2025-05-14 11:44:17 | INFO | train | epoch 004 | loss 5.334 | nll_loss 5.218 | ppl 37.21 | wps 24612.6 | ups 15.67 | wpb 1570.4 | bsz 240 | num_updates 60 | lr 6.0094e-05 | gnorm 1.18 | clip 66.7 | train_wall 1 | wall 5\n",
            "epoch 005:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:17 | INFO | fairseq.trainer | begin training epoch 5\n",
            "epoch 005:  93% 14/15 [00:00<00:00, 18.46it/s]2025-05-14 11:44:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint5.pt (epoch 5 @ 75 updates, score None) (writing took 0.07567586200002552 seconds)\n",
            "2025-05-14 11:44:18 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2025-05-14 11:44:18 | INFO | train | epoch 005 | loss 5.057 | nll_loss 4.911 | ppl 30.08 | wps 22655.6 | ups 14.43 | wpb 1570.4 | bsz 240 | num_updates 75 | lr 7.50925e-05 | gnorm 0.848 | clip 26.7 | train_wall 1 | wall 6\n",
            "epoch 006:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:18 | INFO | fairseq.trainer | begin training epoch 6\n",
            "2025-05-14 11:44:19 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2025-05-14 11:44:19 | INFO | train | epoch 006 | loss 4.93 | nll_loss 4.761 | ppl 27.11 | wps 24597 | ups 15.66 | wpb 1570.4 | bsz 240 | num_updates 90 | lr 9.0091e-05 | gnorm 0.889 | clip 26.7 | train_wall 1 | wall 7\n",
            "epoch 007:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:19 | INFO | fairseq.trainer | begin training epoch 7\n",
            "2025-05-14 11:44:20 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2025-05-14 11:44:20 | INFO | train | epoch 007 | loss 4.843 | nll_loss 4.661 | ppl 25.3 | wps 24003.6 | ups 15.28 | wpb 1570.4 | bsz 240 | num_updates 105 | lr 0.000105089 | gnorm 0.803 | clip 26.7 | train_wall 1 | wall 8\n",
            "epoch 008:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:20 | INFO | fairseq.trainer | begin training epoch 8\n",
            "2025-05-14 11:44:21 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2025-05-14 11:44:21 | INFO | train | epoch 008 | loss 4.754 | nll_loss 4.557 | ppl 23.53 | wps 24864.9 | ups 15.83 | wpb 1570.4 | bsz 240 | num_updates 120 | lr 0.000120088 | gnorm 0.905 | clip 40 | train_wall 1 | wall 9\n",
            "epoch 009:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:21 | INFO | fairseq.trainer | begin training epoch 9\n",
            "2025-05-14 11:44:22 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2025-05-14 11:44:22 | INFO | train | epoch 009 | loss 4.6 | nll_loss 4.372 | ppl 20.71 | wps 25087.2 | ups 15.98 | wpb 1570.4 | bsz 240 | num_updates 135 | lr 0.000135087 | gnorm 0.998 | clip 53.3 | train_wall 1 | wall 10\n",
            "epoch 010:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:22 | INFO | fairseq.trainer | begin training epoch 10\n",
            "epoch 010:  87% 13/15 [00:00<00:00, 17.78it/s]2025-05-14 11:44:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint10.pt (epoch 10 @ 150 updates, score None) (writing took 0.09076854500017362 seconds)\n",
            "2025-05-14 11:44:23 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2025-05-14 11:44:23 | INFO | train | epoch 010 | loss 4.512 | nll_loss 4.245 | ppl 18.97 | wps 22501 | ups 14.33 | wpb 1570.4 | bsz 240 | num_updates 150 | lr 0.000150085 | gnorm 1.724 | clip 46.7 | train_wall 1 | wall 11\n",
            "epoch 011:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:23 | INFO | fairseq.trainer | begin training epoch 11\n",
            "2025-05-14 11:44:24 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
            "2025-05-14 11:44:24 | INFO | train | epoch 011 | loss 4.357 | nll_loss 4.074 | ppl 16.84 | wps 24651.3 | ups 15.7 | wpb 1570.4 | bsz 240 | num_updates 165 | lr 0.000165083 | gnorm 1.914 | clip 73.3 | train_wall 1 | wall 12\n",
            "epoch 012:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:24 | INFO | fairseq.trainer | begin training epoch 12\n",
            "2025-05-14 11:44:25 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
            "2025-05-14 11:44:25 | INFO | train | epoch 012 | loss 4.117 | nll_loss 3.804 | ppl 13.96 | wps 24050.9 | ups 15.32 | wpb 1570.4 | bsz 240 | num_updates 180 | lr 0.000180082 | gnorm 1.436 | clip 53.3 | train_wall 1 | wall 13\n",
            "epoch 013:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:25 | INFO | fairseq.trainer | begin training epoch 13\n",
            "2025-05-14 11:44:26 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
            "2025-05-14 11:44:26 | INFO | train | epoch 013 | loss 3.837 | nll_loss 3.472 | ppl 11.1 | wps 19036.4 | ups 12.12 | wpb 1570.4 | bsz 240 | num_updates 195 | lr 0.00019508 | gnorm 1.261 | clip 60 | train_wall 1 | wall 14\n",
            "epoch 014:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:26 | INFO | fairseq.trainer | begin training epoch 14\n",
            "2025-05-14 11:44:28 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
            "2025-05-14 11:44:28 | INFO | train | epoch 014 | loss 3.496 | nll_loss 3.072 | ppl 8.41 | wps 16004 | ups 10.19 | wpb 1570.4 | bsz 240 | num_updates 210 | lr 0.000210079 | gnorm 1.152 | clip 53.3 | train_wall 1 | wall 16\n",
            "epoch 015:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:28 | INFO | fairseq.trainer | begin training epoch 15\n",
            "epoch 015:  80% 12/15 [00:00<00:00, 17.56it/s]2025-05-14 11:44:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint15.pt (epoch 15 @ 225 updates, score None) (writing took 0.08296325299988894 seconds)\n",
            "2025-05-14 11:44:29 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)\n",
            "2025-05-14 11:44:29 | INFO | train | epoch 015 | loss 3.128 | nll_loss 2.638 | ppl 6.23 | wps 22079.3 | ups 14.06 | wpb 1570.4 | bsz 240 | num_updates 225 | lr 0.000225077 | gnorm 1.326 | clip 80 | train_wall 1 | wall 17\n",
            "epoch 016:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:29 | INFO | fairseq.trainer | begin training epoch 16\n",
            "2025-05-14 11:44:30 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
            "2025-05-14 11:44:30 | INFO | train | epoch 016 | loss 2.866 | nll_loss 2.323 | ppl 5 | wps 24442.5 | ups 15.56 | wpb 1570.4 | bsz 240 | num_updates 240 | lr 0.000240076 | gnorm 1.526 | clip 93.3 | train_wall 1 | wall 18\n",
            "epoch 017:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:30 | INFO | fairseq.trainer | begin training epoch 17\n",
            "2025-05-14 11:44:31 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
            "2025-05-14 11:44:31 | INFO | train | epoch 017 | loss 2.591 | nll_loss 1.993 | ppl 3.98 | wps 24926.7 | ups 15.87 | wpb 1570.4 | bsz 240 | num_updates 255 | lr 0.000255074 | gnorm 1.276 | clip 60 | train_wall 1 | wall 19\n",
            "epoch 018:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:31 | INFO | fairseq.trainer | begin training epoch 18\n",
            "2025-05-14 11:44:32 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
            "2025-05-14 11:44:32 | INFO | train | epoch 018 | loss 2.421 | nll_loss 1.781 | ppl 3.44 | wps 23808.9 | ups 15.16 | wpb 1570.4 | bsz 240 | num_updates 270 | lr 0.000270073 | gnorm 1.562 | clip 80 | train_wall 1 | wall 20\n",
            "epoch 019:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:32 | INFO | fairseq.trainer | begin training epoch 19\n",
            "2025-05-14 11:44:33 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
            "2025-05-14 11:44:33 | INFO | train | epoch 019 | loss 2.434 | nll_loss 1.783 | ppl 3.44 | wps 24306 | ups 15.48 | wpb 1570.4 | bsz 240 | num_updates 285 | lr 0.000285071 | gnorm 2.609 | clip 93.3 | train_wall 1 | wall 21\n",
            "epoch 020:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:33 | INFO | fairseq.trainer | begin training epoch 20\n",
            "epoch 020:  87% 13/15 [00:00<00:00, 18.10it/s]2025-05-14 11:44:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint20.pt (epoch 20 @ 300 updates, score None) (writing took 0.09276990900002602 seconds)\n",
            "2025-05-14 11:44:34 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
            "2025-05-14 11:44:34 | INFO | train | epoch 020 | loss 2.246 | nll_loss 1.559 | ppl 2.95 | wps 21774.8 | ups 13.87 | wpb 1570.4 | bsz 240 | num_updates 300 | lr 0.00030007 | gnorm 1.997 | clip 93.3 | train_wall 1 | wall 22\n",
            "epoch 021:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:34 | INFO | fairseq.trainer | begin training epoch 21\n",
            "2025-05-14 11:44:35 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
            "2025-05-14 11:44:35 | INFO | train | epoch 021 | loss 2.129 | nll_loss 1.419 | ppl 2.67 | wps 23117.2 | ups 14.72 | wpb 1570.4 | bsz 240 | num_updates 315 | lr 0.000315069 | gnorm 1.737 | clip 66.7 | train_wall 1 | wall 23\n",
            "epoch 022:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:35 | INFO | fairseq.trainer | begin training epoch 22\n",
            "2025-05-14 11:44:36 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
            "2025-05-14 11:44:36 | INFO | train | epoch 022 | loss 1.997 | nll_loss 1.258 | ppl 2.39 | wps 20288 | ups 12.92 | wpb 1570.4 | bsz 240 | num_updates 330 | lr 0.000330067 | gnorm 1.457 | clip 66.7 | train_wall 1 | wall 24\n",
            "epoch 023:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:36 | INFO | fairseq.trainer | begin training epoch 23\n",
            "2025-05-14 11:44:37 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
            "2025-05-14 11:44:37 | INFO | train | epoch 023 | loss 1.962 | nll_loss 1.205 | ppl 2.31 | wps 16546.7 | ups 10.54 | wpb 1570.4 | bsz 240 | num_updates 345 | lr 0.000345065 | gnorm 1.492 | clip 66.7 | train_wall 1 | wall 25\n",
            "epoch 024:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:37 | INFO | fairseq.trainer | begin training epoch 24\n",
            "2025-05-14 11:44:39 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
            "2025-05-14 11:44:39 | INFO | train | epoch 024 | loss 2.009 | nll_loss 1.256 | ppl 2.39 | wps 16672.6 | ups 10.62 | wpb 1570.4 | bsz 240 | num_updates 360 | lr 0.000360064 | gnorm 1.715 | clip 80 | train_wall 1 | wall 27\n",
            "epoch 025:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:39 | INFO | fairseq.trainer | begin training epoch 25\n",
            "epoch 025:  93% 14/15 [00:01<00:00, 13.08it/s]2025-05-14 11:44:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint25.pt (epoch 25 @ 375 updates, score None) (writing took 0.12740157600001112 seconds)\n",
            "2025-05-14 11:44:40 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)\n",
            "2025-05-14 11:44:40 | INFO | train | epoch 025 | loss 1.819 | nll_loss 1.037 | ppl 2.05 | wps 15194.3 | ups 9.68 | wpb 1570.4 | bsz 240 | num_updates 375 | lr 0.000375062 | gnorm 1.256 | clip 60 | train_wall 1 | wall 28\n",
            "epoch 026:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:40 | INFO | fairseq.trainer | begin training epoch 26\n",
            "2025-05-14 11:44:41 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)\n",
            "2025-05-14 11:44:41 | INFO | train | epoch 026 | loss 1.789 | nll_loss 1.002 | ppl 2 | wps 23035.4 | ups 14.67 | wpb 1570.4 | bsz 240 | num_updates 390 | lr 0.000390061 | gnorm 1.319 | clip 73.3 | train_wall 1 | wall 29\n",
            "epoch 027:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:41 | INFO | fairseq.trainer | begin training epoch 27\n",
            "2025-05-14 11:44:42 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)\n",
            "2025-05-14 11:44:42 | INFO | train | epoch 027 | loss 1.727 | nll_loss 0.924 | ppl 1.9 | wps 24267 | ups 15.45 | wpb 1570.4 | bsz 240 | num_updates 405 | lr 0.000405059 | gnorm 1.201 | clip 53.3 | train_wall 1 | wall 30\n",
            "epoch 028:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:42 | INFO | fairseq.trainer | begin training epoch 28\n",
            "2025-05-14 11:44:43 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)\n",
            "2025-05-14 11:44:43 | INFO | train | epoch 028 | loss 1.716 | nll_loss 0.908 | ppl 1.88 | wps 24322 | ups 15.49 | wpb 1570.4 | bsz 240 | num_updates 420 | lr 0.000420058 | gnorm 1.423 | clip 66.7 | train_wall 1 | wall 31\n",
            "epoch 029:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:43 | INFO | fairseq.trainer | begin training epoch 29\n",
            "2025-05-14 11:44:44 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)\n",
            "2025-05-14 11:44:44 | INFO | train | epoch 029 | loss 1.634 | nll_loss 0.809 | ppl 1.75 | wps 24619.3 | ups 15.68 | wpb 1570.4 | bsz 240 | num_updates 435 | lr 0.000435056 | gnorm 0.964 | clip 40 | train_wall 1 | wall 32\n",
            "epoch 030:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:44 | INFO | fairseq.trainer | begin training epoch 30\n",
            "epoch 030:  80% 12/15 [00:00<00:00, 16.81it/s]2025-05-14 11:44:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint30.pt (epoch 30 @ 450 updates, score None) (writing took 0.08803201199998512 seconds)\n",
            "2025-05-14 11:44:45 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)\n",
            "2025-05-14 11:44:45 | INFO | train | epoch 030 | loss 1.628 | nll_loss 0.813 | ppl 1.76 | wps 22158.7 | ups 14.11 | wpb 1570.4 | bsz 240 | num_updates 450 | lr 0.000450055 | gnorm 1.099 | clip 40 | train_wall 1 | wall 33\n",
            "epoch 031:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:45 | INFO | fairseq.trainer | begin training epoch 31\n",
            "2025-05-14 11:44:46 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)\n",
            "2025-05-14 11:44:46 | INFO | train | epoch 031 | loss 1.571 | nll_loss 0.734 | ppl 1.66 | wps 23609.8 | ups 15.03 | wpb 1570.4 | bsz 240 | num_updates 465 | lr 0.000465054 | gnorm 0.898 | clip 26.7 | train_wall 1 | wall 34\n",
            "epoch 032:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:46 | INFO | fairseq.trainer | begin training epoch 32\n",
            "2025-05-14 11:44:47 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)\n",
            "2025-05-14 11:44:47 | INFO | train | epoch 032 | loss 1.512 | nll_loss 0.67 | ppl 1.59 | wps 24624.3 | ups 15.68 | wpb 1570.4 | bsz 240 | num_updates 480 | lr 0.000480052 | gnorm 0.756 | clip 20 | train_wall 1 | wall 35\n",
            "epoch 033:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:47 | INFO | fairseq.trainer | begin training epoch 33\n",
            "2025-05-14 11:44:48 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)\n",
            "2025-05-14 11:44:48 | INFO | train | epoch 033 | loss 1.505 | nll_loss 0.661 | ppl 1.58 | wps 24477.9 | ups 15.59 | wpb 1570.4 | bsz 240 | num_updates 495 | lr 0.00049505 | gnorm 0.757 | clip 13.3 | train_wall 1 | wall 36\n",
            "epoch 034:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:48 | INFO | fairseq.trainer | begin training epoch 34\n",
            "2025-05-14 11:44:49 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)\n",
            "2025-05-14 11:44:49 | INFO | train | epoch 034 | loss 1.497 | nll_loss 0.654 | ppl 1.57 | wps 25033.2 | ups 15.94 | wpb 1570.4 | bsz 240 | num_updates 510 | lr 0.000510049 | gnorm 0.858 | clip 20 | train_wall 1 | wall 37\n",
            "epoch 035:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:49 | INFO | fairseq.trainer | begin training epoch 35\n",
            "epoch 035:  80% 12/15 [00:00<00:00, 17.44it/s]2025-05-14 11:44:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint35.pt (epoch 35 @ 525 updates, score None) (writing took 0.08539643899985094 seconds)\n",
            "2025-05-14 11:44:50 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)\n",
            "2025-05-14 11:44:50 | INFO | train | epoch 035 | loss 1.486 | nll_loss 0.642 | ppl 1.56 | wps 22631.3 | ups 14.41 | wpb 1570.4 | bsz 240 | num_updates 525 | lr 0.000525047 | gnorm 1.13 | clip 53.3 | train_wall 1 | wall 38\n",
            "epoch 036:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:50 | INFO | fairseq.trainer | begin training epoch 36\n",
            "2025-05-14 11:44:51 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)\n",
            "2025-05-14 11:44:51 | INFO | train | epoch 036 | loss 1.44 | nll_loss 0.583 | ppl 1.5 | wps 18574.3 | ups 11.83 | wpb 1570.4 | bsz 240 | num_updates 540 | lr 0.000540046 | gnorm 0.768 | clip 13.3 | train_wall 1 | wall 39\n",
            "epoch 037:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:51 | INFO | fairseq.trainer | begin training epoch 37\n",
            "2025-05-14 11:44:53 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)\n",
            "2025-05-14 11:44:53 | INFO | train | epoch 037 | loss 1.437 | nll_loss 0.592 | ppl 1.51 | wps 16161.6 | ups 10.29 | wpb 1570.4 | bsz 240 | num_updates 555 | lr 0.000555044 | gnorm 0.866 | clip 20 | train_wall 1 | wall 41\n",
            "epoch 038:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:53 | INFO | fairseq.trainer | begin training epoch 38\n",
            "2025-05-14 11:44:54 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)\n",
            "2025-05-14 11:44:54 | INFO | train | epoch 038 | loss 1.415 | nll_loss 0.558 | ppl 1.47 | wps 24225.2 | ups 15.43 | wpb 1570.4 | bsz 240 | num_updates 570 | lr 0.000570043 | gnorm 0.793 | clip 20 | train_wall 1 | wall 42\n",
            "epoch 039:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:54 | INFO | fairseq.trainer | begin training epoch 39\n",
            "2025-05-14 11:44:55 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)\n",
            "2025-05-14 11:44:55 | INFO | train | epoch 039 | loss 1.378 | nll_loss 0.521 | ppl 1.44 | wps 24597.1 | ups 15.66 | wpb 1570.4 | bsz 240 | num_updates 585 | lr 0.000585041 | gnorm 0.717 | clip 20 | train_wall 1 | wall 43\n",
            "epoch 040:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:55 | INFO | fairseq.trainer | begin training epoch 40\n",
            "epoch 040:  93% 14/15 [00:00<00:00, 18.68it/s]2025-05-14 11:44:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:44:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint40.pt (epoch 40 @ 600 updates, score None) (writing took 0.08354844000018602 seconds)\n",
            "2025-05-14 11:44:56 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)\n",
            "2025-05-14 11:44:56 | INFO | train | epoch 040 | loss 1.362 | nll_loss 0.502 | ppl 1.42 | wps 22331.3 | ups 14.22 | wpb 1570.4 | bsz 240 | num_updates 600 | lr 0.00060004 | gnorm 0.767 | clip 13.3 | train_wall 1 | wall 44\n",
            "epoch 041:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:56 | INFO | fairseq.trainer | begin training epoch 41\n",
            "2025-05-14 11:44:57 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)\n",
            "2025-05-14 11:44:57 | INFO | train | epoch 041 | loss 1.336 | nll_loss 0.473 | ppl 1.39 | wps 24243.9 | ups 15.44 | wpb 1570.4 | bsz 240 | num_updates 615 | lr 0.000615038 | gnorm 0.684 | clip 13.3 | train_wall 1 | wall 45\n",
            "epoch 042:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:57 | INFO | fairseq.trainer | begin training epoch 42\n",
            "2025-05-14 11:44:58 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)\n",
            "2025-05-14 11:44:58 | INFO | train | epoch 042 | loss 1.328 | nll_loss 0.465 | ppl 1.38 | wps 25171.4 | ups 16.03 | wpb 1570.4 | bsz 240 | num_updates 630 | lr 0.000630037 | gnorm 0.661 | clip 6.7 | train_wall 1 | wall 46\n",
            "epoch 043:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:58 | INFO | fairseq.trainer | begin training epoch 43\n",
            "2025-05-14 11:44:59 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)\n",
            "2025-05-14 11:44:59 | INFO | train | epoch 043 | loss 1.369 | nll_loss 0.513 | ppl 1.43 | wps 24959.9 | ups 15.89 | wpb 1570.4 | bsz 240 | num_updates 645 | lr 0.000645035 | gnorm 0.943 | clip 26.7 | train_wall 1 | wall 47\n",
            "epoch 044:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:44:59 | INFO | fairseq.trainer | begin training epoch 44\n",
            "2025-05-14 11:45:00 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)\n",
            "2025-05-14 11:45:00 | INFO | train | epoch 044 | loss 1.313 | nll_loss 0.453 | ppl 1.37 | wps 24885 | ups 15.85 | wpb 1570.4 | bsz 240 | num_updates 660 | lr 0.000660034 | gnorm 0.607 | clip 0 | train_wall 1 | wall 48\n",
            "epoch 045:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:00 | INFO | fairseq.trainer | begin training epoch 45\n",
            "epoch 045:  87% 13/15 [00:00<00:00, 18.34it/s]2025-05-14 11:45:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint45.pt (epoch 45 @ 675 updates, score None) (writing took 0.11117621499988672 seconds)\n",
            "2025-05-14 11:45:01 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)\n",
            "2025-05-14 11:45:01 | INFO | train | epoch 045 | loss 1.322 | nll_loss 0.465 | ppl 1.38 | wps 21776.4 | ups 13.87 | wpb 1570.4 | bsz 240 | num_updates 675 | lr 0.000675032 | gnorm 0.769 | clip 6.7 | train_wall 1 | wall 49\n",
            "epoch 046:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:01 | INFO | fairseq.trainer | begin training epoch 46\n",
            "2025-05-14 11:45:02 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)\n",
            "2025-05-14 11:45:02 | INFO | train | epoch 046 | loss 1.337 | nll_loss 0.475 | ppl 1.39 | wps 23042.7 | ups 14.67 | wpb 1570.4 | bsz 240 | num_updates 690 | lr 0.000690031 | gnorm 0.833 | clip 33.3 | train_wall 1 | wall 50\n",
            "epoch 047:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:02 | INFO | fairseq.trainer | begin training epoch 47\n",
            "2025-05-14 11:45:03 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)\n",
            "2025-05-14 11:45:03 | INFO | train | epoch 047 | loss 1.314 | nll_loss 0.454 | ppl 1.37 | wps 24133 | ups 15.37 | wpb 1570.4 | bsz 240 | num_updates 705 | lr 0.000705029 | gnorm 0.807 | clip 20 | train_wall 1 | wall 51\n",
            "epoch 048:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:03 | INFO | fairseq.trainer | begin training epoch 48\n",
            "2025-05-14 11:45:04 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)\n",
            "2025-05-14 11:45:04 | INFO | train | epoch 048 | loss 1.285 | nll_loss 0.425 | ppl 1.34 | wps 18003 | ups 11.46 | wpb 1570.4 | bsz 240 | num_updates 720 | lr 0.000720028 | gnorm 0.609 | clip 6.7 | train_wall 1 | wall 52\n",
            "epoch 049:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:04 | INFO | fairseq.trainer | begin training epoch 49\n",
            "2025-05-14 11:45:05 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)\n",
            "2025-05-14 11:45:05 | INFO | train | epoch 049 | loss 1.263 | nll_loss 0.395 | ppl 1.32 | wps 16297 | ups 10.38 | wpb 1570.4 | bsz 240 | num_updates 735 | lr 0.000735026 | gnorm 0.592 | clip 6.7 | train_wall 1 | wall 53\n",
            "epoch 050:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:05 | INFO | fairseq.trainer | begin training epoch 50\n",
            "epoch 050:  87% 13/15 [00:00<00:00, 18.46it/s]2025-05-14 11:45:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint50.pt (epoch 50 @ 750 updates, score None) (writing took 0.08846091200007322 seconds)\n",
            "2025-05-14 11:45:07 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)\n",
            "2025-05-14 11:45:07 | INFO | train | epoch 050 | loss 1.261 | nll_loss 0.395 | ppl 1.32 | wps 22025.8 | ups 14.03 | wpb 1570.4 | bsz 240 | num_updates 750 | lr 0.000750025 | gnorm 0.69 | clip 6.7 | train_wall 1 | wall 54\n",
            "epoch 051:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:07 | INFO | fairseq.trainer | begin training epoch 51\n",
            "2025-05-14 11:45:07 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)\n",
            "2025-05-14 11:45:07 | INFO | train | epoch 051 | loss 1.238 | nll_loss 0.37 | ppl 1.29 | wps 24520.9 | ups 15.61 | wpb 1570.4 | bsz 240 | num_updates 765 | lr 0.000765023 | gnorm 0.563 | clip 13.3 | train_wall 1 | wall 55\n",
            "epoch 052:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:07 | INFO | fairseq.trainer | begin training epoch 52\n",
            "2025-05-14 11:45:08 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)\n",
            "2025-05-14 11:45:08 | INFO | train | epoch 052 | loss 1.233 | nll_loss 0.363 | ppl 1.29 | wps 24770.7 | ups 15.77 | wpb 1570.4 | bsz 240 | num_updates 780 | lr 0.000780022 | gnorm 0.541 | clip 0 | train_wall 1 | wall 56\n",
            "epoch 053:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:08 | INFO | fairseq.trainer | begin training epoch 53\n",
            "2025-05-14 11:45:09 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)\n",
            "2025-05-14 11:45:09 | INFO | train | epoch 053 | loss 1.312 | nll_loss 0.462 | ppl 1.38 | wps 24967.5 | ups 15.9 | wpb 1570.4 | bsz 240 | num_updates 795 | lr 0.00079502 | gnorm 0.989 | clip 26.7 | train_wall 1 | wall 57\n",
            "epoch 054:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:09 | INFO | fairseq.trainer | begin training epoch 54\n",
            "2025-05-14 11:45:10 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)\n",
            "2025-05-14 11:45:10 | INFO | train | epoch 054 | loss 1.266 | nll_loss 0.405 | ppl 1.32 | wps 24322.9 | ups 15.49 | wpb 1570.4 | bsz 240 | num_updates 810 | lr 0.000810019 | gnorm 0.734 | clip 13.3 | train_wall 1 | wall 58\n",
            "epoch 055:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:10 | INFO | fairseq.trainer | begin training epoch 55\n",
            "epoch 055:  93% 14/15 [00:00<00:00, 18.52it/s]2025-05-14 11:45:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint55.pt (epoch 55 @ 825 updates, score None) (writing took 0.09161157300013656 seconds)\n",
            "2025-05-14 11:45:11 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)\n",
            "2025-05-14 11:45:11 | INFO | train | epoch 055 | loss 1.25 | nll_loss 0.382 | ppl 1.3 | wps 22444.4 | ups 14.29 | wpb 1570.4 | bsz 240 | num_updates 825 | lr 0.000825017 | gnorm 0.718 | clip 20 | train_wall 1 | wall 59\n",
            "epoch 056:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:11 | INFO | fairseq.trainer | begin training epoch 56\n",
            "2025-05-14 11:45:12 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)\n",
            "2025-05-14 11:45:12 | INFO | train | epoch 056 | loss 1.229 | nll_loss 0.366 | ppl 1.29 | wps 24095.6 | ups 15.34 | wpb 1570.4 | bsz 240 | num_updates 840 | lr 0.000840016 | gnorm 0.597 | clip 6.7 | train_wall 1 | wall 60\n",
            "epoch 057:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:12 | INFO | fairseq.trainer | begin training epoch 57\n",
            "2025-05-14 11:45:13 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)\n",
            "2025-05-14 11:45:13 | INFO | train | epoch 057 | loss 1.21 | nll_loss 0.342 | ppl 1.27 | wps 23979.7 | ups 15.27 | wpb 1570.4 | bsz 240 | num_updates 855 | lr 0.000855014 | gnorm 0.504 | clip 6.7 | train_wall 1 | wall 61\n",
            "epoch 058:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:13 | INFO | fairseq.trainer | begin training epoch 58\n",
            "2025-05-14 11:45:14 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)\n",
            "2025-05-14 11:45:14 | INFO | train | epoch 058 | loss 1.189 | nll_loss 0.318 | ppl 1.25 | wps 24801.5 | ups 15.79 | wpb 1570.4 | bsz 240 | num_updates 870 | lr 0.000870013 | gnorm 0.493 | clip 0 | train_wall 1 | wall 62\n",
            "epoch 059:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:14 | INFO | fairseq.trainer | begin training epoch 59\n",
            "2025-05-14 11:45:15 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)\n",
            "2025-05-14 11:45:15 | INFO | train | epoch 059 | loss 1.2 | nll_loss 0.331 | ppl 1.26 | wps 24317.4 | ups 15.48 | wpb 1570.4 | bsz 240 | num_updates 885 | lr 0.000885011 | gnorm 0.565 | clip 6.7 | train_wall 1 | wall 63\n",
            "epoch 060:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:15 | INFO | fairseq.trainer | begin training epoch 60\n",
            "epoch 060:  87% 13/15 [00:01<00:00, 13.94it/s]2025-05-14 11:45:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint60.pt (epoch 60 @ 900 updates, score None) (writing took 0.12623164599995107 seconds)\n",
            "2025-05-14 11:45:17 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)\n",
            "2025-05-14 11:45:17 | INFO | train | epoch 060 | loss 1.201 | nll_loss 0.336 | ppl 1.26 | wps 15686.3 | ups 9.99 | wpb 1570.4 | bsz 240 | num_updates 900 | lr 0.00090001 | gnorm 0.547 | clip 6.7 | train_wall 1 | wall 65\n",
            "epoch 061:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:17 | INFO | fairseq.trainer | begin training epoch 61\n",
            "2025-05-14 11:45:18 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)\n",
            "2025-05-14 11:45:18 | INFO | train | epoch 061 | loss 1.18 | nll_loss 0.306 | ppl 1.24 | wps 16187.5 | ups 10.31 | wpb 1570.4 | bsz 240 | num_updates 915 | lr 0.000915008 | gnorm 0.478 | clip 0 | train_wall 1 | wall 66\n",
            "epoch 062:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:18 | INFO | fairseq.trainer | begin training epoch 62\n",
            "2025-05-14 11:45:19 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)\n",
            "2025-05-14 11:45:19 | INFO | train | epoch 062 | loss 1.178 | nll_loss 0.313 | ppl 1.24 | wps 24031.9 | ups 15.3 | wpb 1570.4 | bsz 240 | num_updates 930 | lr 0.000930007 | gnorm 0.452 | clip 0 | train_wall 1 | wall 67\n",
            "epoch 063:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:19 | INFO | fairseq.trainer | begin training epoch 63\n",
            "2025-05-14 11:45:20 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)\n",
            "2025-05-14 11:45:20 | INFO | train | epoch 063 | loss 1.173 | nll_loss 0.301 | ppl 1.23 | wps 24902.9 | ups 15.86 | wpb 1570.4 | bsz 240 | num_updates 945 | lr 0.000945005 | gnorm 0.485 | clip 0 | train_wall 1 | wall 68\n",
            "epoch 064:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:20 | INFO | fairseq.trainer | begin training epoch 64\n",
            "2025-05-14 11:45:21 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)\n",
            "2025-05-14 11:45:21 | INFO | train | epoch 064 | loss 1.164 | nll_loss 0.297 | ppl 1.23 | wps 24630 | ups 15.68 | wpb 1570.4 | bsz 240 | num_updates 960 | lr 0.000960004 | gnorm 0.456 | clip 6.7 | train_wall 1 | wall 69\n",
            "epoch 065:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:21 | INFO | fairseq.trainer | begin training epoch 65\n",
            "epoch 065:  93% 14/15 [00:00<00:00, 18.72it/s]2025-05-14 11:45:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint65.pt (epoch 65 @ 975 updates, score None) (writing took 0.08077703900016786 seconds)\n",
            "2025-05-14 11:45:22 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)\n",
            "2025-05-14 11:45:22 | INFO | train | epoch 065 | loss 1.157 | nll_loss 0.287 | ppl 1.22 | wps 22427.1 | ups 14.28 | wpb 1570.4 | bsz 240 | num_updates 975 | lr 0.000975002 | gnorm 0.45 | clip 0 | train_wall 1 | wall 70\n",
            "epoch 066:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:22 | INFO | fairseq.trainer | begin training epoch 66\n",
            "2025-05-14 11:45:23 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)\n",
            "2025-05-14 11:45:23 | INFO | train | epoch 066 | loss 1.163 | nll_loss 0.293 | ppl 1.23 | wps 24261.9 | ups 15.45 | wpb 1570.4 | bsz 240 | num_updates 990 | lr 0.000990001 | gnorm 0.48 | clip 6.7 | train_wall 1 | wall 71\n",
            "epoch 067:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:23 | INFO | fairseq.trainer | begin training epoch 67\n",
            "2025-05-14 11:45:24 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)\n",
            "2025-05-14 11:45:24 | INFO | train | epoch 067 | loss 1.158 | nll_loss 0.289 | ppl 1.22 | wps 24131.1 | ups 15.37 | wpb 1570.4 | bsz 240 | num_updates 1005 | lr 0.000997509 | gnorm 0.478 | clip 6.7 | train_wall 1 | wall 72\n",
            "epoch 068:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:24 | INFO | fairseq.trainer | begin training epoch 68\n",
            "2025-05-14 11:45:25 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)\n",
            "2025-05-14 11:45:25 | INFO | train | epoch 068 | loss 1.142 | nll_loss 0.269 | ppl 1.2 | wps 24537.3 | ups 15.62 | wpb 1570.4 | bsz 240 | num_updates 1020 | lr 0.000990148 | gnorm 0.418 | clip 0 | train_wall 1 | wall 73\n",
            "epoch 069:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:25 | INFO | fairseq.trainer | begin training epoch 69\n",
            "2025-05-14 11:45:26 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)\n",
            "2025-05-14 11:45:26 | INFO | train | epoch 069 | loss 1.145 | nll_loss 0.276 | ppl 1.21 | wps 23921.8 | ups 15.23 | wpb 1570.4 | bsz 240 | num_updates 1035 | lr 0.000982946 | gnorm 0.418 | clip 0 | train_wall 1 | wall 74\n",
            "epoch 070:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:26 | INFO | fairseq.trainer | begin training epoch 70\n",
            "epoch 070:  80% 12/15 [00:00<00:00, 17.80it/s]2025-05-14 11:45:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint70.pt (epoch 70 @ 1050 updates, score None) (writing took 0.09860637499991753 seconds)\n",
            "2025-05-14 11:45:27 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)\n",
            "2025-05-14 11:45:27 | INFO | train | epoch 070 | loss 1.131 | nll_loss 0.261 | ppl 1.2 | wps 21771.1 | ups 13.86 | wpb 1570.4 | bsz 240 | num_updates 1050 | lr 0.0009759 | gnorm 0.348 | clip 0 | train_wall 1 | wall 75\n",
            "epoch 071:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:27 | INFO | fairseq.trainer | begin training epoch 71\n",
            "2025-05-14 11:45:28 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)\n",
            "2025-05-14 11:45:28 | INFO | train | epoch 071 | loss 1.121 | nll_loss 0.249 | ppl 1.19 | wps 23715.3 | ups 15.1 | wpb 1570.4 | bsz 240 | num_updates 1065 | lr 0.000969003 | gnorm 0.341 | clip 0 | train_wall 1 | wall 76\n",
            "epoch 072:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:28 | INFO | fairseq.trainer | begin training epoch 72\n",
            "2025-05-14 11:45:29 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)\n",
            "2025-05-14 11:45:29 | INFO | train | epoch 072 | loss 1.116 | nll_loss 0.247 | ppl 1.19 | wps 17226.4 | ups 10.97 | wpb 1570.4 | bsz 240 | num_updates 1080 | lr 0.00096225 | gnorm 0.341 | clip 0 | train_wall 1 | wall 77\n",
            "epoch 073:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:30 | INFO | fairseq.trainer | begin training epoch 73\n",
            "2025-05-14 11:45:31 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)\n",
            "2025-05-14 11:45:31 | INFO | train | epoch 073 | loss 1.113 | nll_loss 0.244 | ppl 1.18 | wps 16228.3 | ups 10.33 | wpb 1570.4 | bsz 240 | num_updates 1095 | lr 0.000955637 | gnorm 0.375 | clip 0 | train_wall 1 | wall 79\n",
            "epoch 074:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:31 | INFO | fairseq.trainer | begin training epoch 74\n",
            "2025-05-14 11:45:32 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)\n",
            "2025-05-14 11:45:32 | INFO | train | epoch 074 | loss 1.117 | nll_loss 0.249 | ppl 1.19 | wps 23827.6 | ups 15.17 | wpb 1570.4 | bsz 240 | num_updates 1110 | lr 0.000949158 | gnorm 0.37 | clip 0 | train_wall 1 | wall 80\n",
            "epoch 075:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:32 | INFO | fairseq.trainer | begin training epoch 75\n",
            "epoch 075:  87% 13/15 [00:00<00:00, 17.83it/s]2025-05-14 11:45:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint75.pt (epoch 75 @ 1125 updates, score None) (writing took 0.08464918300001045 seconds)\n",
            "2025-05-14 11:45:33 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)\n",
            "2025-05-14 11:45:33 | INFO | train | epoch 075 | loss 1.112 | nll_loss 0.242 | ppl 1.18 | wps 22459.2 | ups 14.3 | wpb 1570.4 | bsz 240 | num_updates 1125 | lr 0.000942809 | gnorm 0.338 | clip 0 | train_wall 1 | wall 81\n",
            "epoch 076:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:33 | INFO | fairseq.trainer | begin training epoch 76\n",
            "2025-05-14 11:45:34 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)\n",
            "2025-05-14 11:45:34 | INFO | train | epoch 076 | loss 1.111 | nll_loss 0.24 | ppl 1.18 | wps 24522.5 | ups 15.62 | wpb 1570.4 | bsz 240 | num_updates 1140 | lr 0.000936586 | gnorm 0.361 | clip 0 | train_wall 1 | wall 82\n",
            "epoch 077:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:34 | INFO | fairseq.trainer | begin training epoch 77\n",
            "2025-05-14 11:45:35 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)\n",
            "2025-05-14 11:45:35 | INFO | train | epoch 077 | loss 1.102 | nll_loss 0.233 | ppl 1.18 | wps 24571.7 | ups 15.65 | wpb 1570.4 | bsz 240 | num_updates 1155 | lr 0.000930484 | gnorm 0.356 | clip 0 | train_wall 1 | wall 83\n",
            "epoch 078:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:35 | INFO | fairseq.trainer | begin training epoch 78\n",
            "2025-05-14 11:45:36 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)\n",
            "2025-05-14 11:45:36 | INFO | train | epoch 078 | loss 1.1 | nll_loss 0.23 | ppl 1.17 | wps 25449.9 | ups 16.21 | wpb 1570.4 | bsz 240 | num_updates 1170 | lr 0.0009245 | gnorm 0.339 | clip 0 | train_wall 1 | wall 84\n",
            "epoch 079:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:36 | INFO | fairseq.trainer | begin training epoch 79\n",
            "2025-05-14 11:45:37 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)\n",
            "2025-05-14 11:45:37 | INFO | train | epoch 079 | loss 1.115 | nll_loss 0.248 | ppl 1.19 | wps 24971.4 | ups 15.9 | wpb 1570.4 | bsz 240 | num_updates 1185 | lr 0.00091863 | gnorm 0.468 | clip 0 | train_wall 1 | wall 85\n",
            "epoch 080:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:37 | INFO | fairseq.trainer | begin training epoch 80\n",
            "epoch 080:  93% 14/15 [00:00<00:00, 18.61it/s]2025-05-14 11:45:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint80.pt (epoch 80 @ 1200 updates, score None) (writing took 0.08592050300012488 seconds)\n",
            "2025-05-14 11:45:38 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)\n",
            "2025-05-14 11:45:38 | INFO | train | epoch 080 | loss 1.13 | nll_loss 0.262 | ppl 1.2 | wps 21801.4 | ups 13.88 | wpb 1570.4 | bsz 240 | num_updates 1200 | lr 0.000912871 | gnorm 0.544 | clip 6.7 | train_wall 1 | wall 86\n",
            "epoch 081:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:38 | INFO | fairseq.trainer | begin training epoch 81\n",
            "2025-05-14 11:45:39 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)\n",
            "2025-05-14 11:45:39 | INFO | train | epoch 081 | loss 1.115 | nll_loss 0.249 | ppl 1.19 | wps 24254.7 | ups 15.44 | wpb 1570.4 | bsz 240 | num_updates 1215 | lr 0.000907218 | gnorm 0.444 | clip 0 | train_wall 1 | wall 87\n",
            "epoch 082:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:39 | INFO | fairseq.trainer | begin training epoch 82\n",
            "2025-05-14 11:45:40 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)\n",
            "2025-05-14 11:45:40 | INFO | train | epoch 082 | loss 1.098 | nll_loss 0.226 | ppl 1.17 | wps 24399.7 | ups 15.54 | wpb 1570.4 | bsz 240 | num_updates 1230 | lr 0.00090167 | gnorm 0.351 | clip 0 | train_wall 1 | wall 88\n",
            "epoch 083:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:40 | INFO | fairseq.trainer | begin training epoch 83\n",
            "2025-05-14 11:45:41 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)\n",
            "2025-05-14 11:45:41 | INFO | train | epoch 083 | loss 1.096 | nll_loss 0.225 | ppl 1.17 | wps 23052.7 | ups 14.68 | wpb 1570.4 | bsz 240 | num_updates 1245 | lr 0.000896221 | gnorm 0.327 | clip 0 | train_wall 1 | wall 89\n",
            "epoch 084:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:41 | INFO | fairseq.trainer | begin training epoch 84\n",
            "2025-05-14 11:45:42 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)\n",
            "2025-05-14 11:45:42 | INFO | train | epoch 084 | loss 1.083 | nll_loss 0.212 | ppl 1.16 | wps 16973.4 | ups 10.81 | wpb 1570.4 | bsz 240 | num_updates 1260 | lr 0.000890871 | gnorm 0.293 | clip 0 | train_wall 1 | wall 90\n",
            "epoch 085:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:42 | INFO | fairseq.trainer | begin training epoch 85\n",
            "epoch 085:  87% 13/15 [00:01<00:00, 12.46it/s]2025-05-14 11:45:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint85.pt (epoch 85 @ 1275 updates, score None) (writing took 0.08885478199999852 seconds)\n",
            "2025-05-14 11:45:44 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)\n",
            "2025-05-14 11:45:44 | INFO | train | epoch 085 | loss 1.094 | nll_loss 0.227 | ppl 1.17 | wps 14894.8 | ups 9.48 | wpb 1570.4 | bsz 240 | num_updates 1275 | lr 0.000885615 | gnorm 0.298 | clip 0 | train_wall 1 | wall 92\n",
            "epoch 086:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:44 | INFO | fairseq.trainer | begin training epoch 86\n",
            "2025-05-14 11:45:45 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)\n",
            "2025-05-14 11:45:45 | INFO | train | epoch 086 | loss 1.094 | nll_loss 0.226 | ppl 1.17 | wps 23848.5 | ups 15.19 | wpb 1570.4 | bsz 240 | num_updates 1290 | lr 0.000880451 | gnorm 0.369 | clip 0 | train_wall 1 | wall 93\n",
            "epoch 087:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:45 | INFO | fairseq.trainer | begin training epoch 87\n",
            "2025-05-14 11:45:46 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)\n",
            "2025-05-14 11:45:46 | INFO | train | epoch 087 | loss 1.085 | nll_loss 0.213 | ppl 1.16 | wps 23865.9 | ups 15.2 | wpb 1570.4 | bsz 240 | num_updates 1305 | lr 0.000875376 | gnorm 0.369 | clip 6.7 | train_wall 1 | wall 94\n",
            "epoch 088:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:46 | INFO | fairseq.trainer | begin training epoch 88\n",
            "2025-05-14 11:45:47 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)\n",
            "2025-05-14 11:45:47 | INFO | train | epoch 088 | loss 1.092 | nll_loss 0.228 | ppl 1.17 | wps 21957.1 | ups 13.98 | wpb 1570.4 | bsz 240 | num_updates 1320 | lr 0.000870388 | gnorm 0.361 | clip 0 | train_wall 1 | wall 95\n",
            "epoch 089:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:47 | INFO | fairseq.trainer | begin training epoch 89\n",
            "2025-05-14 11:45:48 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)\n",
            "2025-05-14 11:45:48 | INFO | train | epoch 089 | loss 1.092 | nll_loss 0.227 | ppl 1.17 | wps 24013.3 | ups 15.29 | wpb 1570.4 | bsz 240 | num_updates 1335 | lr 0.000865485 | gnorm 0.349 | clip 0 | train_wall 1 | wall 96\n",
            "epoch 090:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:48 | INFO | fairseq.trainer | begin training epoch 90\n",
            "epoch 090:  93% 14/15 [00:00<00:00, 18.31it/s]2025-05-14 11:45:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint90.pt (epoch 90 @ 1350 updates, score None) (writing took 0.07803243600005771 seconds)\n",
            "2025-05-14 11:45:49 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)\n",
            "2025-05-14 11:45:49 | INFO | train | epoch 090 | loss 1.078 | nll_loss 0.206 | ppl 1.15 | wps 21725.6 | ups 13.83 | wpb 1570.4 | bsz 240 | num_updates 1350 | lr 0.000860663 | gnorm 0.287 | clip 0 | train_wall 1 | wall 97\n",
            "epoch 091:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:49 | INFO | fairseq.trainer | begin training epoch 91\n",
            "2025-05-14 11:45:50 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)\n",
            "2025-05-14 11:45:50 | INFO | train | epoch 091 | loss 1.073 | nll_loss 0.203 | ppl 1.15 | wps 23661.1 | ups 15.07 | wpb 1570.4 | bsz 240 | num_updates 1365 | lr 0.000855921 | gnorm 0.282 | clip 0 | train_wall 1 | wall 98\n",
            "epoch 092:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:50 | INFO | fairseq.trainer | begin training epoch 92\n",
            "2025-05-14 11:45:51 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)\n",
            "2025-05-14 11:45:51 | INFO | train | epoch 092 | loss 1.074 | nll_loss 0.205 | ppl 1.15 | wps 24448.5 | ups 15.57 | wpb 1570.4 | bsz 240 | num_updates 1380 | lr 0.000851257 | gnorm 0.347 | clip 0 | train_wall 1 | wall 99\n",
            "epoch 093:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:51 | INFO | fairseq.trainer | begin training epoch 93\n",
            "2025-05-14 11:45:52 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)\n",
            "2025-05-14 11:45:52 | INFO | train | epoch 093 | loss 1.076 | nll_loss 0.208 | ppl 1.15 | wps 24894.2 | ups 15.85 | wpb 1570.4 | bsz 240 | num_updates 1395 | lr 0.000846668 | gnorm 0.309 | clip 0 | train_wall 1 | wall 100\n",
            "epoch 094:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:52 | INFO | fairseq.trainer | begin training epoch 94\n",
            "2025-05-14 11:45:53 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)\n",
            "2025-05-14 11:45:53 | INFO | train | epoch 094 | loss 1.073 | nll_loss 0.204 | ppl 1.15 | wps 24069.1 | ups 15.33 | wpb 1570.4 | bsz 240 | num_updates 1410 | lr 0.000842152 | gnorm 0.28 | clip 0 | train_wall 1 | wall 101\n",
            "epoch 095:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:53 | INFO | fairseq.trainer | begin training epoch 95\n",
            "epoch 095:  87% 13/15 [00:00<00:00, 17.41it/s]2025-05-14 11:45:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:45:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint95.pt (epoch 95 @ 1425 updates, score None) (writing took 0.12280932400017264 seconds)\n",
            "2025-05-14 11:45:54 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)\n",
            "2025-05-14 11:45:54 | INFO | train | epoch 095 | loss 1.072 | nll_loss 0.205 | ppl 1.15 | wps 20390.6 | ups 12.98 | wpb 1570.4 | bsz 240 | num_updates 1425 | lr 0.000837708 | gnorm 0.262 | clip 0 | train_wall 1 | wall 102\n",
            "epoch 096:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:54 | INFO | fairseq.trainer | begin training epoch 96\n",
            "2025-05-14 11:45:55 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)\n",
            "2025-05-14 11:45:55 | INFO | train | epoch 096 | loss 1.068 | nll_loss 0.198 | ppl 1.15 | wps 16807.9 | ups 10.7 | wpb 1570.4 | bsz 240 | num_updates 1440 | lr 0.000833333 | gnorm 0.269 | clip 0 | train_wall 1 | wall 103\n",
            "epoch 097:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:55 | INFO | fairseq.trainer | begin training epoch 97\n",
            "2025-05-14 11:45:57 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)\n",
            "2025-05-14 11:45:57 | INFO | train | epoch 097 | loss 1.062 | nll_loss 0.193 | ppl 1.14 | wps 18144.8 | ups 11.55 | wpb 1570.4 | bsz 240 | num_updates 1455 | lr 0.000829027 | gnorm 0.241 | clip 0 | train_wall 1 | wall 105\n",
            "epoch 098:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:57 | INFO | fairseq.trainer | begin training epoch 98\n",
            "2025-05-14 11:45:58 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)\n",
            "2025-05-14 11:45:58 | INFO | train | epoch 098 | loss 1.065 | nll_loss 0.197 | ppl 1.15 | wps 23871.5 | ups 15.2 | wpb 1570.4 | bsz 240 | num_updates 1470 | lr 0.000824786 | gnorm 0.308 | clip 0 | train_wall 1 | wall 106\n",
            "epoch 099:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:58 | INFO | fairseq.trainer | begin training epoch 99\n",
            "2025-05-14 11:45:59 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)\n",
            "2025-05-14 11:45:59 | INFO | train | epoch 099 | loss 1.062 | nll_loss 0.194 | ppl 1.14 | wps 24180.8 | ups 15.4 | wpb 1570.4 | bsz 240 | num_updates 1485 | lr 0.00082061 | gnorm 0.274 | clip 0 | train_wall 1 | wall 107\n",
            "epoch 100:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:45:59 | INFO | fairseq.trainer | begin training epoch 100\n",
            "epoch 100:  93% 14/15 [00:00<00:00, 18.87it/s]2025-05-14 11:46:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint100.pt (epoch 100 @ 1500 updates, score None) (writing took 0.07992235200003961 seconds)\n",
            "2025-05-14 11:46:00 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)\n",
            "2025-05-14 11:46:00 | INFO | train | epoch 100 | loss 1.063 | nll_loss 0.191 | ppl 1.14 | wps 22326.3 | ups 14.22 | wpb 1570.4 | bsz 240 | num_updates 1500 | lr 0.000816497 | gnorm 0.262 | clip 0 | train_wall 1 | wall 108\n",
            "epoch 101:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:00 | INFO | fairseq.trainer | begin training epoch 101\n",
            "2025-05-14 11:46:01 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)\n",
            "2025-05-14 11:46:01 | INFO | train | epoch 101 | loss 1.061 | nll_loss 0.195 | ppl 1.14 | wps 24052.3 | ups 15.32 | wpb 1570.4 | bsz 240 | num_updates 1515 | lr 0.000812444 | gnorm 0.246 | clip 0 | train_wall 1 | wall 109\n",
            "epoch 102:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:01 | INFO | fairseq.trainer | begin training epoch 102\n",
            "2025-05-14 11:46:02 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)\n",
            "2025-05-14 11:46:02 | INFO | train | epoch 102 | loss 1.059 | nll_loss 0.19 | ppl 1.14 | wps 23440.1 | ups 14.93 | wpb 1570.4 | bsz 240 | num_updates 1530 | lr 0.000808452 | gnorm 0.256 | clip 0 | train_wall 1 | wall 110\n",
            "epoch 103:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:02 | INFO | fairseq.trainer | begin training epoch 103\n",
            "2025-05-14 11:46:03 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)\n",
            "2025-05-14 11:46:03 | INFO | train | epoch 103 | loss 1.062 | nll_loss 0.197 | ppl 1.15 | wps 23886.8 | ups 15.21 | wpb 1570.4 | bsz 240 | num_updates 1545 | lr 0.000804518 | gnorm 0.281 | clip 0 | train_wall 1 | wall 111\n",
            "epoch 104:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:03 | INFO | fairseq.trainer | begin training epoch 104\n",
            "2025-05-14 11:46:04 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)\n",
            "2025-05-14 11:46:04 | INFO | train | epoch 104 | loss 1.059 | nll_loss 0.189 | ppl 1.14 | wps 23581.2 | ups 15.02 | wpb 1570.4 | bsz 240 | num_updates 1560 | lr 0.000800641 | gnorm 0.25 | clip 0 | train_wall 1 | wall 112\n",
            "epoch 105:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:04 | INFO | fairseq.trainer | begin training epoch 105\n",
            "epoch 105:  80% 12/15 [00:00<00:00, 16.94it/s]2025-05-14 11:46:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint105.pt (epoch 105 @ 1575 updates, score None) (writing took 0.07668905900004575 seconds)\n",
            "2025-05-14 11:46:05 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)\n",
            "2025-05-14 11:46:05 | INFO | train | epoch 105 | loss 1.059 | nll_loss 0.193 | ppl 1.14 | wps 20742.7 | ups 13.21 | wpb 1570.4 | bsz 240 | num_updates 1575 | lr 0.000796819 | gnorm 0.308 | clip 0 | train_wall 1 | wall 113\n",
            "epoch 106:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:05 | INFO | fairseq.trainer | begin training epoch 106\n",
            "2025-05-14 11:46:06 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)\n",
            "2025-05-14 11:46:06 | INFO | train | epoch 106 | loss 1.065 | nll_loss 0.198 | ppl 1.15 | wps 23419.8 | ups 14.91 | wpb 1570.4 | bsz 240 | num_updates 1590 | lr 0.000793052 | gnorm 0.341 | clip 0 | train_wall 1 | wall 114\n",
            "epoch 107:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:06 | INFO | fairseq.trainer | begin training epoch 107\n",
            "2025-05-14 11:46:07 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)\n",
            "2025-05-14 11:46:07 | INFO | train | epoch 107 | loss 1.062 | nll_loss 0.196 | ppl 1.15 | wps 19402 | ups 12.35 | wpb 1570.4 | bsz 240 | num_updates 1605 | lr 0.000789337 | gnorm 0.311 | clip 0 | train_wall 1 | wall 115\n",
            "epoch 108:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:07 | INFO | fairseq.trainer | begin training epoch 108\n",
            "2025-05-14 11:46:09 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)\n",
            "2025-05-14 11:46:09 | INFO | train | epoch 108 | loss 1.058 | nll_loss 0.192 | ppl 1.14 | wps 15052.8 | ups 9.59 | wpb 1570.4 | bsz 240 | num_updates 1620 | lr 0.000785674 | gnorm 0.279 | clip 0 | train_wall 1 | wall 117\n",
            "epoch 109:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:09 | INFO | fairseq.trainer | begin training epoch 109\n",
            "2025-05-14 11:46:10 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)\n",
            "2025-05-14 11:46:10 | INFO | train | epoch 109 | loss 1.058 | nll_loss 0.19 | ppl 1.14 | wps 20122.6 | ups 12.81 | wpb 1570.4 | bsz 240 | num_updates 1635 | lr 0.000782062 | gnorm 0.237 | clip 0 | train_wall 1 | wall 118\n",
            "epoch 110:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:10 | INFO | fairseq.trainer | begin training epoch 110\n",
            "epoch 110:  80% 12/15 [00:00<00:00, 17.04it/s]2025-05-14 11:46:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint110.pt (epoch 110 @ 1650 updates, score None) (writing took 0.0921628520000013 seconds)\n",
            "2025-05-14 11:46:11 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)\n",
            "2025-05-14 11:46:11 | INFO | train | epoch 110 | loss 1.057 | nll_loss 0.191 | ppl 1.14 | wps 21495.6 | ups 13.69 | wpb 1570.4 | bsz 240 | num_updates 1650 | lr 0.000778499 | gnorm 0.268 | clip 0 | train_wall 1 | wall 119\n",
            "epoch 111:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:11 | INFO | fairseq.trainer | begin training epoch 111\n",
            "2025-05-14 11:46:12 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)\n",
            "2025-05-14 11:46:12 | INFO | train | epoch 111 | loss 1.053 | nll_loss 0.185 | ppl 1.14 | wps 22180.1 | ups 14.12 | wpb 1570.4 | bsz 240 | num_updates 1665 | lr 0.000774984 | gnorm 0.272 | clip 0 | train_wall 1 | wall 120\n",
            "epoch 112:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:12 | INFO | fairseq.trainer | begin training epoch 112\n",
            "2025-05-14 11:46:13 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)\n",
            "2025-05-14 11:46:13 | INFO | train | epoch 112 | loss 1.056 | nll_loss 0.189 | ppl 1.14 | wps 24099.6 | ups 15.35 | wpb 1570.4 | bsz 240 | num_updates 1680 | lr 0.000771517 | gnorm 0.264 | clip 0 | train_wall 1 | wall 121\n",
            "epoch 113:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:13 | INFO | fairseq.trainer | begin training epoch 113\n",
            "2025-05-14 11:46:14 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)\n",
            "2025-05-14 11:46:14 | INFO | train | epoch 113 | loss 1.055 | nll_loss 0.189 | ppl 1.14 | wps 23987.6 | ups 15.27 | wpb 1570.4 | bsz 240 | num_updates 1695 | lr 0.000768095 | gnorm 0.264 | clip 0 | train_wall 1 | wall 122\n",
            "epoch 114:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:14 | INFO | fairseq.trainer | begin training epoch 114\n",
            "2025-05-14 11:46:15 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)\n",
            "2025-05-14 11:46:15 | INFO | train | epoch 114 | loss 1.051 | nll_loss 0.183 | ppl 1.14 | wps 23963.3 | ups 15.26 | wpb 1570.4 | bsz 240 | num_updates 1710 | lr 0.000764719 | gnorm 0.245 | clip 0 | train_wall 1 | wall 123\n",
            "epoch 115:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:15 | INFO | fairseq.trainer | begin training epoch 115\n",
            "epoch 115:  87% 13/15 [00:00<00:00, 17.38it/s]2025-05-14 11:46:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint115.pt (epoch 115 @ 1725 updates, score None) (writing took 0.1792207060000237 seconds)\n",
            "2025-05-14 11:46:16 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)\n",
            "2025-05-14 11:46:16 | INFO | train | epoch 115 | loss 1.048 | nll_loss 0.182 | ppl 1.13 | wps 20297.9 | ups 12.93 | wpb 1570.4 | bsz 240 | num_updates 1725 | lr 0.000761387 | gnorm 0.273 | clip 0 | train_wall 1 | wall 124\n",
            "epoch 116:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:16 | INFO | fairseq.trainer | begin training epoch 116\n",
            "2025-05-14 11:46:17 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)\n",
            "2025-05-14 11:46:17 | INFO | train | epoch 116 | loss 1.051 | nll_loss 0.186 | ppl 1.14 | wps 23300.9 | ups 14.84 | wpb 1570.4 | bsz 240 | num_updates 1740 | lr 0.000758098 | gnorm 0.254 | clip 0 | train_wall 1 | wall 125\n",
            "epoch 117:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:17 | INFO | fairseq.trainer | begin training epoch 117\n",
            "2025-05-14 11:46:18 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)\n",
            "2025-05-14 11:46:18 | INFO | train | epoch 117 | loss 1.055 | nll_loss 0.19 | ppl 1.14 | wps 23688 | ups 15.08 | wpb 1570.4 | bsz 240 | num_updates 1755 | lr 0.000754851 | gnorm 0.303 | clip 6.7 | train_wall 1 | wall 126\n",
            "epoch 118:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:18 | INFO | fairseq.trainer | begin training epoch 118\n",
            "2025-05-14 11:46:19 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)\n",
            "2025-05-14 11:46:19 | INFO | train | epoch 118 | loss 1.06 | nll_loss 0.193 | ppl 1.14 | wps 22740.4 | ups 14.48 | wpb 1570.4 | bsz 240 | num_updates 1770 | lr 0.000751646 | gnorm 0.346 | clip 0 | train_wall 1 | wall 127\n",
            "epoch 119:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:19 | INFO | fairseq.trainer | begin training epoch 119\n",
            "2025-05-14 11:46:20 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)\n",
            "2025-05-14 11:46:20 | INFO | train | epoch 119 | loss 1.064 | nll_loss 0.201 | ppl 1.15 | wps 16885.8 | ups 10.75 | wpb 1570.4 | bsz 240 | num_updates 1785 | lr 0.000748481 | gnorm 0.362 | clip 0 | train_wall 1 | wall 128\n",
            "epoch 120:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:20 | INFO | fairseq.trainer | begin training epoch 120\n",
            "epoch 120:  93% 14/15 [00:01<00:00, 14.64it/s]2025-05-14 11:46:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint120.pt (epoch 120 @ 1800 updates, score None) (writing took 0.10489424800016423 seconds)\n",
            "2025-05-14 11:46:22 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)\n",
            "2025-05-14 11:46:22 | INFO | train | epoch 120 | loss 1.057 | nll_loss 0.19 | ppl 1.14 | wps 15622.4 | ups 9.95 | wpb 1570.4 | bsz 240 | num_updates 1800 | lr 0.000745356 | gnorm 0.271 | clip 0 | train_wall 1 | wall 130\n",
            "epoch 121:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:22 | INFO | fairseq.trainer | begin training epoch 121\n",
            "2025-05-14 11:46:23 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)\n",
            "2025-05-14 11:46:23 | INFO | train | epoch 121 | loss 1.047 | nll_loss 0.181 | ppl 1.13 | wps 23908 | ups 15.22 | wpb 1570.4 | bsz 240 | num_updates 1815 | lr 0.00074227 | gnorm 0.198 | clip 0 | train_wall 1 | wall 131\n",
            "epoch 122:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:23 | INFO | fairseq.trainer | begin training epoch 122\n",
            "2025-05-14 11:46:24 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)\n",
            "2025-05-14 11:46:24 | INFO | train | epoch 122 | loss 1.047 | nll_loss 0.18 | ppl 1.13 | wps 24478.5 | ups 15.59 | wpb 1570.4 | bsz 240 | num_updates 1830 | lr 0.000739221 | gnorm 0.232 | clip 0 | train_wall 1 | wall 132\n",
            "epoch 123:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:24 | INFO | fairseq.trainer | begin training epoch 123\n",
            "2025-05-14 11:46:25 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)\n",
            "2025-05-14 11:46:25 | INFO | train | epoch 123 | loss 1.044 | nll_loss 0.178 | ppl 1.13 | wps 23854.4 | ups 15.19 | wpb 1570.4 | bsz 240 | num_updates 1845 | lr 0.00073621 | gnorm 0.221 | clip 0 | train_wall 1 | wall 133\n",
            "epoch 124:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:25 | INFO | fairseq.trainer | begin training epoch 124\n",
            "2025-05-14 11:46:26 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)\n",
            "2025-05-14 11:46:26 | INFO | train | epoch 124 | loss 1.044 | nll_loss 0.177 | ppl 1.13 | wps 23792.3 | ups 15.15 | wpb 1570.4 | bsz 240 | num_updates 1860 | lr 0.000733236 | gnorm 0.253 | clip 0 | train_wall 1 | wall 134\n",
            "epoch 125:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:26 | INFO | fairseq.trainer | begin training epoch 125\n",
            "epoch 125:  93% 14/15 [00:00<00:00, 18.43it/s]2025-05-14 11:46:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint125.pt (epoch 125 @ 1875 updates, score None) (writing took 0.09562457200013341 seconds)\n",
            "2025-05-14 11:46:27 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)\n",
            "2025-05-14 11:46:27 | INFO | train | epoch 125 | loss 1.049 | nll_loss 0.184 | ppl 1.14 | wps 21670 | ups 13.8 | wpb 1570.4 | bsz 240 | num_updates 1875 | lr 0.000730297 | gnorm 0.279 | clip 0 | train_wall 1 | wall 135\n",
            "epoch 126:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:27 | INFO | fairseq.trainer | begin training epoch 126\n",
            "2025-05-14 11:46:28 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)\n",
            "2025-05-14 11:46:28 | INFO | train | epoch 126 | loss 1.048 | nll_loss 0.184 | ppl 1.14 | wps 23362.5 | ups 14.88 | wpb 1570.4 | bsz 240 | num_updates 1890 | lr 0.000727393 | gnorm 0.234 | clip 0 | train_wall 1 | wall 136\n",
            "epoch 127:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:28 | INFO | fairseq.trainer | begin training epoch 127\n",
            "2025-05-14 11:46:29 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)\n",
            "2025-05-14 11:46:29 | INFO | train | epoch 127 | loss 1.044 | nll_loss 0.175 | ppl 1.13 | wps 23372.5 | ups 14.88 | wpb 1570.4 | bsz 240 | num_updates 1905 | lr 0.000724524 | gnorm 0.22 | clip 0 | train_wall 1 | wall 137\n",
            "epoch 128:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:29 | INFO | fairseq.trainer | begin training epoch 128\n",
            "2025-05-14 11:46:30 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)\n",
            "2025-05-14 11:46:30 | INFO | train | epoch 128 | loss 1.04 | nll_loss 0.172 | ppl 1.13 | wps 23223.9 | ups 14.79 | wpb 1570.4 | bsz 240 | num_updates 1920 | lr 0.000721688 | gnorm 0.19 | clip 0 | train_wall 1 | wall 138\n",
            "epoch 129:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:30 | INFO | fairseq.trainer | begin training epoch 129\n",
            "2025-05-14 11:46:31 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)\n",
            "2025-05-14 11:46:31 | INFO | train | epoch 129 | loss 1.047 | nll_loss 0.183 | ppl 1.14 | wps 23407.6 | ups 14.91 | wpb 1570.4 | bsz 240 | num_updates 1935 | lr 0.000718885 | gnorm 0.312 | clip 0 | train_wall 1 | wall 139\n",
            "epoch 130:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:31 | INFO | fairseq.trainer | begin training epoch 130\n",
            "epoch 130:  93% 14/15 [00:01<00:00, 14.16it/s]2025-05-14 11:46:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint130.pt (epoch 130 @ 1950 updates, score None) (writing took 0.12013228099999651 seconds)\n",
            "2025-05-14 11:46:32 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)\n",
            "2025-05-14 11:46:32 | INFO | train | epoch 130 | loss 1.048 | nll_loss 0.186 | ppl 1.14 | wps 18091.1 | ups 11.52 | wpb 1570.4 | bsz 240 | num_updates 1950 | lr 0.000716115 | gnorm 0.335 | clip 6.7 | train_wall 1 | wall 140\n",
            "epoch 131:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:32 | INFO | fairseq.trainer | begin training epoch 131\n",
            "2025-05-14 11:46:34 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)\n",
            "2025-05-14 11:46:34 | INFO | train | epoch 131 | loss 1.052 | nll_loss 0.186 | ppl 1.14 | wps 15841.7 | ups 10.09 | wpb 1570.4 | bsz 240 | num_updates 1965 | lr 0.000713376 | gnorm 0.292 | clip 0 | train_wall 1 | wall 142\n",
            "epoch 132:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:34 | INFO | fairseq.trainer | begin training epoch 132\n",
            "2025-05-14 11:46:35 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)\n",
            "2025-05-14 11:46:35 | INFO | train | epoch 132 | loss 1.048 | nll_loss 0.184 | ppl 1.14 | wps 20138.4 | ups 12.82 | wpb 1570.4 | bsz 240 | num_updates 1980 | lr 0.000710669 | gnorm 0.287 | clip 0 | train_wall 1 | wall 143\n",
            "epoch 133:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:35 | INFO | fairseq.trainer | begin training epoch 133\n",
            "2025-05-14 11:46:36 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)\n",
            "2025-05-14 11:46:36 | INFO | train | epoch 133 | loss 1.052 | nll_loss 0.189 | ppl 1.14 | wps 24231.3 | ups 15.43 | wpb 1570.4 | bsz 240 | num_updates 1995 | lr 0.000707992 | gnorm 0.332 | clip 0 | train_wall 1 | wall 144\n",
            "epoch 134:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:36 | INFO | fairseq.trainer | begin training epoch 134\n",
            "2025-05-14 11:46:37 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)\n",
            "2025-05-14 11:46:37 | INFO | train | epoch 134 | loss 1.048 | nll_loss 0.184 | ppl 1.14 | wps 23724.3 | ups 15.11 | wpb 1570.4 | bsz 240 | num_updates 2010 | lr 0.000705346 | gnorm 0.234 | clip 0 | train_wall 1 | wall 145\n",
            "epoch 135:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:37 | INFO | fairseq.trainer | begin training epoch 135\n",
            "epoch 135:  93% 14/15 [00:00<00:00, 17.82it/s]2025-05-14 11:46:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint135.pt (epoch 135 @ 2025 updates, score None) (writing took 0.0904215440000371 seconds)\n",
            "2025-05-14 11:46:38 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)\n",
            "2025-05-14 11:46:38 | INFO | train | epoch 135 | loss 1.046 | nll_loss 0.18 | ppl 1.13 | wps 21620 | ups 13.77 | wpb 1570.4 | bsz 240 | num_updates 2025 | lr 0.000702728 | gnorm 0.248 | clip 0 | train_wall 1 | wall 146\n",
            "epoch 136:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:38 | INFO | fairseq.trainer | begin training epoch 136\n",
            "2025-05-14 11:46:39 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)\n",
            "2025-05-14 11:46:39 | INFO | train | epoch 136 | loss 1.04 | nll_loss 0.174 | ppl 1.13 | wps 23834.3 | ups 15.18 | wpb 1570.4 | bsz 240 | num_updates 2040 | lr 0.00070014 | gnorm 0.257 | clip 0 | train_wall 1 | wall 147\n",
            "epoch 137:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:39 | INFO | fairseq.trainer | begin training epoch 137\n",
            "2025-05-14 11:46:40 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)\n",
            "2025-05-14 11:46:40 | INFO | train | epoch 137 | loss 1.045 | nll_loss 0.183 | ppl 1.14 | wps 23751.1 | ups 15.12 | wpb 1570.4 | bsz 240 | num_updates 2055 | lr 0.00069758 | gnorm 0.253 | clip 0 | train_wall 1 | wall 148\n",
            "epoch 138:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:40 | INFO | fairseq.trainer | begin training epoch 138\n",
            "2025-05-14 11:46:41 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)\n",
            "2025-05-14 11:46:41 | INFO | train | epoch 138 | loss 1.042 | nll_loss 0.175 | ppl 1.13 | wps 23676.2 | ups 15.08 | wpb 1570.4 | bsz 240 | num_updates 2070 | lr 0.000695048 | gnorm 0.205 | clip 0 | train_wall 1 | wall 149\n",
            "epoch 139:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:41 | INFO | fairseq.trainer | begin training epoch 139\n",
            "2025-05-14 11:46:42 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)\n",
            "2025-05-14 11:46:42 | INFO | train | epoch 139 | loss 1.042 | nll_loss 0.178 | ppl 1.13 | wps 23126.5 | ups 14.73 | wpb 1570.4 | bsz 240 | num_updates 2085 | lr 0.000692543 | gnorm 0.298 | clip 0 | train_wall 1 | wall 150\n",
            "epoch 140:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:42 | INFO | fairseq.trainer | begin training epoch 140\n",
            "epoch 140:  93% 14/15 [00:00<00:00, 18.11it/s]2025-05-14 11:46:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint140.pt (epoch 140 @ 2100 updates, score None) (writing took 0.08545615399998496 seconds)\n",
            "2025-05-14 11:46:43 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)\n",
            "2025-05-14 11:46:43 | INFO | train | epoch 140 | loss 1.043 | nll_loss 0.179 | ppl 1.13 | wps 21928.4 | ups 13.96 | wpb 1570.4 | bsz 240 | num_updates 2100 | lr 0.000690066 | gnorm 0.254 | clip 0 | train_wall 1 | wall 151\n",
            "epoch 141:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:43 | INFO | fairseq.trainer | begin training epoch 141\n",
            "2025-05-14 11:46:44 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)\n",
            "2025-05-14 11:46:44 | INFO | train | epoch 141 | loss 1.042 | nll_loss 0.177 | ppl 1.13 | wps 23506 | ups 14.97 | wpb 1570.4 | bsz 240 | num_updates 2115 | lr 0.000687614 | gnorm 0.247 | clip 0 | train_wall 1 | wall 152\n",
            "epoch 142:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:44 | INFO | fairseq.trainer | begin training epoch 142\n",
            "2025-05-14 11:46:45 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)\n",
            "2025-05-14 11:46:45 | INFO | train | epoch 142 | loss 1.038 | nll_loss 0.173 | ppl 1.13 | wps 17676.8 | ups 11.26 | wpb 1570.4 | bsz 240 | num_updates 2130 | lr 0.000685189 | gnorm 0.215 | clip 0 | train_wall 1 | wall 153\n",
            "epoch 143:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:45 | INFO | fairseq.trainer | begin training epoch 143\n",
            "2025-05-14 11:46:47 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)\n",
            "2025-05-14 11:46:47 | INFO | train | epoch 143 | loss 1.036 | nll_loss 0.169 | ppl 1.12 | wps 14762.9 | ups 9.4 | wpb 1570.4 | bsz 240 | num_updates 2145 | lr 0.000682789 | gnorm 0.205 | clip 0 | train_wall 1 | wall 155\n",
            "epoch 144:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:47 | INFO | fairseq.trainer | begin training epoch 144\n",
            "2025-05-14 11:46:48 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)\n",
            "2025-05-14 11:46:48 | INFO | train | epoch 144 | loss 1.035 | nll_loss 0.171 | ppl 1.13 | wps 23339.8 | ups 14.86 | wpb 1570.4 | bsz 240 | num_updates 2160 | lr 0.000680414 | gnorm 0.197 | clip 0 | train_wall 1 | wall 156\n",
            "epoch 145:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:48 | INFO | fairseq.trainer | begin training epoch 145\n",
            "epoch 145:  80% 12/15 [00:00<00:00, 17.83it/s]2025-05-14 11:46:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint145.pt (epoch 145 @ 2175 updates, score None) (writing took 0.10044630799984589 seconds)\n",
            "2025-05-14 11:46:49 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)\n",
            "2025-05-14 11:46:49 | INFO | train | epoch 145 | loss 1.034 | nll_loss 0.167 | ppl 1.12 | wps 21820.3 | ups 13.89 | wpb 1570.4 | bsz 240 | num_updates 2175 | lr 0.000678064 | gnorm 0.19 | clip 0 | train_wall 1 | wall 157\n",
            "epoch 146:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:49 | INFO | fairseq.trainer | begin training epoch 146\n",
            "2025-05-14 11:46:50 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)\n",
            "2025-05-14 11:46:50 | INFO | train | epoch 146 | loss 1.034 | nll_loss 0.17 | ppl 1.13 | wps 23224.3 | ups 14.79 | wpb 1570.4 | bsz 240 | num_updates 2190 | lr 0.000675737 | gnorm 0.202 | clip 0 | train_wall 1 | wall 158\n",
            "epoch 147:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:50 | INFO | fairseq.trainer | begin training epoch 147\n",
            "2025-05-14 11:46:51 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)\n",
            "2025-05-14 11:46:51 | INFO | train | epoch 147 | loss 1.035 | nll_loss 0.171 | ppl 1.13 | wps 23142.7 | ups 14.74 | wpb 1570.4 | bsz 240 | num_updates 2205 | lr 0.000673435 | gnorm 0.197 | clip 0 | train_wall 1 | wall 159\n",
            "epoch 148:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:51 | INFO | fairseq.trainer | begin training epoch 148\n",
            "2025-05-14 11:46:52 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)\n",
            "2025-05-14 11:46:52 | INFO | train | epoch 148 | loss 1.034 | nll_loss 0.171 | ppl 1.13 | wps 24530.2 | ups 15.62 | wpb 1570.4 | bsz 240 | num_updates 2220 | lr 0.000671156 | gnorm 0.207 | clip 0 | train_wall 1 | wall 160\n",
            "epoch 149:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:52 | INFO | fairseq.trainer | begin training epoch 149\n",
            "2025-05-14 11:46:53 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)\n",
            "2025-05-14 11:46:53 | INFO | train | epoch 149 | loss 1.033 | nll_loss 0.166 | ppl 1.12 | wps 23754.3 | ups 15.13 | wpb 1570.4 | bsz 240 | num_updates 2235 | lr 0.0006689 | gnorm 0.187 | clip 0 | train_wall 1 | wall 161\n",
            "epoch 150:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:53 | INFO | fairseq.trainer | begin training epoch 150\n",
            "epoch 150:  87% 13/15 [00:00<00:00, 17.58it/s]2025-05-14 11:46:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:46:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint150.pt (epoch 150 @ 2250 updates, score None) (writing took 0.0938023549999798 seconds)\n",
            "2025-05-14 11:46:54 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)\n",
            "2025-05-14 11:46:54 | INFO | train | epoch 150 | loss 1.032 | nll_loss 0.17 | ppl 1.12 | wps 21600.8 | ups 13.75 | wpb 1570.4 | bsz 240 | num_updates 2250 | lr 0.000666667 | gnorm 0.17 | clip 0 | train_wall 1 | wall 162\n",
            "epoch 151:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:54 | INFO | fairseq.trainer | begin training epoch 151\n",
            "2025-05-14 11:46:55 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)\n",
            "2025-05-14 11:46:55 | INFO | train | epoch 151 | loss 1.032 | nll_loss 0.166 | ppl 1.12 | wps 24605.4 | ups 15.67 | wpb 1570.4 | bsz 240 | num_updates 2265 | lr 0.000664455 | gnorm 0.178 | clip 0 | train_wall 1 | wall 163\n",
            "epoch 152:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:55 | INFO | fairseq.trainer | begin training epoch 152\n",
            "2025-05-14 11:46:56 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)\n",
            "2025-05-14 11:46:56 | INFO | train | epoch 152 | loss 1.032 | nll_loss 0.167 | ppl 1.12 | wps 23780.4 | ups 15.14 | wpb 1570.4 | bsz 240 | num_updates 2280 | lr 0.000662266 | gnorm 0.164 | clip 0 | train_wall 1 | wall 164\n",
            "epoch 153:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:56 | INFO | fairseq.trainer | begin training epoch 153\n",
            "2025-05-14 11:46:57 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)\n",
            "2025-05-14 11:46:57 | INFO | train | epoch 153 | loss 1.029 | nll_loss 0.166 | ppl 1.12 | wps 22261.6 | ups 14.18 | wpb 1570.4 | bsz 240 | num_updates 2295 | lr 0.000660098 | gnorm 0.172 | clip 0 | train_wall 1 | wall 165\n",
            "epoch 154:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:57 | INFO | fairseq.trainer | begin training epoch 154\n",
            "2025-05-14 11:46:59 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)\n",
            "2025-05-14 11:46:59 | INFO | train | epoch 154 | loss 1.031 | nll_loss 0.167 | ppl 1.12 | wps 16029.5 | ups 10.21 | wpb 1570.4 | bsz 240 | num_updates 2310 | lr 0.000657952 | gnorm 0.239 | clip 0 | train_wall 1 | wall 167\n",
            "epoch 155:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:46:59 | INFO | fairseq.trainer | begin training epoch 155\n",
            "epoch 155:  93% 14/15 [00:01<00:00, 14.81it/s]2025-05-14 11:47:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint155.pt (epoch 155 @ 2325 updates, score None) (writing took 0.0922444570001062 seconds)\n",
            "2025-05-14 11:47:00 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)\n",
            "2025-05-14 11:47:00 | INFO | train | epoch 155 | loss 1.038 | nll_loss 0.176 | ppl 1.13 | wps 15960.8 | ups 10.16 | wpb 1570.4 | bsz 240 | num_updates 2325 | lr 0.000655826 | gnorm 0.25 | clip 0 | train_wall 1 | wall 168\n",
            "epoch 156:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:00 | INFO | fairseq.trainer | begin training epoch 156\n",
            "2025-05-14 11:47:01 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)\n",
            "2025-05-14 11:47:01 | INFO | train | epoch 156 | loss 1.04 | nll_loss 0.175 | ppl 1.13 | wps 22677 | ups 14.44 | wpb 1570.4 | bsz 240 | num_updates 2340 | lr 0.00065372 | gnorm 0.307 | clip 0 | train_wall 1 | wall 169\n",
            "epoch 157:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:01 | INFO | fairseq.trainer | begin training epoch 157\n",
            "2025-05-14 11:47:02 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)\n",
            "2025-05-14 11:47:02 | INFO | train | epoch 157 | loss 1.039 | nll_loss 0.177 | ppl 1.13 | wps 24157.2 | ups 15.38 | wpb 1570.4 | bsz 240 | num_updates 2355 | lr 0.000651635 | gnorm 0.323 | clip 0 | train_wall 1 | wall 170\n",
            "epoch 158:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:02 | INFO | fairseq.trainer | begin training epoch 158\n",
            "2025-05-14 11:47:03 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)\n",
            "2025-05-14 11:47:03 | INFO | train | epoch 158 | loss 1.037 | nll_loss 0.173 | ppl 1.13 | wps 24126.2 | ups 15.36 | wpb 1570.4 | bsz 240 | num_updates 2370 | lr 0.00064957 | gnorm 0.221 | clip 0 | train_wall 1 | wall 171\n",
            "epoch 159:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:03 | INFO | fairseq.trainer | begin training epoch 159\n",
            "2025-05-14 11:47:04 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)\n",
            "2025-05-14 11:47:04 | INFO | train | epoch 159 | loss 1.034 | nll_loss 0.171 | ppl 1.13 | wps 24248 | ups 15.44 | wpb 1570.4 | bsz 240 | num_updates 2385 | lr 0.000647524 | gnorm 0.186 | clip 0 | train_wall 1 | wall 172\n",
            "epoch 160:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:04 | INFO | fairseq.trainer | begin training epoch 160\n",
            "epoch 160:  93% 14/15 [00:00<00:00, 17.90it/s]2025-05-14 11:47:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint160.pt (epoch 160 @ 2400 updates, score None) (writing took 0.08653648199992858 seconds)\n",
            "2025-05-14 11:47:05 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)\n",
            "2025-05-14 11:47:05 | INFO | train | epoch 160 | loss 1.034 | nll_loss 0.171 | ppl 1.13 | wps 21826.1 | ups 13.9 | wpb 1570.4 | bsz 240 | num_updates 2400 | lr 0.000645497 | gnorm 0.252 | clip 0 | train_wall 1 | wall 173\n",
            "epoch 161:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:05 | INFO | fairseq.trainer | begin training epoch 161\n",
            "2025-05-14 11:47:06 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)\n",
            "2025-05-14 11:47:06 | INFO | train | epoch 161 | loss 1.035 | nll_loss 0.173 | ppl 1.13 | wps 24438.4 | ups 15.56 | wpb 1570.4 | bsz 240 | num_updates 2415 | lr 0.000643489 | gnorm 0.278 | clip 0 | train_wall 1 | wall 174\n",
            "epoch 162:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:06 | INFO | fairseq.trainer | begin training epoch 162\n",
            "2025-05-14 11:47:07 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)\n",
            "2025-05-14 11:47:07 | INFO | train | epoch 162 | loss 1.037 | nll_loss 0.174 | ppl 1.13 | wps 24189 | ups 15.4 | wpb 1570.4 | bsz 240 | num_updates 2430 | lr 0.0006415 | gnorm 0.23 | clip 0 | train_wall 1 | wall 175\n",
            "epoch 163:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:07 | INFO | fairseq.trainer | begin training epoch 163\n",
            "2025-05-14 11:47:08 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)\n",
            "2025-05-14 11:47:08 | INFO | train | epoch 163 | loss 1.035 | nll_loss 0.169 | ppl 1.12 | wps 24687.1 | ups 15.72 | wpb 1570.4 | bsz 240 | num_updates 2445 | lr 0.000639529 | gnorm 0.189 | clip 0 | train_wall 1 | wall 176\n",
            "epoch 164:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:08 | INFO | fairseq.trainer | begin training epoch 164\n",
            "2025-05-14 11:47:09 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)\n",
            "2025-05-14 11:47:09 | INFO | train | epoch 164 | loss 1.034 | nll_loss 0.172 | ppl 1.13 | wps 23244.7 | ups 14.8 | wpb 1570.4 | bsz 240 | num_updates 2460 | lr 0.000637577 | gnorm 0.218 | clip 0 | train_wall 1 | wall 177\n",
            "epoch 165:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:09 | INFO | fairseq.trainer | begin training epoch 165\n",
            "epoch 165:  87% 13/15 [00:00<00:00, 14.76it/s]2025-05-14 11:47:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint165.pt (epoch 165 @ 2475 updates, score None) (writing took 0.12142405300005521 seconds)\n",
            "2025-05-14 11:47:10 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)\n",
            "2025-05-14 11:47:10 | INFO | train | epoch 165 | loss 1.034 | nll_loss 0.171 | ppl 1.13 | wps 19204.1 | ups 12.23 | wpb 1570.4 | bsz 240 | num_updates 2475 | lr 0.000635642 | gnorm 0.257 | clip 0 | train_wall 1 | wall 178\n",
            "epoch 166:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:10 | INFO | fairseq.trainer | begin training epoch 166\n",
            "2025-05-14 11:47:12 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)\n",
            "2025-05-14 11:47:12 | INFO | train | epoch 166 | loss 1.033 | nll_loss 0.169 | ppl 1.12 | wps 15920.7 | ups 10.14 | wpb 1570.4 | bsz 240 | num_updates 2490 | lr 0.000633724 | gnorm 0.209 | clip 0 | train_wall 1 | wall 180\n",
            "epoch 167:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:12 | INFO | fairseq.trainer | begin training epoch 167\n",
            "2025-05-14 11:47:13 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)\n",
            "2025-05-14 11:47:13 | INFO | train | epoch 167 | loss 1.029 | nll_loss 0.164 | ppl 1.12 | wps 19235.9 | ups 12.25 | wpb 1570.4 | bsz 240 | num_updates 2505 | lr 0.000631824 | gnorm 0.173 | clip 0 | train_wall 1 | wall 181\n",
            "epoch 168:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:13 | INFO | fairseq.trainer | begin training epoch 168\n",
            "2025-05-14 11:47:14 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)\n",
            "2025-05-14 11:47:14 | INFO | train | epoch 168 | loss 1.031 | nll_loss 0.168 | ppl 1.12 | wps 24473.9 | ups 15.58 | wpb 1570.4 | bsz 240 | num_updates 2520 | lr 0.000629941 | gnorm 0.236 | clip 0 | train_wall 1 | wall 182\n",
            "epoch 169:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:14 | INFO | fairseq.trainer | begin training epoch 169\n",
            "2025-05-14 11:47:15 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)\n",
            "2025-05-14 11:47:15 | INFO | train | epoch 169 | loss 1.037 | nll_loss 0.177 | ppl 1.13 | wps 23870.3 | ups 15.2 | wpb 1570.4 | bsz 240 | num_updates 2535 | lr 0.000628074 | gnorm 0.263 | clip 0 | train_wall 1 | wall 183\n",
            "epoch 170:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:15 | INFO | fairseq.trainer | begin training epoch 170\n",
            "epoch 170:  87% 13/15 [00:00<00:00, 17.85it/s]2025-05-14 11:47:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint170.pt (epoch 170 @ 2550 updates, score None) (writing took 0.09010117599996192 seconds)\n",
            "2025-05-14 11:47:16 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)\n",
            "2025-05-14 11:47:16 | INFO | train | epoch 170 | loss 1.035 | nll_loss 0.17 | ppl 1.13 | wps 22190.7 | ups 14.13 | wpb 1570.4 | bsz 240 | num_updates 2550 | lr 0.000626224 | gnorm 0.257 | clip 0 | train_wall 1 | wall 184\n",
            "epoch 171:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:16 | INFO | fairseq.trainer | begin training epoch 171\n",
            "2025-05-14 11:47:17 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)\n",
            "2025-05-14 11:47:17 | INFO | train | epoch 171 | loss 1.033 | nll_loss 0.172 | ppl 1.13 | wps 23740 | ups 15.12 | wpb 1570.4 | bsz 240 | num_updates 2565 | lr 0.000624391 | gnorm 0.217 | clip 0 | train_wall 1 | wall 185\n",
            "epoch 172:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:17 | INFO | fairseq.trainer | begin training epoch 172\n",
            "2025-05-14 11:47:18 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)\n",
            "2025-05-14 11:47:18 | INFO | train | epoch 172 | loss 1.029 | nll_loss 0.163 | ppl 1.12 | wps 22847 | ups 14.55 | wpb 1570.4 | bsz 240 | num_updates 2580 | lr 0.000622573 | gnorm 0.198 | clip 0 | train_wall 1 | wall 186\n",
            "epoch 173:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:18 | INFO | fairseq.trainer | begin training epoch 173\n",
            "2025-05-14 11:47:19 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)\n",
            "2025-05-14 11:47:19 | INFO | train | epoch 173 | loss 1.031 | nll_loss 0.169 | ppl 1.12 | wps 23599.1 | ups 15.03 | wpb 1570.4 | bsz 240 | num_updates 2595 | lr 0.000620771 | gnorm 0.186 | clip 0 | train_wall 1 | wall 187\n",
            "epoch 174:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:19 | INFO | fairseq.trainer | begin training epoch 174\n",
            "2025-05-14 11:47:20 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)\n",
            "2025-05-14 11:47:20 | INFO | train | epoch 174 | loss 1.03 | nll_loss 0.166 | ppl 1.12 | wps 23128.4 | ups 14.73 | wpb 1570.4 | bsz 240 | num_updates 2610 | lr 0.000618984 | gnorm 0.229 | clip 0 | train_wall 1 | wall 188\n",
            "epoch 175:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:20 | INFO | fairseq.trainer | begin training epoch 175\n",
            "epoch 175:  93% 14/15 [00:00<00:00, 18.49it/s]2025-05-14 11:47:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint175.pt (epoch 175 @ 2625 updates, score None) (writing took 0.09521868899992114 seconds)\n",
            "2025-05-14 11:47:21 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)\n",
            "2025-05-14 11:47:21 | INFO | train | epoch 175 | loss 1.03 | nll_loss 0.168 | ppl 1.12 | wps 21918.4 | ups 13.96 | wpb 1570.4 | bsz 240 | num_updates 2625 | lr 0.000617213 | gnorm 0.207 | clip 0 | train_wall 1 | wall 189\n",
            "epoch 176:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:21 | INFO | fairseq.trainer | begin training epoch 176\n",
            "2025-05-14 11:47:22 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)\n",
            "2025-05-14 11:47:22 | INFO | train | epoch 176 | loss 1.029 | nll_loss 0.166 | ppl 1.12 | wps 23531.3 | ups 14.98 | wpb 1570.4 | bsz 240 | num_updates 2640 | lr 0.000615457 | gnorm 0.223 | clip 0 | train_wall 1 | wall 190\n",
            "epoch 177:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:22 | INFO | fairseq.trainer | begin training epoch 177\n",
            "2025-05-14 11:47:23 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)\n",
            "2025-05-14 11:47:23 | INFO | train | epoch 177 | loss 1.03 | nll_loss 0.167 | ppl 1.12 | wps 19013.3 | ups 12.11 | wpb 1570.4 | bsz 240 | num_updates 2655 | lr 0.000613716 | gnorm 0.182 | clip 0 | train_wall 1 | wall 191\n",
            "epoch 178:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:23 | INFO | fairseq.trainer | begin training epoch 178\n",
            "2025-05-14 11:47:25 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)\n",
            "2025-05-14 11:47:25 | INFO | train | epoch 178 | loss 1.033 | nll_loss 0.172 | ppl 1.13 | wps 15950.2 | ups 10.16 | wpb 1570.4 | bsz 240 | num_updates 2670 | lr 0.00061199 | gnorm 0.241 | clip 0 | train_wall 1 | wall 193\n",
            "epoch 179:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:25 | INFO | fairseq.trainer | begin training epoch 179\n",
            "2025-05-14 11:47:26 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)\n",
            "2025-05-14 11:47:26 | INFO | train | epoch 179 | loss 1.035 | nll_loss 0.172 | ppl 1.13 | wps 21974 | ups 13.99 | wpb 1570.4 | bsz 240 | num_updates 2685 | lr 0.000610278 | gnorm 0.234 | clip 0 | train_wall 1 | wall 194\n",
            "epoch 180:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:26 | INFO | fairseq.trainer | begin training epoch 180\n",
            "epoch 180:  87% 13/15 [00:00<00:00, 17.79it/s]2025-05-14 11:47:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint180.pt (epoch 180 @ 2700 updates, score None) (writing took 0.08925148599996646 seconds)\n",
            "2025-05-14 11:47:27 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)\n",
            "2025-05-14 11:47:27 | INFO | train | epoch 180 | loss 1.032 | nll_loss 0.168 | ppl 1.12 | wps 22322.2 | ups 14.21 | wpb 1570.4 | bsz 240 | num_updates 2700 | lr 0.000608581 | gnorm 0.282 | clip 0 | train_wall 1 | wall 195\n",
            "epoch 181:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:27 | INFO | fairseq.trainer | begin training epoch 181\n",
            "2025-05-14 11:47:28 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)\n",
            "2025-05-14 11:47:28 | INFO | train | epoch 181 | loss 1.031 | nll_loss 0.168 | ppl 1.12 | wps 24409.4 | ups 15.54 | wpb 1570.4 | bsz 240 | num_updates 2715 | lr 0.000606897 | gnorm 0.226 | clip 0 | train_wall 1 | wall 196\n",
            "epoch 182:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:28 | INFO | fairseq.trainer | begin training epoch 182\n",
            "2025-05-14 11:47:29 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)\n",
            "2025-05-14 11:47:29 | INFO | train | epoch 182 | loss 1.035 | nll_loss 0.173 | ppl 1.13 | wps 23022.6 | ups 14.66 | wpb 1570.4 | bsz 240 | num_updates 2730 | lr 0.000605228 | gnorm 0.338 | clip 6.7 | train_wall 1 | wall 197\n",
            "epoch 183:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:29 | INFO | fairseq.trainer | begin training epoch 183\n",
            "2025-05-14 11:47:30 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)\n",
            "2025-05-14 11:47:30 | INFO | train | epoch 183 | loss 1.032 | nll_loss 0.168 | ppl 1.12 | wps 23101.9 | ups 14.71 | wpb 1570.4 | bsz 240 | num_updates 2745 | lr 0.000603572 | gnorm 0.196 | clip 0 | train_wall 1 | wall 198\n",
            "epoch 184:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:30 | INFO | fairseq.trainer | begin training epoch 184\n",
            "2025-05-14 11:47:31 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)\n",
            "2025-05-14 11:47:31 | INFO | train | epoch 184 | loss 1.03 | nll_loss 0.168 | ppl 1.12 | wps 23701.3 | ups 15.09 | wpb 1570.4 | bsz 240 | num_updates 2760 | lr 0.000601929 | gnorm 0.19 | clip 0 | train_wall 1 | wall 199\n",
            "epoch 185:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:31 | INFO | fairseq.trainer | begin training epoch 185\n",
            "epoch 185:  87% 13/15 [00:00<00:00, 18.53it/s]2025-05-14 11:47:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint185.pt (epoch 185 @ 2775 updates, score None) (writing took 0.09334250599999905 seconds)\n",
            "2025-05-14 11:47:32 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)\n",
            "2025-05-14 11:47:32 | INFO | train | epoch 185 | loss 1.03 | nll_loss 0.166 | ppl 1.12 | wps 21811.8 | ups 13.89 | wpb 1570.4 | bsz 240 | num_updates 2775 | lr 0.0006003 | gnorm 0.179 | clip 0 | train_wall 1 | wall 200\n",
            "epoch 186:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:32 | INFO | fairseq.trainer | begin training epoch 186\n",
            "2025-05-14 11:47:33 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)\n",
            "2025-05-14 11:47:33 | INFO | train | epoch 186 | loss 1.028 | nll_loss 0.166 | ppl 1.12 | wps 23437.8 | ups 14.92 | wpb 1570.4 | bsz 240 | num_updates 2790 | lr 0.000598684 | gnorm 0.169 | clip 0 | train_wall 1 | wall 201\n",
            "epoch 187:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:33 | INFO | fairseq.trainer | begin training epoch 187\n",
            "2025-05-14 11:47:34 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)\n",
            "2025-05-14 11:47:34 | INFO | train | epoch 187 | loss 1.029 | nll_loss 0.166 | ppl 1.12 | wps 23625.8 | ups 15.04 | wpb 1570.4 | bsz 240 | num_updates 2805 | lr 0.000597081 | gnorm 0.172 | clip 0 | train_wall 1 | wall 202\n",
            "epoch 188:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:34 | INFO | fairseq.trainer | begin training epoch 188\n",
            "2025-05-14 11:47:35 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)\n",
            "2025-05-14 11:47:35 | INFO | train | epoch 188 | loss 1.029 | nll_loss 0.167 | ppl 1.12 | wps 23681.3 | ups 15.08 | wpb 1570.4 | bsz 240 | num_updates 2820 | lr 0.000595491 | gnorm 0.224 | clip 0 | train_wall 1 | wall 203\n",
            "epoch 189:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:35 | INFO | fairseq.trainer | begin training epoch 189\n",
            "2025-05-14 11:47:36 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)\n",
            "2025-05-14 11:47:36 | INFO | train | epoch 189 | loss 1.03 | nll_loss 0.168 | ppl 1.12 | wps 17558.5 | ups 11.18 | wpb 1570.4 | bsz 240 | num_updates 2835 | lr 0.000593914 | gnorm 0.223 | clip 0 | train_wall 1 | wall 204\n",
            "epoch 190:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:36 | INFO | fairseq.trainer | begin training epoch 190\n",
            "epoch 190:  87% 13/15 [00:01<00:00, 12.34it/s]2025-05-14 11:47:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint190.pt (epoch 190 @ 2850 updates, score None) (writing took 0.10949352600005113 seconds)\n",
            "2025-05-14 11:47:38 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)\n",
            "2025-05-14 11:47:38 | INFO | train | epoch 190 | loss 1.029 | nll_loss 0.165 | ppl 1.12 | wps 14510.7 | ups 9.24 | wpb 1570.4 | bsz 240 | num_updates 2850 | lr 0.000592349 | gnorm 0.166 | clip 0 | train_wall 1 | wall 206\n",
            "epoch 191:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:38 | INFO | fairseq.trainer | begin training epoch 191\n",
            "2025-05-14 11:47:39 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)\n",
            "2025-05-14 11:47:39 | INFO | train | epoch 191 | loss 1.026 | nll_loss 0.164 | ppl 1.12 | wps 24103.8 | ups 15.35 | wpb 1570.4 | bsz 240 | num_updates 2865 | lr 0.000590796 | gnorm 0.177 | clip 0 | train_wall 1 | wall 207\n",
            "epoch 192:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:39 | INFO | fairseq.trainer | begin training epoch 192\n",
            "2025-05-14 11:47:40 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)\n",
            "2025-05-14 11:47:40 | INFO | train | epoch 192 | loss 1.027 | nll_loss 0.164 | ppl 1.12 | wps 24152.9 | ups 15.38 | wpb 1570.4 | bsz 240 | num_updates 2880 | lr 0.000589256 | gnorm 0.195 | clip 0 | train_wall 1 | wall 208\n",
            "epoch 193:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:40 | INFO | fairseq.trainer | begin training epoch 193\n",
            "2025-05-14 11:47:41 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)\n",
            "2025-05-14 11:47:41 | INFO | train | epoch 193 | loss 1.029 | nll_loss 0.167 | ppl 1.12 | wps 23708.4 | ups 15.1 | wpb 1570.4 | bsz 240 | num_updates 2895 | lr 0.000587727 | gnorm 0.253 | clip 0 | train_wall 1 | wall 209\n",
            "epoch 194:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:41 | INFO | fairseq.trainer | begin training epoch 194\n",
            "2025-05-14 11:47:42 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)\n",
            "2025-05-14 11:47:42 | INFO | train | epoch 194 | loss 1.031 | nll_loss 0.168 | ppl 1.12 | wps 23938 | ups 15.24 | wpb 1570.4 | bsz 240 | num_updates 2910 | lr 0.00058621 | gnorm 0.257 | clip 0 | train_wall 1 | wall 210\n",
            "epoch 195:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:42 | INFO | fairseq.trainer | begin training epoch 195\n",
            "epoch 195:  93% 14/15 [00:00<00:00, 18.70it/s]2025-05-14 11:47:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint195.pt (epoch 195 @ 2925 updates, score None) (writing took 0.09154266099994857 seconds)\n",
            "2025-05-14 11:47:43 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)\n",
            "2025-05-14 11:47:43 | INFO | train | epoch 195 | loss 1.031 | nll_loss 0.169 | ppl 1.12 | wps 21411.1 | ups 13.63 | wpb 1570.4 | bsz 240 | num_updates 2925 | lr 0.000584705 | gnorm 0.252 | clip 0 | train_wall 1 | wall 211\n",
            "epoch 196:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:43 | INFO | fairseq.trainer | begin training epoch 196\n",
            "2025-05-14 11:47:44 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)\n",
            "2025-05-14 11:47:44 | INFO | train | epoch 196 | loss 1.041 | nll_loss 0.181 | ppl 1.13 | wps 23752.5 | ups 15.13 | wpb 1570.4 | bsz 240 | num_updates 2940 | lr 0.000583212 | gnorm 0.339 | clip 6.7 | train_wall 1 | wall 212\n",
            "epoch 197:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:44 | INFO | fairseq.trainer | begin training epoch 197\n",
            "2025-05-14 11:47:45 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)\n",
            "2025-05-14 11:47:45 | INFO | train | epoch 197 | loss 1.038 | nll_loss 0.178 | ppl 1.13 | wps 23355.7 | ups 14.87 | wpb 1570.4 | bsz 240 | num_updates 2955 | lr 0.00058173 | gnorm 0.319 | clip 6.7 | train_wall 1 | wall 213\n",
            "epoch 198:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:45 | INFO | fairseq.trainer | begin training epoch 198\n",
            "2025-05-14 11:47:46 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)\n",
            "2025-05-14 11:47:46 | INFO | train | epoch 198 | loss 1.034 | nll_loss 0.17 | ppl 1.13 | wps 22615.6 | ups 14.4 | wpb 1570.4 | bsz 240 | num_updates 2970 | lr 0.000580259 | gnorm 0.225 | clip 0 | train_wall 1 | wall 214\n",
            "epoch 199:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:46 | INFO | fairseq.trainer | begin training epoch 199\n",
            "2025-05-14 11:47:47 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)\n",
            "2025-05-14 11:47:47 | INFO | train | epoch 199 | loss 1.033 | nll_loss 0.17 | ppl 1.13 | wps 22717.4 | ups 14.47 | wpb 1570.4 | bsz 240 | num_updates 2985 | lr 0.000578799 | gnorm 0.25 | clip 0 | train_wall 1 | wall 215\n",
            "epoch 200:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:47 | INFO | fairseq.trainer | begin training epoch 200\n",
            "epoch 200:  93% 14/15 [00:01<00:00, 14.13it/s]2025-05-14 11:47:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint200.pt (epoch 200 @ 3000 updates, score None) (writing took 0.11968723399991177 seconds)\n",
            "2025-05-14 11:47:48 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)\n",
            "2025-05-14 11:47:48 | INFO | train | epoch 200 | loss 1.032 | nll_loss 0.171 | ppl 1.13 | wps 17276.2 | ups 11 | wpb 1570.4 | bsz 240 | num_updates 3000 | lr 0.00057735 | gnorm 0.248 | clip 0 | train_wall 1 | wall 216\n",
            "epoch 201:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:49 | INFO | fairseq.trainer | begin training epoch 201\n",
            "2025-05-14 11:47:50 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)\n",
            "2025-05-14 11:47:50 | INFO | train | epoch 201 | loss 1.03 | nll_loss 0.169 | ppl 1.12 | wps 16653.5 | ups 10.6 | wpb 1570.4 | bsz 240 | num_updates 3015 | lr 0.000575912 | gnorm 0.22 | clip 0 | train_wall 1 | wall 218\n",
            "epoch 202:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:50 | INFO | fairseq.trainer | begin training epoch 202\n",
            "2025-05-14 11:47:51 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)\n",
            "2025-05-14 11:47:51 | INFO | train | epoch 202 | loss 1.028 | nll_loss 0.164 | ppl 1.12 | wps 19337.5 | ups 12.31 | wpb 1570.4 | bsz 240 | num_updates 3030 | lr 0.000574485 | gnorm 0.182 | clip 0 | train_wall 1 | wall 219\n",
            "epoch 203:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:51 | INFO | fairseq.trainer | begin training epoch 203\n",
            "2025-05-14 11:47:52 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)\n",
            "2025-05-14 11:47:52 | INFO | train | epoch 203 | loss 1.027 | nll_loss 0.165 | ppl 1.12 | wps 23767.6 | ups 15.13 | wpb 1570.4 | bsz 240 | num_updates 3045 | lr 0.000573068 | gnorm 0.178 | clip 0 | train_wall 1 | wall 220\n",
            "epoch 204:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:52 | INFO | fairseq.trainer | begin training epoch 204\n",
            "2025-05-14 11:47:53 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)\n",
            "2025-05-14 11:47:53 | INFO | train | epoch 204 | loss 1.026 | nll_loss 0.163 | ppl 1.12 | wps 23747.5 | ups 15.12 | wpb 1570.4 | bsz 240 | num_updates 3060 | lr 0.000571662 | gnorm 0.169 | clip 0 | train_wall 1 | wall 221\n",
            "epoch 205:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:53 | INFO | fairseq.trainer | begin training epoch 205\n",
            "epoch 205:  80% 12/15 [00:00<00:00, 16.94it/s]2025-05-14 11:47:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint205.pt (epoch 205 @ 3075 updates, score None) (writing took 0.09058277000008275 seconds)\n",
            "2025-05-14 11:47:54 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)\n",
            "2025-05-14 11:47:54 | INFO | train | epoch 205 | loss 1.025 | nll_loss 0.164 | ppl 1.12 | wps 21952.4 | ups 13.98 | wpb 1570.4 | bsz 240 | num_updates 3075 | lr 0.000570266 | gnorm 0.187 | clip 0 | train_wall 1 | wall 222\n",
            "epoch 206:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:54 | INFO | fairseq.trainer | begin training epoch 206\n",
            "2025-05-14 11:47:55 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)\n",
            "2025-05-14 11:47:55 | INFO | train | epoch 206 | loss 1.025 | nll_loss 0.162 | ppl 1.12 | wps 24513.8 | ups 15.61 | wpb 1570.4 | bsz 240 | num_updates 3090 | lr 0.00056888 | gnorm 0.155 | clip 0 | train_wall 1 | wall 223\n",
            "epoch 207:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:55 | INFO | fairseq.trainer | begin training epoch 207\n",
            "2025-05-14 11:47:56 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)\n",
            "2025-05-14 11:47:56 | INFO | train | epoch 207 | loss 1.024 | nll_loss 0.161 | ppl 1.12 | wps 24285.9 | ups 15.46 | wpb 1570.4 | bsz 240 | num_updates 3105 | lr 0.000567504 | gnorm 0.206 | clip 0 | train_wall 1 | wall 224\n",
            "epoch 208:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:56 | INFO | fairseq.trainer | begin training epoch 208\n",
            "2025-05-14 11:47:57 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)\n",
            "2025-05-14 11:47:57 | INFO | train | epoch 208 | loss 1.03 | nll_loss 0.17 | ppl 1.13 | wps 24053.7 | ups 15.32 | wpb 1570.4 | bsz 240 | num_updates 3120 | lr 0.000566139 | gnorm 0.252 | clip 0 | train_wall 1 | wall 225\n",
            "epoch 209:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:57 | INFO | fairseq.trainer | begin training epoch 209\n",
            "2025-05-14 11:47:58 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)\n",
            "2025-05-14 11:47:58 | INFO | train | epoch 209 | loss 1.034 | nll_loss 0.171 | ppl 1.13 | wps 24688.2 | ups 15.72 | wpb 1570.4 | bsz 240 | num_updates 3135 | lr 0.000564782 | gnorm 0.269 | clip 0 | train_wall 1 | wall 226\n",
            "epoch 210:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:58 | INFO | fairseq.trainer | begin training epoch 210\n",
            "epoch 210:  80% 12/15 [00:00<00:00, 17.48it/s]2025-05-14 11:47:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:47:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint210.pt (epoch 210 @ 3150 updates, score None) (writing took 0.07992061200002354 seconds)\n",
            "2025-05-14 11:47:59 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)\n",
            "2025-05-14 11:47:59 | INFO | train | epoch 210 | loss 1.028 | nll_loss 0.166 | ppl 1.12 | wps 22476.4 | ups 14.31 | wpb 1570.4 | bsz 240 | num_updates 3150 | lr 0.000563436 | gnorm 0.182 | clip 0 | train_wall 1 | wall 227\n",
            "epoch 211:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:47:59 | INFO | fairseq.trainer | begin training epoch 211\n",
            "2025-05-14 11:48:00 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)\n",
            "2025-05-14 11:48:00 | INFO | train | epoch 211 | loss 1.027 | nll_loss 0.164 | ppl 1.12 | wps 24120.1 | ups 15.36 | wpb 1570.4 | bsz 240 | num_updates 3165 | lr 0.000562099 | gnorm 0.203 | clip 0 | train_wall 1 | wall 228\n",
            "epoch 212:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:00 | INFO | fairseq.trainer | begin training epoch 212\n",
            "2025-05-14 11:48:01 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)\n",
            "2025-05-14 11:48:01 | INFO | train | epoch 212 | loss 1.026 | nll_loss 0.164 | ppl 1.12 | wps 17433.5 | ups 11.1 | wpb 1570.4 | bsz 240 | num_updates 3180 | lr 0.000560772 | gnorm 0.21 | clip 0 | train_wall 1 | wall 229\n",
            "epoch 213:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:01 | INFO | fairseq.trainer | begin training epoch 213\n",
            "2025-05-14 11:48:03 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)\n",
            "2025-05-14 11:48:03 | INFO | train | epoch 213 | loss 1.025 | nll_loss 0.164 | ppl 1.12 | wps 16636.7 | ups 10.59 | wpb 1570.4 | bsz 240 | num_updates 3195 | lr 0.000559454 | gnorm 0.23 | clip 6.7 | train_wall 1 | wall 231\n",
            "epoch 214:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:03 | INFO | fairseq.trainer | begin training epoch 214\n",
            "2025-05-14 11:48:04 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)\n",
            "2025-05-14 11:48:04 | INFO | train | epoch 214 | loss 1.027 | nll_loss 0.165 | ppl 1.12 | wps 21269.9 | ups 13.54 | wpb 1570.4 | bsz 240 | num_updates 3210 | lr 0.000558146 | gnorm 0.254 | clip 0 | train_wall 1 | wall 232\n",
            "epoch 215:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:04 | INFO | fairseq.trainer | begin training epoch 215\n",
            "epoch 215:  80% 12/15 [00:00<00:00, 18.27it/s]2025-05-14 11:48:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint215.pt (epoch 215 @ 3225 updates, score None) (writing took 0.09556218300008368 seconds)\n",
            "2025-05-14 11:48:05 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)\n",
            "2025-05-14 11:48:05 | INFO | train | epoch 215 | loss 1.03 | nll_loss 0.17 | ppl 1.13 | wps 21811.5 | ups 13.89 | wpb 1570.4 | bsz 240 | num_updates 3225 | lr 0.000556846 | gnorm 0.266 | clip 0 | train_wall 1 | wall 233\n",
            "epoch 216:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:05 | INFO | fairseq.trainer | begin training epoch 216\n",
            "2025-05-14 11:48:06 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)\n",
            "2025-05-14 11:48:06 | INFO | train | epoch 216 | loss 1.033 | nll_loss 0.173 | ppl 1.13 | wps 23734.2 | ups 15.11 | wpb 1570.4 | bsz 240 | num_updates 3240 | lr 0.000555556 | gnorm 0.247 | clip 0 | train_wall 1 | wall 234\n",
            "epoch 217:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:06 | INFO | fairseq.trainer | begin training epoch 217\n",
            "2025-05-14 11:48:07 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)\n",
            "2025-05-14 11:48:07 | INFO | train | epoch 217 | loss 1.028 | nll_loss 0.165 | ppl 1.12 | wps 24087.7 | ups 15.34 | wpb 1570.4 | bsz 240 | num_updates 3255 | lr 0.000554274 | gnorm 0.244 | clip 0 | train_wall 1 | wall 235\n",
            "epoch 218:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:07 | INFO | fairseq.trainer | begin training epoch 218\n",
            "2025-05-14 11:48:08 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)\n",
            "2025-05-14 11:48:08 | INFO | train | epoch 218 | loss 1.033 | nll_loss 0.174 | ppl 1.13 | wps 23738.4 | ups 15.12 | wpb 1570.4 | bsz 240 | num_updates 3270 | lr 0.000553001 | gnorm 0.252 | clip 0 | train_wall 1 | wall 236\n",
            "epoch 219:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:08 | INFO | fairseq.trainer | begin training epoch 219\n",
            "2025-05-14 11:48:09 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)\n",
            "2025-05-14 11:48:09 | INFO | train | epoch 219 | loss 1.029 | nll_loss 0.167 | ppl 1.12 | wps 24284.7 | ups 15.46 | wpb 1570.4 | bsz 240 | num_updates 3285 | lr 0.000551737 | gnorm 0.22 | clip 0 | train_wall 1 | wall 237\n",
            "epoch 220:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:09 | INFO | fairseq.trainer | begin training epoch 220\n",
            "epoch 220:  87% 13/15 [00:00<00:00, 18.34it/s]2025-05-14 11:48:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint220.pt (epoch 220 @ 3300 updates, score None) (writing took 0.08855918299991572 seconds)\n",
            "2025-05-14 11:48:10 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)\n",
            "2025-05-14 11:48:10 | INFO | train | epoch 220 | loss 1.025 | nll_loss 0.162 | ppl 1.12 | wps 22189.5 | ups 14.13 | wpb 1570.4 | bsz 240 | num_updates 3300 | lr 0.000550482 | gnorm 0.187 | clip 0 | train_wall 1 | wall 238\n",
            "epoch 221:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:10 | INFO | fairseq.trainer | begin training epoch 221\n",
            "2025-05-14 11:48:11 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)\n",
            "2025-05-14 11:48:11 | INFO | train | epoch 221 | loss 1.027 | nll_loss 0.166 | ppl 1.12 | wps 23556.7 | ups 15 | wpb 1570.4 | bsz 240 | num_updates 3315 | lr 0.000549235 | gnorm 0.2 | clip 0 | train_wall 1 | wall 239\n",
            "epoch 222:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:11 | INFO | fairseq.trainer | begin training epoch 222\n",
            "2025-05-14 11:48:12 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)\n",
            "2025-05-14 11:48:12 | INFO | train | epoch 222 | loss 1.026 | nll_loss 0.162 | ppl 1.12 | wps 24503.3 | ups 15.6 | wpb 1570.4 | bsz 240 | num_updates 3330 | lr 0.000547997 | gnorm 0.229 | clip 0 | train_wall 1 | wall 240\n",
            "epoch 223:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:12 | INFO | fairseq.trainer | begin training epoch 223\n",
            "2025-05-14 11:48:13 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)\n",
            "2025-05-14 11:48:13 | INFO | train | epoch 223 | loss 1.026 | nll_loss 0.167 | ppl 1.12 | wps 24447.8 | ups 15.57 | wpb 1570.4 | bsz 240 | num_updates 3345 | lr 0.000546767 | gnorm 0.184 | clip 0 | train_wall 1 | wall 241\n",
            "epoch 224:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:13 | INFO | fairseq.trainer | begin training epoch 224\n",
            "2025-05-14 11:48:14 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)\n",
            "2025-05-14 11:48:14 | INFO | train | epoch 224 | loss 1.024 | nll_loss 0.161 | ppl 1.12 | wps 19149.7 | ups 12.19 | wpb 1570.4 | bsz 240 | num_updates 3360 | lr 0.000545545 | gnorm 0.153 | clip 0 | train_wall 1 | wall 242\n",
            "epoch 225:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:14 | INFO | fairseq.trainer | begin training epoch 225\n",
            "epoch 225:  87% 13/15 [00:01<00:00, 13.74it/s]2025-05-14 11:48:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint225.pt (epoch 225 @ 3375 updates, score None) (writing took 0.12273955199998454 seconds)\n",
            "2025-05-14 11:48:16 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)\n",
            "2025-05-14 11:48:16 | INFO | train | epoch 225 | loss 1.023 | nll_loss 0.16 | ppl 1.12 | wps 15134.4 | ups 9.64 | wpb 1570.4 | bsz 240 | num_updates 3375 | lr 0.000544331 | gnorm 0.204 | clip 0 | train_wall 1 | wall 244\n",
            "epoch 226:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:16 | INFO | fairseq.trainer | begin training epoch 226\n",
            "2025-05-14 11:48:17 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)\n",
            "2025-05-14 11:48:17 | INFO | train | epoch 226 | loss 1.023 | nll_loss 0.162 | ppl 1.12 | wps 22883.6 | ups 14.57 | wpb 1570.4 | bsz 240 | num_updates 3390 | lr 0.000543125 | gnorm 0.199 | clip 0 | train_wall 1 | wall 245\n",
            "epoch 227:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:17 | INFO | fairseq.trainer | begin training epoch 227\n",
            "2025-05-14 11:48:18 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)\n",
            "2025-05-14 11:48:18 | INFO | train | epoch 227 | loss 1.024 | nll_loss 0.162 | ppl 1.12 | wps 22872.3 | ups 14.56 | wpb 1570.4 | bsz 240 | num_updates 3405 | lr 0.000541928 | gnorm 0.162 | clip 0 | train_wall 1 | wall 246\n",
            "epoch 228:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:18 | INFO | fairseq.trainer | begin training epoch 228\n",
            "2025-05-14 11:48:19 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)\n",
            "2025-05-14 11:48:19 | INFO | train | epoch 228 | loss 1.023 | nll_loss 0.162 | ppl 1.12 | wps 21571.4 | ups 13.74 | wpb 1570.4 | bsz 240 | num_updates 3420 | lr 0.000540738 | gnorm 0.16 | clip 0 | train_wall 1 | wall 247\n",
            "epoch 229:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:19 | INFO | fairseq.trainer | begin training epoch 229\n",
            "2025-05-14 11:48:20 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)\n",
            "2025-05-14 11:48:20 | INFO | train | epoch 229 | loss 1.023 | nll_loss 0.161 | ppl 1.12 | wps 23768.1 | ups 15.14 | wpb 1570.4 | bsz 240 | num_updates 3435 | lr 0.000539556 | gnorm 0.159 | clip 0 | train_wall 1 | wall 248\n",
            "epoch 230:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:20 | INFO | fairseq.trainer | begin training epoch 230\n",
            "epoch 230:  87% 13/15 [00:00<00:00, 18.45it/s]2025-05-14 11:48:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint230.pt (epoch 230 @ 3450 updates, score None) (writing took 0.08863302800000383 seconds)\n",
            "2025-05-14 11:48:21 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)\n",
            "2025-05-14 11:48:21 | INFO | train | epoch 230 | loss 1.021 | nll_loss 0.159 | ppl 1.12 | wps 22216.1 | ups 14.15 | wpb 1570.4 | bsz 240 | num_updates 3450 | lr 0.000538382 | gnorm 0.156 | clip 0 | train_wall 1 | wall 249\n",
            "epoch 231:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:21 | INFO | fairseq.trainer | begin training epoch 231\n",
            "2025-05-14 11:48:22 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)\n",
            "2025-05-14 11:48:22 | INFO | train | epoch 231 | loss 1.021 | nll_loss 0.161 | ppl 1.12 | wps 24269 | ups 15.45 | wpb 1570.4 | bsz 240 | num_updates 3465 | lr 0.000537215 | gnorm 0.151 | clip 0 | train_wall 1 | wall 250\n",
            "epoch 232:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:22 | INFO | fairseq.trainer | begin training epoch 232\n",
            "2025-05-14 11:48:23 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)\n",
            "2025-05-14 11:48:23 | INFO | train | epoch 232 | loss 1.022 | nll_loss 0.161 | ppl 1.12 | wps 24457.6 | ups 15.57 | wpb 1570.4 | bsz 240 | num_updates 3480 | lr 0.000536056 | gnorm 0.14 | clip 0 | train_wall 1 | wall 251\n",
            "epoch 233:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:23 | INFO | fairseq.trainer | begin training epoch 233\n",
            "2025-05-14 11:48:24 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)\n",
            "2025-05-14 11:48:24 | INFO | train | epoch 233 | loss 1.021 | nll_loss 0.159 | ppl 1.12 | wps 24755.8 | ups 15.76 | wpb 1570.4 | bsz 240 | num_updates 3495 | lr 0.000534905 | gnorm 0.157 | clip 0 | train_wall 1 | wall 252\n",
            "epoch 234:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:24 | INFO | fairseq.trainer | begin training epoch 234\n",
            "2025-05-14 11:48:25 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)\n",
            "2025-05-14 11:48:25 | INFO | train | epoch 234 | loss 1.021 | nll_loss 0.159 | ppl 1.12 | wps 24267.3 | ups 15.45 | wpb 1570.4 | bsz 240 | num_updates 3510 | lr 0.000533761 | gnorm 0.12 | clip 0 | train_wall 1 | wall 253\n",
            "epoch 235:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:25 | INFO | fairseq.trainer | begin training epoch 235\n",
            "epoch 235:  87% 13/15 [00:00<00:00, 18.53it/s]2025-05-14 11:48:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint235.pt (epoch 235 @ 3525 updates, score None) (writing took 0.11280045400008021 seconds)\n",
            "2025-05-14 11:48:26 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)\n",
            "2025-05-14 11:48:26 | INFO | train | epoch 235 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 21779.8 | ups 13.87 | wpb 1570.4 | bsz 240 | num_updates 3525 | lr 0.000532624 | gnorm 0.163 | clip 0 | train_wall 1 | wall 254\n",
            "epoch 236:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:26 | INFO | fairseq.trainer | begin training epoch 236\n",
            "2025-05-14 11:48:27 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)\n",
            "2025-05-14 11:48:27 | INFO | train | epoch 236 | loss 1.019 | nll_loss 0.157 | ppl 1.12 | wps 16762.9 | ups 10.67 | wpb 1570.4 | bsz 240 | num_updates 3540 | lr 0.000531494 | gnorm 0.116 | clip 0 | train_wall 1 | wall 255\n",
            "epoch 237:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:27 | INFO | fairseq.trainer | begin training epoch 237\n",
            "2025-05-14 11:48:29 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)\n",
            "2025-05-14 11:48:29 | INFO | train | epoch 237 | loss 1.02 | nll_loss 0.159 | ppl 1.12 | wps 16411.6 | ups 10.45 | wpb 1570.4 | bsz 240 | num_updates 3555 | lr 0.000530372 | gnorm 0.131 | clip 0 | train_wall 1 | wall 257\n",
            "epoch 238:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:29 | INFO | fairseq.trainer | begin training epoch 238\n",
            "2025-05-14 11:48:30 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)\n",
            "2025-05-14 11:48:30 | INFO | train | epoch 238 | loss 1.019 | nll_loss 0.158 | ppl 1.12 | wps 22948.8 | ups 14.61 | wpb 1570.4 | bsz 240 | num_updates 3570 | lr 0.000529256 | gnorm 0.132 | clip 0 | train_wall 1 | wall 258\n",
            "epoch 239:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:30 | INFO | fairseq.trainer | begin training epoch 239\n",
            "2025-05-14 11:48:31 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)\n",
            "2025-05-14 11:48:31 | INFO | train | epoch 239 | loss 1.021 | nll_loss 0.158 | ppl 1.12 | wps 23599.6 | ups 15.03 | wpb 1570.4 | bsz 240 | num_updates 3585 | lr 0.000528148 | gnorm 0.151 | clip 0 | train_wall 1 | wall 259\n",
            "epoch 240:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:31 | INFO | fairseq.trainer | begin training epoch 240\n",
            "epoch 240:  93% 14/15 [00:00<00:00, 18.56it/s]2025-05-14 11:48:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint240.pt (epoch 240 @ 3600 updates, score None) (writing took 0.08151044300007015 seconds)\n",
            "2025-05-14 11:48:32 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)\n",
            "2025-05-14 11:48:32 | INFO | train | epoch 240 | loss 1.024 | nll_loss 0.165 | ppl 1.12 | wps 22100 | ups 14.07 | wpb 1570.4 | bsz 240 | num_updates 3600 | lr 0.000527046 | gnorm 0.216 | clip 0 | train_wall 1 | wall 260\n",
            "epoch 241:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:32 | INFO | fairseq.trainer | begin training epoch 241\n",
            "2025-05-14 11:48:33 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)\n",
            "2025-05-14 11:48:33 | INFO | train | epoch 241 | loss 1.023 | nll_loss 0.162 | ppl 1.12 | wps 24604.8 | ups 15.67 | wpb 1570.4 | bsz 240 | num_updates 3615 | lr 0.000525952 | gnorm 0.178 | clip 0 | train_wall 1 | wall 261\n",
            "epoch 242:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:33 | INFO | fairseq.trainer | begin training epoch 242\n",
            "2025-05-14 11:48:34 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)\n",
            "2025-05-14 11:48:34 | INFO | train | epoch 242 | loss 1.022 | nll_loss 0.161 | ppl 1.12 | wps 24561.4 | ups 15.64 | wpb 1570.4 | bsz 240 | num_updates 3630 | lr 0.000524864 | gnorm 0.181 | clip 0 | train_wall 1 | wall 262\n",
            "epoch 243:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:34 | INFO | fairseq.trainer | begin training epoch 243\n",
            "2025-05-14 11:48:35 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)\n",
            "2025-05-14 11:48:35 | INFO | train | epoch 243 | loss 1.021 | nll_loss 0.16 | ppl 1.12 | wps 23898.5 | ups 15.22 | wpb 1570.4 | bsz 240 | num_updates 3645 | lr 0.000523783 | gnorm 0.203 | clip 0 | train_wall 1 | wall 263\n",
            "epoch 244:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:35 | INFO | fairseq.trainer | begin training epoch 244\n",
            "2025-05-14 11:48:36 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)\n",
            "2025-05-14 11:48:36 | INFO | train | epoch 244 | loss 1.023 | nll_loss 0.162 | ppl 1.12 | wps 23524.9 | ups 14.98 | wpb 1570.4 | bsz 240 | num_updates 3660 | lr 0.000522708 | gnorm 0.163 | clip 0 | train_wall 1 | wall 264\n",
            "epoch 245:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:36 | INFO | fairseq.trainer | begin training epoch 245\n",
            "epoch 245:  93% 14/15 [00:00<00:00, 18.68it/s]2025-05-14 11:48:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint245.pt (epoch 245 @ 3675 updates, score None) (writing took 0.08121742900016216 seconds)\n",
            "2025-05-14 11:48:37 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)\n",
            "2025-05-14 11:48:37 | INFO | train | epoch 245 | loss 1.023 | nll_loss 0.161 | ppl 1.12 | wps 22105.3 | ups 14.08 | wpb 1570.4 | bsz 240 | num_updates 3675 | lr 0.000521641 | gnorm 0.158 | clip 0 | train_wall 1 | wall 265\n",
            "epoch 246:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:37 | INFO | fairseq.trainer | begin training epoch 246\n",
            "2025-05-14 11:48:38 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)\n",
            "2025-05-14 11:48:38 | INFO | train | epoch 246 | loss 1.02 | nll_loss 0.16 | ppl 1.12 | wps 23952.4 | ups 15.25 | wpb 1570.4 | bsz 240 | num_updates 3690 | lr 0.000520579 | gnorm 0.135 | clip 0 | train_wall 1 | wall 266\n",
            "epoch 247:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:38 | INFO | fairseq.trainer | begin training epoch 247\n",
            "2025-05-14 11:48:39 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)\n",
            "2025-05-14 11:48:39 | INFO | train | epoch 247 | loss 1.02 | nll_loss 0.158 | ppl 1.12 | wps 22030.4 | ups 14.03 | wpb 1570.4 | bsz 240 | num_updates 3705 | lr 0.000519524 | gnorm 0.139 | clip 0 | train_wall 1 | wall 267\n",
            "epoch 248:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:39 | INFO | fairseq.trainer | begin training epoch 248\n",
            "2025-05-14 11:48:40 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)\n",
            "2025-05-14 11:48:40 | INFO | train | epoch 248 | loss 1.02 | nll_loss 0.159 | ppl 1.12 | wps 16384.8 | ups 10.43 | wpb 1570.4 | bsz 240 | num_updates 3720 | lr 0.000518476 | gnorm 0.122 | clip 0 | train_wall 1 | wall 268\n",
            "epoch 249:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:40 | INFO | fairseq.trainer | begin training epoch 249\n",
            "2025-05-14 11:48:42 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)\n",
            "2025-05-14 11:48:42 | INFO | train | epoch 249 | loss 1.021 | nll_loss 0.159 | ppl 1.12 | wps 16947.1 | ups 10.79 | wpb 1570.4 | bsz 240 | num_updates 3735 | lr 0.000517434 | gnorm 0.188 | clip 0 | train_wall 1 | wall 270\n",
            "epoch 250:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:42 | INFO | fairseq.trainer | begin training epoch 250\n",
            "epoch 250:  80% 12/15 [00:00<00:00, 16.84it/s]2025-05-14 11:48:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint250.pt (epoch 250 @ 3750 updates, score None) (writing took 0.08306536500003858 seconds)\n",
            "2025-05-14 11:48:43 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)\n",
            "2025-05-14 11:48:43 | INFO | train | epoch 250 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 21207.9 | ups 13.5 | wpb 1570.4 | bsz 240 | num_updates 3750 | lr 0.000516398 | gnorm 0.199 | clip 6.7 | train_wall 1 | wall 271\n",
            "epoch 251:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:43 | INFO | fairseq.trainer | begin training epoch 251\n",
            "2025-05-14 11:48:44 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)\n",
            "2025-05-14 11:48:44 | INFO | train | epoch 251 | loss 1.029 | nll_loss 0.169 | ppl 1.12 | wps 23938.1 | ups 15.24 | wpb 1570.4 | bsz 240 | num_updates 3765 | lr 0.000515368 | gnorm 0.201 | clip 0 | train_wall 1 | wall 272\n",
            "epoch 252:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:44 | INFO | fairseq.trainer | begin training epoch 252\n",
            "2025-05-14 11:48:45 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)\n",
            "2025-05-14 11:48:45 | INFO | train | epoch 252 | loss 1.024 | nll_loss 0.163 | ppl 1.12 | wps 24093.3 | ups 15.34 | wpb 1570.4 | bsz 240 | num_updates 3780 | lr 0.000514344 | gnorm 0.172 | clip 0 | train_wall 1 | wall 273\n",
            "epoch 253:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:45 | INFO | fairseq.trainer | begin training epoch 253\n",
            "2025-05-14 11:48:46 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)\n",
            "2025-05-14 11:48:46 | INFO | train | epoch 253 | loss 1.021 | nll_loss 0.161 | ppl 1.12 | wps 24205 | ups 15.41 | wpb 1570.4 | bsz 240 | num_updates 3795 | lr 0.000513327 | gnorm 0.178 | clip 0 | train_wall 1 | wall 274\n",
            "epoch 254:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:46 | INFO | fairseq.trainer | begin training epoch 254\n",
            "2025-05-14 11:48:47 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)\n",
            "2025-05-14 11:48:47 | INFO | train | epoch 254 | loss 1.023 | nll_loss 0.16 | ppl 1.12 | wps 23595.9 | ups 15.03 | wpb 1570.4 | bsz 240 | num_updates 3810 | lr 0.000512316 | gnorm 0.147 | clip 0 | train_wall 1 | wall 275\n",
            "epoch 255:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:47 | INFO | fairseq.trainer | begin training epoch 255\n",
            "epoch 255:  87% 13/15 [00:00<00:00, 18.50it/s]2025-05-14 11:48:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint255.pt (epoch 255 @ 3825 updates, score None) (writing took 0.09343550099993081 seconds)\n",
            "2025-05-14 11:48:48 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)\n",
            "2025-05-14 11:48:48 | INFO | train | epoch 255 | loss 1.019 | nll_loss 0.158 | ppl 1.12 | wps 22014.1 | ups 14.02 | wpb 1570.4 | bsz 240 | num_updates 3825 | lr 0.00051131 | gnorm 0.148 | clip 0 | train_wall 1 | wall 276\n",
            "epoch 256:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:48 | INFO | fairseq.trainer | begin training epoch 256\n",
            "2025-05-14 11:48:49 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)\n",
            "2025-05-14 11:48:49 | INFO | train | epoch 256 | loss 1.024 | nll_loss 0.162 | ppl 1.12 | wps 23399.5 | ups 14.9 | wpb 1570.4 | bsz 240 | num_updates 3840 | lr 0.00051031 | gnorm 0.201 | clip 0 | train_wall 1 | wall 277\n",
            "epoch 257:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:49 | INFO | fairseq.trainer | begin training epoch 257\n",
            "2025-05-14 11:48:50 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)\n",
            "2025-05-14 11:48:50 | INFO | train | epoch 257 | loss 1.034 | nll_loss 0.177 | ppl 1.13 | wps 23865.4 | ups 15.2 | wpb 1570.4 | bsz 240 | num_updates 3855 | lr 0.000509317 | gnorm 0.358 | clip 6.7 | train_wall 1 | wall 278\n",
            "epoch 258:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:50 | INFO | fairseq.trainer | begin training epoch 258\n",
            "2025-05-14 11:48:51 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)\n",
            "2025-05-14 11:48:51 | INFO | train | epoch 258 | loss 1.04 | nll_loss 0.181 | ppl 1.13 | wps 24308.7 | ups 15.48 | wpb 1570.4 | bsz 240 | num_updates 3870 | lr 0.000508329 | gnorm 0.395 | clip 6.7 | train_wall 1 | wall 279\n",
            "epoch 259:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:51 | INFO | fairseq.trainer | begin training epoch 259\n",
            "2025-05-14 11:48:52 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)\n",
            "2025-05-14 11:48:52 | INFO | train | epoch 259 | loss 1.037 | nll_loss 0.178 | ppl 1.13 | wps 19807.7 | ups 12.61 | wpb 1570.4 | bsz 240 | num_updates 3885 | lr 0.000507346 | gnorm 0.293 | clip 0 | train_wall 1 | wall 280\n",
            "epoch 260:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:52 | INFO | fairseq.trainer | begin training epoch 260\n",
            "epoch 260:  93% 14/15 [00:01<00:00, 13.28it/s]2025-05-14 11:48:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint260.pt (epoch 260 @ 3900 updates, score None) (writing took 0.12344146500004172 seconds)\n",
            "2025-05-14 11:48:54 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)\n",
            "2025-05-14 11:48:54 | INFO | train | epoch 260 | loss 1.034 | nll_loss 0.175 | ppl 1.13 | wps 13921.9 | ups 8.87 | wpb 1570.4 | bsz 240 | num_updates 3900 | lr 0.00050637 | gnorm 0.335 | clip 6.7 | train_wall 1 | wall 282\n",
            "epoch 261:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:54 | INFO | fairseq.trainer | begin training epoch 261\n",
            "2025-05-14 11:48:55 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)\n",
            "2025-05-14 11:48:55 | INFO | train | epoch 261 | loss 1.028 | nll_loss 0.165 | ppl 1.12 | wps 21240.3 | ups 13.53 | wpb 1570.4 | bsz 240 | num_updates 3915 | lr 0.000505399 | gnorm 0.223 | clip 0 | train_wall 1 | wall 283\n",
            "epoch 262:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:55 | INFO | fairseq.trainer | begin training epoch 262\n",
            "2025-05-14 11:48:56 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)\n",
            "2025-05-14 11:48:56 | INFO | train | epoch 262 | loss 1.024 | nll_loss 0.164 | ppl 1.12 | wps 23638.5 | ups 15.05 | wpb 1570.4 | bsz 240 | num_updates 3930 | lr 0.000504433 | gnorm 0.168 | clip 0 | train_wall 1 | wall 284\n",
            "epoch 263:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:56 | INFO | fairseq.trainer | begin training epoch 263\n",
            "2025-05-14 11:48:57 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)\n",
            "2025-05-14 11:48:57 | INFO | train | epoch 263 | loss 1.022 | nll_loss 0.161 | ppl 1.12 | wps 23913.4 | ups 15.23 | wpb 1570.4 | bsz 240 | num_updates 3945 | lr 0.000503473 | gnorm 0.195 | clip 0 | train_wall 1 | wall 285\n",
            "epoch 264:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:57 | INFO | fairseq.trainer | begin training epoch 264\n",
            "2025-05-14 11:48:58 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)\n",
            "2025-05-14 11:48:58 | INFO | train | epoch 264 | loss 1.024 | nll_loss 0.163 | ppl 1.12 | wps 23020.1 | ups 14.66 | wpb 1570.4 | bsz 240 | num_updates 3960 | lr 0.000502519 | gnorm 0.235 | clip 0 | train_wall 1 | wall 286\n",
            "epoch 265:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:58 | INFO | fairseq.trainer | begin training epoch 265\n",
            "epoch 265:  93% 14/15 [00:00<00:00, 17.99it/s]2025-05-14 11:48:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:48:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint265.pt (epoch 265 @ 3975 updates, score None) (writing took 0.08303417499996613 seconds)\n",
            "2025-05-14 11:48:59 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)\n",
            "2025-05-14 11:48:59 | INFO | train | epoch 265 | loss 1.025 | nll_loss 0.164 | ppl 1.12 | wps 21405.6 | ups 13.63 | wpb 1570.4 | bsz 240 | num_updates 3975 | lr 0.00050157 | gnorm 0.279 | clip 0 | train_wall 1 | wall 287\n",
            "epoch 266:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:48:59 | INFO | fairseq.trainer | begin training epoch 266\n",
            "2025-05-14 11:49:00 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)\n",
            "2025-05-14 11:49:00 | INFO | train | epoch 266 | loss 1.025 | nll_loss 0.165 | ppl 1.12 | wps 23845 | ups 15.18 | wpb 1570.4 | bsz 240 | num_updates 3990 | lr 0.000500626 | gnorm 0.22 | clip 0 | train_wall 1 | wall 288\n",
            "epoch 267:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:00 | INFO | fairseq.trainer | begin training epoch 267\n",
            "2025-05-14 11:49:01 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)\n",
            "2025-05-14 11:49:01 | INFO | train | epoch 267 | loss 1.036 | nll_loss 0.176 | ppl 1.13 | wps 23488.5 | ups 14.96 | wpb 1570.4 | bsz 240 | num_updates 4005 | lr 0.000499688 | gnorm 0.249 | clip 0 | train_wall 1 | wall 289\n",
            "epoch 268:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:01 | INFO | fairseq.trainer | begin training epoch 268\n",
            "2025-05-14 11:49:02 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)\n",
            "2025-05-14 11:49:02 | INFO | train | epoch 268 | loss 1.031 | nll_loss 0.17 | ppl 1.13 | wps 23495.3 | ups 14.96 | wpb 1570.4 | bsz 240 | num_updates 4020 | lr 0.000498755 | gnorm 0.224 | clip 0 | train_wall 1 | wall 290\n",
            "epoch 269:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:02 | INFO | fairseq.trainer | begin training epoch 269\n",
            "2025-05-14 11:49:03 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)\n",
            "2025-05-14 11:49:03 | INFO | train | epoch 269 | loss 1.023 | nll_loss 0.163 | ppl 1.12 | wps 23477.6 | ups 14.95 | wpb 1570.4 | bsz 240 | num_updates 4035 | lr 0.000497827 | gnorm 0.209 | clip 0 | train_wall 1 | wall 291\n",
            "epoch 270:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:03 | INFO | fairseq.trainer | begin training epoch 270\n",
            "epoch 270:  93% 14/15 [00:00<00:00, 18.15it/s]2025-05-14 11:49:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint270.pt (epoch 270 @ 4050 updates, score None) (writing took 0.12187995399995089 seconds)\n",
            "2025-05-14 11:49:04 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)\n",
            "2025-05-14 11:49:04 | INFO | train | epoch 270 | loss 1.026 | nll_loss 0.166 | ppl 1.12 | wps 20508.3 | ups 13.06 | wpb 1570.4 | bsz 240 | num_updates 4050 | lr 0.000496904 | gnorm 0.25 | clip 0 | train_wall 1 | wall 292\n",
            "epoch 271:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:04 | INFO | fairseq.trainer | begin training epoch 271\n",
            "2025-05-14 11:49:05 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)\n",
            "2025-05-14 11:49:05 | INFO | train | epoch 271 | loss 1.023 | nll_loss 0.162 | ppl 1.12 | wps 16549.9 | ups 10.54 | wpb 1570.4 | bsz 240 | num_updates 4065 | lr 0.000495986 | gnorm 0.201 | clip 0 | train_wall 1 | wall 293\n",
            "epoch 272:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:05 | INFO | fairseq.trainer | begin training epoch 272\n",
            "2025-05-14 11:49:07 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)\n",
            "2025-05-14 11:49:07 | INFO | train | epoch 272 | loss 1.023 | nll_loss 0.162 | ppl 1.12 | wps 16850.9 | ups 10.73 | wpb 1570.4 | bsz 240 | num_updates 4080 | lr 0.000495074 | gnorm 0.205 | clip 0 | train_wall 1 | wall 295\n",
            "epoch 273:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:07 | INFO | fairseq.trainer | begin training epoch 273\n",
            "2025-05-14 11:49:08 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)\n",
            "2025-05-14 11:49:08 | INFO | train | epoch 273 | loss 1.022 | nll_loss 0.161 | ppl 1.12 | wps 24053.3 | ups 15.32 | wpb 1570.4 | bsz 240 | num_updates 4095 | lr 0.000494166 | gnorm 0.209 | clip 0 | train_wall 1 | wall 296\n",
            "epoch 274:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:08 | INFO | fairseq.trainer | begin training epoch 274\n",
            "2025-05-14 11:49:09 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)\n",
            "2025-05-14 11:49:09 | INFO | train | epoch 274 | loss 1.03 | nll_loss 0.17 | ppl 1.13 | wps 23786.4 | ups 15.15 | wpb 1570.4 | bsz 240 | num_updates 4110 | lr 0.000493264 | gnorm 0.289 | clip 0 | train_wall 1 | wall 297\n",
            "epoch 275:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:09 | INFO | fairseq.trainer | begin training epoch 275\n",
            "epoch 275:  87% 13/15 [00:00<00:00, 17.48it/s]2025-05-14 11:49:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint275.pt (epoch 275 @ 4125 updates, score None) (writing took 0.08420655899999474 seconds)\n",
            "2025-05-14 11:49:10 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)\n",
            "2025-05-14 11:49:10 | INFO | train | epoch 275 | loss 1.038 | nll_loss 0.181 | ppl 1.13 | wps 21723.4 | ups 13.83 | wpb 1570.4 | bsz 240 | num_updates 4125 | lr 0.000492366 | gnorm 0.288 | clip 0 | train_wall 1 | wall 298\n",
            "epoch 276:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:10 | INFO | fairseq.trainer | begin training epoch 276\n",
            "2025-05-14 11:49:11 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)\n",
            "2025-05-14 11:49:11 | INFO | train | epoch 276 | loss 1.031 | nll_loss 0.169 | ppl 1.12 | wps 23279.4 | ups 14.82 | wpb 1570.4 | bsz 240 | num_updates 4140 | lr 0.000491473 | gnorm 0.234 | clip 0 | train_wall 1 | wall 299\n",
            "epoch 277:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:11 | INFO | fairseq.trainer | begin training epoch 277\n",
            "2025-05-14 11:49:12 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)\n",
            "2025-05-14 11:49:12 | INFO | train | epoch 277 | loss 1.03 | nll_loss 0.171 | ppl 1.13 | wps 23864 | ups 15.2 | wpb 1570.4 | bsz 240 | num_updates 4155 | lr 0.000490585 | gnorm 0.291 | clip 0 | train_wall 1 | wall 300\n",
            "epoch 278:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:12 | INFO | fairseq.trainer | begin training epoch 278\n",
            "2025-05-14 11:49:13 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)\n",
            "2025-05-14 11:49:13 | INFO | train | epoch 278 | loss 1.028 | nll_loss 0.168 | ppl 1.12 | wps 23219 | ups 14.79 | wpb 1570.4 | bsz 240 | num_updates 4170 | lr 0.000489702 | gnorm 0.254 | clip 0 | train_wall 1 | wall 301\n",
            "epoch 279:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:13 | INFO | fairseq.trainer | begin training epoch 279\n",
            "2025-05-14 11:49:14 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)\n",
            "2025-05-14 11:49:14 | INFO | train | epoch 279 | loss 1.028 | nll_loss 0.168 | ppl 1.12 | wps 24044.3 | ups 15.31 | wpb 1570.4 | bsz 240 | num_updates 4185 | lr 0.000488824 | gnorm 0.243 | clip 0 | train_wall 1 | wall 302\n",
            "epoch 280:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:14 | INFO | fairseq.trainer | begin training epoch 280\n",
            "epoch 280:  80% 12/15 [00:00<00:00, 17.05it/s]2025-05-14 11:49:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint280.pt (epoch 280 @ 4200 updates, score None) (writing took 0.09163224300004913 seconds)\n",
            "2025-05-14 11:49:15 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)\n",
            "2025-05-14 11:49:15 | INFO | train | epoch 280 | loss 1.03 | nll_loss 0.172 | ppl 1.13 | wps 21147.7 | ups 13.47 | wpb 1570.4 | bsz 240 | num_updates 4200 | lr 0.00048795 | gnorm 0.283 | clip 6.7 | train_wall 1 | wall 303\n",
            "epoch 281:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:15 | INFO | fairseq.trainer | begin training epoch 281\n",
            "2025-05-14 11:49:16 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)\n",
            "2025-05-14 11:49:16 | INFO | train | epoch 281 | loss 1.028 | nll_loss 0.167 | ppl 1.12 | wps 22180.3 | ups 14.12 | wpb 1570.4 | bsz 240 | num_updates 4215 | lr 0.000487081 | gnorm 0.228 | clip 0 | train_wall 1 | wall 304\n",
            "epoch 282:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:16 | INFO | fairseq.trainer | begin training epoch 282\n",
            "2025-05-14 11:49:17 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)\n",
            "2025-05-14 11:49:17 | INFO | train | epoch 282 | loss 1.029 | nll_loss 0.169 | ppl 1.12 | wps 17391.7 | ups 11.07 | wpb 1570.4 | bsz 240 | num_updates 4230 | lr 0.000486217 | gnorm 0.235 | clip 0 | train_wall 1 | wall 305\n",
            "epoch 283:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:17 | INFO | fairseq.trainer | begin training epoch 283\n",
            "2025-05-14 11:49:19 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)\n",
            "2025-05-14 11:49:19 | INFO | train | epoch 283 | loss 1.024 | nll_loss 0.161 | ppl 1.12 | wps 12467.5 | ups 7.94 | wpb 1570.4 | bsz 240 | num_updates 4245 | lr 0.000485357 | gnorm 0.245 | clip 6.7 | train_wall 2 | wall 307\n",
            "epoch 284:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:19 | INFO | fairseq.trainer | begin training epoch 284\n",
            "2025-05-14 11:49:21 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)\n",
            "2025-05-14 11:49:21 | INFO | train | epoch 284 | loss 1.028 | nll_loss 0.169 | ppl 1.12 | wps 13053.2 | ups 8.31 | wpb 1570.4 | bsz 240 | num_updates 4260 | lr 0.000484502 | gnorm 0.267 | clip 6.7 | train_wall 2 | wall 309\n",
            "epoch 285:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:21 | INFO | fairseq.trainer | begin training epoch 285\n",
            "epoch 285:  87% 13/15 [00:00<00:00, 17.94it/s]2025-05-14 11:49:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint285.pt (epoch 285 @ 4275 updates, score None) (writing took 0.09778023100011524 seconds)\n",
            "2025-05-14 11:49:22 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)\n",
            "2025-05-14 11:49:22 | INFO | train | epoch 285 | loss 1.025 | nll_loss 0.165 | ppl 1.12 | wps 21255.2 | ups 13.53 | wpb 1570.4 | bsz 240 | num_updates 4275 | lr 0.000483651 | gnorm 0.174 | clip 0 | train_wall 1 | wall 310\n",
            "epoch 286:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:22 | INFO | fairseq.trainer | begin training epoch 286\n",
            "2025-05-14 11:49:23 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)\n",
            "2025-05-14 11:49:23 | INFO | train | epoch 286 | loss 1.022 | nll_loss 0.16 | ppl 1.12 | wps 23647.9 | ups 15.06 | wpb 1570.4 | bsz 240 | num_updates 4290 | lr 0.000482805 | gnorm 0.188 | clip 0 | train_wall 1 | wall 311\n",
            "epoch 287:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:23 | INFO | fairseq.trainer | begin training epoch 287\n",
            "2025-05-14 11:49:24 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)\n",
            "2025-05-14 11:49:24 | INFO | train | epoch 287 | loss 1.021 | nll_loss 0.16 | ppl 1.12 | wps 23899.6 | ups 15.22 | wpb 1570.4 | bsz 240 | num_updates 4305 | lr 0.000481963 | gnorm 0.143 | clip 0 | train_wall 1 | wall 312\n",
            "epoch 288:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:24 | INFO | fairseq.trainer | begin training epoch 288\n",
            "2025-05-14 11:49:25 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)\n",
            "2025-05-14 11:49:25 | INFO | train | epoch 288 | loss 1.022 | nll_loss 0.16 | ppl 1.12 | wps 23100 | ups 14.71 | wpb 1570.4 | bsz 240 | num_updates 4320 | lr 0.000481125 | gnorm 0.134 | clip 0 | train_wall 1 | wall 313\n",
            "epoch 289:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:25 | INFO | fairseq.trainer | begin training epoch 289\n",
            "2025-05-14 11:49:26 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)\n",
            "2025-05-14 11:49:26 | INFO | train | epoch 289 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 24171 | ups 15.39 | wpb 1570.4 | bsz 240 | num_updates 4335 | lr 0.000480292 | gnorm 0.164 | clip 0 | train_wall 1 | wall 314\n",
            "epoch 290:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:26 | INFO | fairseq.trainer | begin training epoch 290\n",
            "epoch 290:  80% 12/15 [00:00<00:00, 17.82it/s]2025-05-14 11:49:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint290.pt (epoch 290 @ 4350 updates, score None) (writing took 0.09139783199998419 seconds)\n",
            "2025-05-14 11:49:27 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)\n",
            "2025-05-14 11:49:27 | INFO | train | epoch 290 | loss 1.019 | nll_loss 0.158 | ppl 1.12 | wps 21560.9 | ups 13.73 | wpb 1570.4 | bsz 240 | num_updates 4350 | lr 0.000479463 | gnorm 0.132 | clip 0 | train_wall 1 | wall 315\n",
            "epoch 291:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:27 | INFO | fairseq.trainer | begin training epoch 291\n",
            "2025-05-14 11:49:28 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)\n",
            "2025-05-14 11:49:28 | INFO | train | epoch 291 | loss 1.019 | nll_loss 0.157 | ppl 1.12 | wps 22851 | ups 14.55 | wpb 1570.4 | bsz 240 | num_updates 4365 | lr 0.000478639 | gnorm 0.133 | clip 0 | train_wall 1 | wall 316\n",
            "epoch 292:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:28 | INFO | fairseq.trainer | begin training epoch 292\n",
            "2025-05-14 11:49:29 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)\n",
            "2025-05-14 11:49:29 | INFO | train | epoch 292 | loss 1.021 | nll_loss 0.16 | ppl 1.12 | wps 23269.7 | ups 14.82 | wpb 1570.4 | bsz 240 | num_updates 4380 | lr 0.000477818 | gnorm 0.183 | clip 0 | train_wall 1 | wall 317\n",
            "epoch 293:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:29 | INFO | fairseq.trainer | begin training epoch 293\n",
            "2025-05-14 11:49:30 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)\n",
            "2025-05-14 11:49:30 | INFO | train | epoch 293 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 23815.3 | ups 15.17 | wpb 1570.4 | bsz 240 | num_updates 4395 | lr 0.000477002 | gnorm 0.181 | clip 0 | train_wall 1 | wall 318\n",
            "epoch 294:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:30 | INFO | fairseq.trainer | begin training epoch 294\n",
            "2025-05-14 11:49:31 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)\n",
            "2025-05-14 11:49:31 | INFO | train | epoch 294 | loss 1.019 | nll_loss 0.158 | ppl 1.12 | wps 22215.6 | ups 14.15 | wpb 1570.4 | bsz 240 | num_updates 4410 | lr 0.00047619 | gnorm 0.118 | clip 0 | train_wall 1 | wall 319\n",
            "epoch 295:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:31 | INFO | fairseq.trainer | begin training epoch 295\n",
            "epoch 295:  87% 13/15 [00:01<00:00, 13.49it/s]2025-05-14 11:49:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint295.pt (epoch 295 @ 4425 updates, score None) (writing took 0.11839286100007484 seconds)\n",
            "2025-05-14 11:49:33 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)\n",
            "2025-05-14 11:49:33 | INFO | train | epoch 295 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 15240.5 | ups 9.7 | wpb 1570.4 | bsz 240 | num_updates 4425 | lr 0.000475383 | gnorm 0.127 | clip 0 | train_wall 1 | wall 321\n",
            "epoch 296:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:33 | INFO | fairseq.trainer | begin training epoch 296\n",
            "2025-05-14 11:49:34 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)\n",
            "2025-05-14 11:49:34 | INFO | train | epoch 296 | loss 1.018 | nll_loss 0.159 | ppl 1.12 | wps 18357.7 | ups 11.69 | wpb 1570.4 | bsz 240 | num_updates 4440 | lr 0.000474579 | gnorm 0.215 | clip 0 | train_wall 1 | wall 322\n",
            "epoch 297:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:34 | INFO | fairseq.trainer | begin training epoch 297\n",
            "2025-05-14 11:49:35 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)\n",
            "2025-05-14 11:49:35 | INFO | train | epoch 297 | loss 1.021 | nll_loss 0.158 | ppl 1.12 | wps 24193.9 | ups 15.41 | wpb 1570.4 | bsz 240 | num_updates 4455 | lr 0.000473779 | gnorm 0.188 | clip 0 | train_wall 1 | wall 323\n",
            "epoch 298:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:35 | INFO | fairseq.trainer | begin training epoch 298\n",
            "2025-05-14 11:49:36 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)\n",
            "2025-05-14 11:49:36 | INFO | train | epoch 298 | loss 1.022 | nll_loss 0.162 | ppl 1.12 | wps 24057.1 | ups 15.32 | wpb 1570.4 | bsz 240 | num_updates 4470 | lr 0.000472984 | gnorm 0.198 | clip 0 | train_wall 1 | wall 324\n",
            "epoch 299:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:36 | INFO | fairseq.trainer | begin training epoch 299\n",
            "2025-05-14 11:49:37 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)\n",
            "2025-05-14 11:49:37 | INFO | train | epoch 299 | loss 1.022 | nll_loss 0.16 | ppl 1.12 | wps 23963.5 | ups 15.26 | wpb 1570.4 | bsz 240 | num_updates 4485 | lr 0.000472192 | gnorm 0.206 | clip 0 | train_wall 1 | wall 325\n",
            "epoch 300:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:37 | INFO | fairseq.trainer | begin training epoch 300\n",
            "epoch 300:  87% 13/15 [00:00<00:00, 18.10it/s]2025-05-14 11:49:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint300.pt (epoch 300 @ 4500 updates, score None) (writing took 0.0943785909998951 seconds)\n",
            "2025-05-14 11:49:38 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)\n",
            "2025-05-14 11:49:38 | INFO | train | epoch 300 | loss 1.02 | nll_loss 0.16 | ppl 1.12 | wps 21933.4 | ups 13.97 | wpb 1570.4 | bsz 240 | num_updates 4500 | lr 0.000471405 | gnorm 0.174 | clip 0 | train_wall 1 | wall 326\n",
            "epoch 301:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:38 | INFO | fairseq.trainer | begin training epoch 301\n",
            "2025-05-14 11:49:39 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)\n",
            "2025-05-14 11:49:39 | INFO | train | epoch 301 | loss 1.02 | nll_loss 0.159 | ppl 1.12 | wps 23883.4 | ups 15.21 | wpb 1570.4 | bsz 240 | num_updates 4515 | lr 0.000470621 | gnorm 0.196 | clip 0 | train_wall 1 | wall 327\n",
            "epoch 302:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:39 | INFO | fairseq.trainer | begin training epoch 302\n",
            "2025-05-14 11:49:40 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)\n",
            "2025-05-14 11:49:40 | INFO | train | epoch 302 | loss 1.02 | nll_loss 0.159 | ppl 1.12 | wps 23886.4 | ups 15.21 | wpb 1570.4 | bsz 240 | num_updates 4530 | lr 0.000469841 | gnorm 0.213 | clip 0 | train_wall 1 | wall 328\n",
            "epoch 303:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:40 | INFO | fairseq.trainer | begin training epoch 303\n",
            "2025-05-14 11:49:41 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)\n",
            "2025-05-14 11:49:41 | INFO | train | epoch 303 | loss 1.027 | nll_loss 0.168 | ppl 1.12 | wps 22530.7 | ups 14.35 | wpb 1570.4 | bsz 240 | num_updates 4545 | lr 0.000469065 | gnorm 0.194 | clip 0 | train_wall 1 | wall 329\n",
            "epoch 304:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:41 | INFO | fairseq.trainer | begin training epoch 304\n",
            "2025-05-14 11:49:42 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)\n",
            "2025-05-14 11:49:42 | INFO | train | epoch 304 | loss 1.02 | nll_loss 0.16 | ppl 1.12 | wps 23906 | ups 15.22 | wpb 1570.4 | bsz 240 | num_updates 4560 | lr 0.000468293 | gnorm 0.172 | clip 0 | train_wall 1 | wall 330\n",
            "epoch 305:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:42 | INFO | fairseq.trainer | begin training epoch 305\n",
            "epoch 305:  80% 12/15 [00:00<00:00, 17.36it/s]2025-05-14 11:49:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint305.pt (epoch 305 @ 4575 updates, score None) (writing took 0.09150413299994398 seconds)\n",
            "2025-05-14 11:49:43 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)\n",
            "2025-05-14 11:49:43 | INFO | train | epoch 305 | loss 1.02 | nll_loss 0.159 | ppl 1.12 | wps 22029.1 | ups 14.03 | wpb 1570.4 | bsz 240 | num_updates 4575 | lr 0.000467525 | gnorm 0.164 | clip 0 | train_wall 1 | wall 331\n",
            "epoch 306:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:43 | INFO | fairseq.trainer | begin training epoch 306\n",
            "2025-05-14 11:49:44 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)\n",
            "2025-05-14 11:49:44 | INFO | train | epoch 306 | loss 1.018 | nll_loss 0.158 | ppl 1.12 | wps 19740.1 | ups 12.57 | wpb 1570.4 | bsz 240 | num_updates 4590 | lr 0.00046676 | gnorm 0.193 | clip 0 | train_wall 1 | wall 332\n",
            "epoch 307:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:44 | INFO | fairseq.trainer | begin training epoch 307\n",
            "2025-05-14 11:49:46 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)\n",
            "2025-05-14 11:49:46 | INFO | train | epoch 307 | loss 1.02 | nll_loss 0.159 | ppl 1.12 | wps 16251.3 | ups 10.35 | wpb 1570.4 | bsz 240 | num_updates 4605 | lr 0.000465999 | gnorm 0.227 | clip 0 | train_wall 1 | wall 334\n",
            "epoch 308:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:46 | INFO | fairseq.trainer | begin training epoch 308\n",
            "2025-05-14 11:49:47 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)\n",
            "2025-05-14 11:49:47 | INFO | train | epoch 308 | loss 1.022 | nll_loss 0.163 | ppl 1.12 | wps 20466.5 | ups 13.03 | wpb 1570.4 | bsz 240 | num_updates 4620 | lr 0.000465242 | gnorm 0.205 | clip 0 | train_wall 1 | wall 335\n",
            "epoch 309:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:47 | INFO | fairseq.trainer | begin training epoch 309\n",
            "2025-05-14 11:49:48 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)\n",
            "2025-05-14 11:49:48 | INFO | train | epoch 309 | loss 1.021 | nll_loss 0.161 | ppl 1.12 | wps 24331.6 | ups 15.49 | wpb 1570.4 | bsz 240 | num_updates 4635 | lr 0.000464489 | gnorm 0.172 | clip 0 | train_wall 1 | wall 336\n",
            "epoch 310:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:48 | INFO | fairseq.trainer | begin training epoch 310\n",
            "epoch 310:  80% 12/15 [00:00<00:00, 17.47it/s]2025-05-14 11:49:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint310.pt (epoch 310 @ 4650 updates, score None) (writing took 0.12587364099999832 seconds)\n",
            "2025-05-14 11:49:49 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)\n",
            "2025-05-14 11:49:49 | INFO | train | epoch 310 | loss 1.019 | nll_loss 0.158 | ppl 1.12 | wps 21168.1 | ups 13.48 | wpb 1570.4 | bsz 240 | num_updates 4650 | lr 0.000463739 | gnorm 0.193 | clip 0 | train_wall 1 | wall 337\n",
            "epoch 311:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:49 | INFO | fairseq.trainer | begin training epoch 311\n",
            "2025-05-14 11:49:50 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)\n",
            "2025-05-14 11:49:50 | INFO | train | epoch 311 | loss 1.018 | nll_loss 0.159 | ppl 1.12 | wps 23703 | ups 15.09 | wpb 1570.4 | bsz 240 | num_updates 4665 | lr 0.000462993 | gnorm 0.156 | clip 0 | train_wall 1 | wall 338\n",
            "epoch 312:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:50 | INFO | fairseq.trainer | begin training epoch 312\n",
            "2025-05-14 11:49:51 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)\n",
            "2025-05-14 11:49:51 | INFO | train | epoch 312 | loss 1.017 | nll_loss 0.155 | ppl 1.11 | wps 23307.4 | ups 14.84 | wpb 1570.4 | bsz 240 | num_updates 4680 | lr 0.00046225 | gnorm 0.138 | clip 0 | train_wall 1 | wall 339\n",
            "epoch 313:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:51 | INFO | fairseq.trainer | begin training epoch 313\n",
            "2025-05-14 11:49:52 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)\n",
            "2025-05-14 11:49:52 | INFO | train | epoch 313 | loss 1.018 | nll_loss 0.158 | ppl 1.12 | wps 23489.1 | ups 14.96 | wpb 1570.4 | bsz 240 | num_updates 4695 | lr 0.000461511 | gnorm 0.227 | clip 6.7 | train_wall 1 | wall 340\n",
            "epoch 314:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:52 | INFO | fairseq.trainer | begin training epoch 314\n",
            "2025-05-14 11:49:53 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)\n",
            "2025-05-14 11:49:53 | INFO | train | epoch 314 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 23916.7 | ups 15.23 | wpb 1570.4 | bsz 240 | num_updates 4710 | lr 0.000460776 | gnorm 0.171 | clip 0 | train_wall 1 | wall 341\n",
            "epoch 315:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:53 | INFO | fairseq.trainer | begin training epoch 315\n",
            "epoch 315:  93% 14/15 [00:00<00:00, 18.37it/s]2025-05-14 11:49:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:49:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint315.pt (epoch 315 @ 4725 updates, score None) (writing took 0.08030347700014318 seconds)\n",
            "2025-05-14 11:49:54 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)\n",
            "2025-05-14 11:49:54 | INFO | train | epoch 315 | loss 1.02 | nll_loss 0.159 | ppl 1.12 | wps 22041.4 | ups 14.04 | wpb 1570.4 | bsz 240 | num_updates 4725 | lr 0.000460044 | gnorm 0.189 | clip 0 | train_wall 1 | wall 342\n",
            "epoch 316:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:54 | INFO | fairseq.trainer | begin training epoch 316\n",
            "2025-05-14 11:49:55 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)\n",
            "2025-05-14 11:49:55 | INFO | train | epoch 316 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 23779.9 | ups 15.14 | wpb 1570.4 | bsz 240 | num_updates 4740 | lr 0.000459315 | gnorm 0.183 | clip 0 | train_wall 1 | wall 343\n",
            "epoch 317:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:55 | INFO | fairseq.trainer | begin training epoch 317\n",
            "2025-05-14 11:49:56 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)\n",
            "2025-05-14 11:49:56 | INFO | train | epoch 317 | loss 1.022 | nll_loss 0.162 | ppl 1.12 | wps 23892 | ups 15.21 | wpb 1570.4 | bsz 240 | num_updates 4755 | lr 0.00045859 | gnorm 0.259 | clip 6.7 | train_wall 1 | wall 344\n",
            "epoch 318:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:56 | INFO | fairseq.trainer | begin training epoch 318\n",
            "2025-05-14 11:49:58 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)\n",
            "2025-05-14 11:49:58 | INFO | train | epoch 318 | loss 1.024 | nll_loss 0.165 | ppl 1.12 | wps 17498.3 | ups 11.14 | wpb 1570.4 | bsz 240 | num_updates 4770 | lr 0.000457869 | gnorm 0.232 | clip 0 | train_wall 1 | wall 345\n",
            "epoch 319:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:58 | INFO | fairseq.trainer | begin training epoch 319\n",
            "2025-05-14 11:49:59 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)\n",
            "2025-05-14 11:49:59 | INFO | train | epoch 319 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 15782.2 | ups 10.05 | wpb 1570.4 | bsz 240 | num_updates 4785 | lr 0.00045715 | gnorm 0.14 | clip 0 | train_wall 1 | wall 347\n",
            "epoch 320:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:49:59 | INFO | fairseq.trainer | begin training epoch 320\n",
            "epoch 320:  80% 12/15 [00:00<00:00, 16.47it/s]2025-05-14 11:50:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:50:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint320.pt (epoch 320 @ 4800 updates, score None) (writing took 0.08677710699998897 seconds)\n",
            "2025-05-14 11:50:00 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)\n",
            "2025-05-14 11:50:00 | INFO | train | epoch 320 | loss 1.02 | nll_loss 0.16 | ppl 1.12 | wps 21813.1 | ups 13.89 | wpb 1570.4 | bsz 240 | num_updates 4800 | lr 0.000456435 | gnorm 0.16 | clip 0 | train_wall 1 | wall 348\n",
            "epoch 321:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:00 | INFO | fairseq.trainer | begin training epoch 321\n",
            "2025-05-14 11:50:01 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)\n",
            "2025-05-14 11:50:01 | INFO | train | epoch 321 | loss 1.017 | nll_loss 0.156 | ppl 1.11 | wps 23579.2 | ups 15.01 | wpb 1570.4 | bsz 240 | num_updates 4815 | lr 0.000455724 | gnorm 0.143 | clip 0 | train_wall 1 | wall 349\n",
            "epoch 322:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:01 | INFO | fairseq.trainer | begin training epoch 322\n",
            "2025-05-14 11:50:02 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)\n",
            "2025-05-14 11:50:02 | INFO | train | epoch 322 | loss 1.018 | nll_loss 0.157 | ppl 1.12 | wps 23944.8 | ups 15.25 | wpb 1570.4 | bsz 240 | num_updates 4830 | lr 0.000455016 | gnorm 0.141 | clip 0 | train_wall 1 | wall 350\n",
            "epoch 323:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:02 | INFO | fairseq.trainer | begin training epoch 323\n",
            "2025-05-14 11:50:03 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)\n",
            "2025-05-14 11:50:03 | INFO | train | epoch 323 | loss 1.015 | nll_loss 0.155 | ppl 1.11 | wps 23659.2 | ups 15.07 | wpb 1570.4 | bsz 240 | num_updates 4845 | lr 0.000454311 | gnorm 0.12 | clip 0 | train_wall 1 | wall 351\n",
            "epoch 324:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:03 | INFO | fairseq.trainer | begin training epoch 324\n",
            "2025-05-14 11:50:04 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)\n",
            "2025-05-14 11:50:04 | INFO | train | epoch 324 | loss 1.016 | nll_loss 0.155 | ppl 1.11 | wps 23683 | ups 15.08 | wpb 1570.4 | bsz 240 | num_updates 4860 | lr 0.000453609 | gnorm 0.123 | clip 0 | train_wall 1 | wall 352\n",
            "epoch 325:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:04 | INFO | fairseq.trainer | begin training epoch 325\n",
            "epoch 325:  93% 14/15 [00:00<00:00, 17.78it/s]2025-05-14 11:50:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:50:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint325.pt (epoch 325 @ 4875 updates, score None) (writing took 0.08784359100013717 seconds)\n",
            "2025-05-14 11:50:05 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)\n",
            "2025-05-14 11:50:05 | INFO | train | epoch 325 | loss 1.018 | nll_loss 0.159 | ppl 1.12 | wps 21711.3 | ups 13.83 | wpb 1570.4 | bsz 240 | num_updates 4875 | lr 0.000452911 | gnorm 0.199 | clip 0 | train_wall 1 | wall 353\n",
            "epoch 326:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:05 | INFO | fairseq.trainer | begin training epoch 326\n",
            "2025-05-14 11:50:06 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)\n",
            "2025-05-14 11:50:06 | INFO | train | epoch 326 | loss 1.018 | nll_loss 0.158 | ppl 1.12 | wps 24373.8 | ups 15.52 | wpb 1570.4 | bsz 240 | num_updates 4890 | lr 0.000452216 | gnorm 0.166 | clip 0 | train_wall 1 | wall 354\n",
            "epoch 327:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:06 | INFO | fairseq.trainer | begin training epoch 327\n",
            "2025-05-14 11:50:07 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)\n",
            "2025-05-14 11:50:07 | INFO | train | epoch 327 | loss 1.019 | nll_loss 0.159 | ppl 1.12 | wps 23626.2 | ups 15.04 | wpb 1570.4 | bsz 240 | num_updates 4905 | lr 0.000451524 | gnorm 0.167 | clip 0 | train_wall 1 | wall 355\n",
            "epoch 328:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:07 | INFO | fairseq.trainer | begin training epoch 328\n",
            "2025-05-14 11:50:08 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)\n",
            "2025-05-14 11:50:08 | INFO | train | epoch 328 | loss 1.018 | nll_loss 0.158 | ppl 1.12 | wps 24314.5 | ups 15.48 | wpb 1570.4 | bsz 240 | num_updates 4920 | lr 0.000450835 | gnorm 0.135 | clip 0 | train_wall 1 | wall 356\n",
            "epoch 329:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:08 | INFO | fairseq.trainer | begin training epoch 329\n",
            "2025-05-14 11:50:09 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)\n",
            "2025-05-14 11:50:09 | INFO | train | epoch 329 | loss 1.02 | nll_loss 0.16 | ppl 1.12 | wps 21875.4 | ups 13.93 | wpb 1570.4 | bsz 240 | num_updates 4935 | lr 0.000450149 | gnorm 0.169 | clip 0 | train_wall 1 | wall 357\n",
            "epoch 330:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:09 | INFO | fairseq.trainer | begin training epoch 330\n",
            "epoch 330:  87% 13/15 [00:01<00:00, 13.87it/s]2025-05-14 11:50:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:50:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint330.pt (epoch 330 @ 4950 updates, score None) (writing took 0.12264271699996243 seconds)\n",
            "2025-05-14 11:50:11 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)\n",
            "2025-05-14 11:50:11 | INFO | train | epoch 330 | loss 1.02 | nll_loss 0.16 | ppl 1.12 | wps 15000.5 | ups 9.55 | wpb 1570.4 | bsz 240 | num_updates 4950 | lr 0.000449467 | gnorm 0.139 | clip 0 | train_wall 1 | wall 359\n",
            "epoch 331:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:11 | INFO | fairseq.trainer | begin training epoch 331\n",
            "2025-05-14 11:50:12 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)\n",
            "2025-05-14 11:50:12 | INFO | train | epoch 331 | loss 1.016 | nll_loss 0.155 | ppl 1.11 | wps 17757.5 | ups 11.31 | wpb 1570.4 | bsz 240 | num_updates 4965 | lr 0.000448787 | gnorm 0.115 | clip 0 | train_wall 1 | wall 360\n",
            "epoch 332:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:12 | INFO | fairseq.trainer | begin training epoch 332\n",
            "2025-05-14 11:50:13 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)\n",
            "2025-05-14 11:50:13 | INFO | train | epoch 332 | loss 1.016 | nll_loss 0.156 | ppl 1.11 | wps 23440.2 | ups 14.93 | wpb 1570.4 | bsz 240 | num_updates 4980 | lr 0.000448111 | gnorm 0.141 | clip 0 | train_wall 1 | wall 361\n",
            "epoch 333:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:13 | INFO | fairseq.trainer | begin training epoch 333\n",
            "2025-05-14 11:50:14 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)\n",
            "2025-05-14 11:50:14 | INFO | train | epoch 333 | loss 1.016 | nll_loss 0.156 | ppl 1.11 | wps 24086.1 | ups 15.34 | wpb 1570.4 | bsz 240 | num_updates 4995 | lr 0.000447437 | gnorm 0.139 | clip 0 | train_wall 1 | wall 362\n",
            "epoch 334:   0% 0/15 [00:00<?, ?it/s]2025-05-14 11:50:14 | INFO | fairseq.trainer | begin training epoch 334\n",
            "epoch 334:  27% 4/15 [00:00<00:01,  9.42it/s]2025-05-14 11:50:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 11:50:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-s/checkpoint_last.pt (epoch 334 @ 5000 updates, score None) (writing took 0.0706609409999146 seconds)\n",
            "2025-05-14 11:50:15 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)\n",
            "2025-05-14 11:50:15 | INFO | train | epoch 334 | loss 1.013 | nll_loss 0.154 | ppl 1.11 | wps 9311.7 | ups 8.28 | wpb 1125.2 | bsz 208 | num_updates 5000 | lr 0.000447214 | gnorm 0.062 | clip 0 | train_wall 0 | wall 363\n",
            "2025-05-14 11:50:15 | INFO | fairseq_cli.train | done training in 362.6 seconds\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint100-dev.res\n",
            "2025-05-14 11:50:16 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint100.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:16 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:16 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:16 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:16 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:16 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:16 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint100.pt\n",
            "2025-05-14 11:50:19 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:19 | INFO | fairseq_cli.generate | Translated 450 sentences (2929 tokens) in 0.8s (562.05 sentences/s, 3658.31 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint105-dev.res\n",
            "2025-05-14 11:50:21 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint105.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:21 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:21 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:21 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:21 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint105.pt\n",
            "2025-05-14 11:50:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:24 | INFO | fairseq_cli.generate | Translated 450 sentences (2937 tokens) in 1.0s (430.01 sentences/s, 2806.56 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint10-dev.res\n",
            "2025-05-14 11:50:26 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint10.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:26 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:26 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:26 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:26 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint10.pt\n",
            "2025-05-14 11:50:29 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:29 | INFO | fairseq_cli.generate | Translated 450 sentences (1620 tokens) in 0.7s (662.44 sentences/s, 2384.78 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint110-dev.res\n",
            "2025-05-14 11:50:30 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint110.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:30 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:30 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:30 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:30 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:30 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:30 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint110.pt\n",
            "2025-05-14 11:50:33 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:33 | INFO | fairseq_cli.generate | Translated 450 sentences (2934 tokens) in 0.8s (597.50 sentences/s, 3895.68 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint115-dev.res\n",
            "2025-05-14 11:50:34 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint115.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:34 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:34 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:34 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:34 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:34 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:34 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint115.pt\n",
            "2025-05-14 11:50:38 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:38 | INFO | fairseq_cli.generate | Translated 450 sentences (2928 tokens) in 0.8s (594.51 sentences/s, 3868.26 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint120-dev.res\n",
            "2025-05-14 11:50:39 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint120.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:39 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:39 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:39 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:39 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:39 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:39 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint120.pt\n",
            "2025-05-14 11:50:43 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:43 | INFO | fairseq_cli.generate | Translated 450 sentences (2930 tokens) in 0.8s (596.87 sentences/s, 3886.31 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint125-dev.res\n",
            "2025-05-14 11:50:44 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint125.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:44 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:44 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:44 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:44 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:44 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:44 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint125.pt\n",
            "2025-05-14 11:50:47 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:47 | INFO | fairseq_cli.generate | Translated 450 sentences (2928 tokens) in 0.8s (544.57 sentences/s, 3543.34 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint130-dev.res\n",
            "2025-05-14 11:50:49 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint130.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:49 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:49 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:49 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:49 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint130.pt\n",
            "2025-05-14 11:50:52 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:52 | INFO | fairseq_cli.generate | Translated 450 sentences (2919 tokens) in 0.8s (596.05 sentences/s, 3866.40 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint135-dev.res\n",
            "2025-05-14 11:50:53 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint135.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:53 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:53 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:53 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:53 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:53 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:53 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint135.pt\n",
            "2025-05-14 11:50:57 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:50:57 | INFO | fairseq_cli.generate | Translated 450 sentences (2918 tokens) in 0.7s (601.91 sentences/s, 3903.02 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint140-dev.res\n",
            "2025-05-14 11:50:58 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint140.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:50:58 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:50:58 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:50:58 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:50:58 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:50:58 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:50:58 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint140.pt\n",
            "2025-05-14 11:51:02 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:02 | INFO | fairseq_cli.generate | Translated 450 sentences (2942 tokens) in 0.9s (475.51 sentences/s, 3108.75 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint145-dev.res\n",
            "2025-05-14 11:51:03 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint145.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:03 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:03 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:03 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:03 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint145.pt\n",
            "2025-05-14 11:51:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:06 | INFO | fairseq_cli.generate | Translated 450 sentences (2926 tokens) in 0.7s (604.94 sentences/s, 3933.43 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint150-dev.res\n",
            "2025-05-14 11:51:07 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint150.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:07 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:07 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:07 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:07 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint150.pt\n",
            "2025-05-14 11:51:10 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:10 | INFO | fairseq_cli.generate | Translated 450 sentences (2930 tokens) in 0.8s (597.58 sentences/s, 3890.91 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint155-dev.res\n",
            "2025-05-14 11:51:12 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint155.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:12 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:12 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:12 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:12 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:12 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:12 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint155.pt\n",
            "2025-05-14 11:51:15 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:15 | INFO | fairseq_cli.generate | Translated 450 sentences (2923 tokens) in 0.7s (609.31 sentences/s, 3957.84 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint15-dev.res\n",
            "2025-05-14 11:51:17 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint15.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:17 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:17 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:17 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:17 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint15.pt\n",
            "2025-05-14 11:51:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:20 | INFO | fairseq_cli.generate | Translated 450 sentences (2448 tokens) in 0.7s (621.28 sentences/s, 3379.78 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint160-dev.res\n",
            "2025-05-14 11:51:21 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint160.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:21 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:21 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:21 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:21 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint160.pt\n",
            "2025-05-14 11:51:25 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:25 | INFO | fairseq_cli.generate | Translated 450 sentences (2933 tokens) in 1.0s (458.87 sentences/s, 2990.83 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint165-dev.res\n",
            "2025-05-14 11:51:26 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint165.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:26 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:26 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:26 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:26 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint165.pt\n",
            "2025-05-14 11:51:29 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:29 | INFO | fairseq_cli.generate | Translated 450 sentences (2907 tokens) in 0.8s (594.17 sentences/s, 3838.34 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint170-dev.res\n",
            "2025-05-14 11:51:31 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint170.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:31 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:31 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:31 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:31 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:31 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:31 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint170.pt\n",
            "2025-05-14 11:51:34 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:34 | INFO | fairseq_cli.generate | Translated 450 sentences (2927 tokens) in 0.7s (603.06 sentences/s, 3922.58 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint175-dev.res\n",
            "2025-05-14 11:51:35 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint175.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:35 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:35 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:35 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:35 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:35 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:35 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint175.pt\n",
            "2025-05-14 11:51:39 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:39 | INFO | fairseq_cli.generate | Translated 450 sentences (2922 tokens) in 0.7s (600.62 sentences/s, 3900.00 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint180-dev.res\n",
            "2025-05-14 11:51:40 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint180.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:40 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:40 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:40 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:40 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:40 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:40 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint180.pt\n",
            "2025-05-14 11:51:43 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:43 | INFO | fairseq_cli.generate | Translated 450 sentences (2907 tokens) in 0.7s (601.22 sentences/s, 3883.91 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint185-dev.res\n",
            "2025-05-14 11:51:45 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint185.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:45 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:45 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:45 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:45 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint185.pt\n",
            "2025-05-14 11:51:48 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:48 | INFO | fairseq_cli.generate | Translated 450 sentences (2933 tokens) in 0.8s (572.19 sentences/s, 3729.38 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint190-dev.res\n",
            "2025-05-14 11:51:50 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint190.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:50 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:50 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:50 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:50 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:50 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:50 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint190.pt\n",
            "2025-05-14 11:51:53 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:53 | INFO | fairseq_cli.generate | Translated 450 sentences (2930 tokens) in 0.8s (582.92 sentences/s, 3795.43 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint195-dev.res\n",
            "2025-05-14 11:51:54 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint195.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:54 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:54 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:54 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:54 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint195.pt\n",
            "2025-05-14 11:51:58 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:51:58 | INFO | fairseq_cli.generate | Translated 450 sentences (2922 tokens) in 0.7s (601.72 sentences/s, 3907.16 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint200-dev.res\n",
            "2025-05-14 11:51:59 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint200.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:51:59 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:51:59 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:51:59 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:51:59 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:51:59 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:51:59 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint200.pt\n",
            "2025-05-14 11:52:03 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:03 | INFO | fairseq_cli.generate | Translated 450 sentences (2930 tokens) in 1.0s (452.58 sentences/s, 2946.77 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint205-dev.res\n",
            "2025-05-14 11:52:04 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint205.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:04 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:04 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:04 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:04 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:04 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:04 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint205.pt\n",
            "2025-05-14 11:52:07 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:07 | INFO | fairseq_cli.generate | Translated 450 sentences (2927 tokens) in 0.7s (600.94 sentences/s, 3908.75 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint20-dev.res\n",
            "2025-05-14 11:52:08 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint20.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:08 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:08 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:08 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:08 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint20.pt\n",
            "2025-05-14 11:52:13 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:13 | INFO | fairseq_cli.generate | Translated 450 sentences (2919 tokens) in 1.9s (240.92 sentences/s, 1562.80 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint210-dev.res\n",
            "2025-05-14 11:52:14 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint210.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:14 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:14 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:14 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:14 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:14 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:14 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint210.pt\n",
            "2025-05-14 11:52:18 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:18 | INFO | fairseq_cli.generate | Translated 450 sentences (2926 tokens) in 0.7s (600.70 sentences/s, 3905.88 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint215-dev.res\n",
            "2025-05-14 11:52:19 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint215.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:19 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:19 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:19 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:19 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:19 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:19 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint215.pt\n",
            "2025-05-14 11:52:22 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:22 | INFO | fairseq_cli.generate | Translated 450 sentences (2924 tokens) in 0.8s (556.26 sentences/s, 3614.43 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint220-dev.res\n",
            "2025-05-14 11:52:23 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint220.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:23 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:23 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:23 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:23 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:23 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:23 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint220.pt\n",
            "2025-05-14 11:52:27 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:27 | INFO | fairseq_cli.generate | Translated 450 sentences (2925 tokens) in 1.0s (446.29 sentences/s, 2900.87 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint225-dev.res\n",
            "2025-05-14 11:52:28 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint225.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:28 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:28 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:28 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:28 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:28 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:28 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint225.pt\n",
            "2025-05-14 11:52:31 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:31 | INFO | fairseq_cli.generate | Translated 450 sentences (2931 tokens) in 0.8s (594.13 sentences/s, 3869.75 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint230-dev.res\n",
            "2025-05-14 11:52:33 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint230.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:33 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:33 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:33 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:33 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:33 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:33 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint230.pt\n",
            "2025-05-14 11:52:36 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:36 | INFO | fairseq_cli.generate | Translated 450 sentences (2931 tokens) in 0.8s (580.08 sentences/s, 3778.28 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint235-dev.res\n",
            "2025-05-14 11:52:38 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint235.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:38 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:38 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:38 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:38 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:38 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:38 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint235.pt\n",
            "2025-05-14 11:52:41 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:41 | INFO | fairseq_cli.generate | Translated 450 sentences (2926 tokens) in 0.8s (584.36 sentences/s, 3799.62 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint240-dev.res\n",
            "2025-05-14 11:52:42 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint240.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:42 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:42 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:42 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:42 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:42 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:42 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint240.pt\n",
            "2025-05-14 11:52:46 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:46 | INFO | fairseq_cli.generate | Translated 450 sentences (2926 tokens) in 0.8s (586.95 sentences/s, 3816.47 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint245-dev.res\n",
            "2025-05-14 11:52:47 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint245.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:47 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:47 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:47 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:47 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:47 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:47 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint245.pt\n",
            "2025-05-14 11:52:51 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:51 | INFO | fairseq_cli.generate | Translated 450 sentences (2925 tokens) in 1.1s (428.37 sentences/s, 2784.41 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint250-dev.res\n",
            "2025-05-14 11:52:52 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint250.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:52 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:52 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:52 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:52 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:52 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:52 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint250.pt\n",
            "2025-05-14 11:52:56 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:52:56 | INFO | fairseq_cli.generate | Translated 450 sentences (2936 tokens) in 0.8s (590.81 sentences/s, 3854.68 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint255-dev.res\n",
            "2025-05-14 11:52:57 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint255.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:52:57 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:52:57 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:52:57 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:52:57 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:52:57 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:52:57 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint255.pt\n",
            "2025-05-14 11:53:00 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:00 | INFO | fairseq_cli.generate | Translated 450 sentences (2933 tokens) in 0.8s (581.44 sentences/s, 3789.69 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint25-dev.res\n",
            "2025-05-14 11:53:01 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint25.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:01 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:01 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:01 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:01 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:01 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:01 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint25.pt\n",
            "2025-05-14 11:53:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:06 | INFO | fairseq_cli.generate | Translated 450 sentences (3100 tokens) in 1.9s (241.85 sentences/s, 1666.11 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint260-dev.res\n",
            "2025-05-14 11:53:08 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint260.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:08 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:08 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:08 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:08 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint260.pt\n",
            "2025-05-14 11:53:11 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:11 | INFO | fairseq_cli.generate | Translated 450 sentences (2927 tokens) in 0.7s (611.46 sentences/s, 3977.18 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint265-dev.res\n",
            "2025-05-14 11:53:12 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint265.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:12 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:12 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:12 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:12 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:12 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:12 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint265.pt\n",
            "2025-05-14 11:53:16 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:16 | INFO | fairseq_cli.generate | Translated 450 sentences (2920 tokens) in 1.0s (435.48 sentences/s, 2825.81 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint270-dev.res\n",
            "2025-05-14 11:53:17 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint270.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:17 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:17 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:17 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:17 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint270.pt\n",
            "2025-05-14 11:53:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:20 | INFO | fairseq_cli.generate | Translated 450 sentences (2931 tokens) in 0.8s (585.04 sentences/s, 3810.53 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint275-dev.res\n",
            "2025-05-14 11:53:22 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint275.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:22 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:22 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:22 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:22 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:22 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:22 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint275.pt\n",
            "2025-05-14 11:53:25 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:25 | INFO | fairseq_cli.generate | Translated 450 sentences (2927 tokens) in 0.8s (597.82 sentences/s, 3888.50 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint280-dev.res\n",
            "2025-05-14 11:53:26 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint280.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:26 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:26 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:26 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:26 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint280.pt\n",
            "2025-05-14 11:53:30 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:30 | INFO | fairseq_cli.generate | Translated 450 sentences (2910 tokens) in 0.8s (593.25 sentences/s, 3836.34 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint285-dev.res\n",
            "2025-05-14 11:53:31 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint285.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:31 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:31 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:31 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:31 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:31 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:31 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint285.pt\n",
            "2025-05-14 11:53:35 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:35 | INFO | fairseq_cli.generate | Translated 450 sentences (2919 tokens) in 0.8s (598.44 sentences/s, 3881.86 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint290-dev.res\n",
            "2025-05-14 11:53:36 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint290.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:36 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:36 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:36 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:36 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:36 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:36 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint290.pt\n",
            "2025-05-14 11:53:39 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:39 | INFO | fairseq_cli.generate | Translated 450 sentences (2932 tokens) in 0.9s (526.37 sentences/s, 3429.59 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint295-dev.res\n",
            "2025-05-14 11:53:41 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint295.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:41 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:41 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:41 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:41 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:41 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:41 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint295.pt\n",
            "2025-05-14 11:53:44 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:44 | INFO | fairseq_cli.generate | Translated 450 sentences (2935 tokens) in 0.8s (588.42 sentences/s, 3837.80 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint300-dev.res\n",
            "2025-05-14 11:53:45 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint300.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:45 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:45 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:45 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:45 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint300.pt\n",
            "2025-05-14 11:53:49 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:49 | INFO | fairseq_cli.generate | Translated 450 sentences (2921 tokens) in 0.8s (595.56 sentences/s, 3865.83 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint305-dev.res\n",
            "2025-05-14 11:53:50 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint305.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:50 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:50 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:50 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:50 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:50 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:50 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint305.pt\n",
            "2025-05-14 11:53:54 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:54 | INFO | fairseq_cli.generate | Translated 450 sentences (2932 tokens) in 0.9s (506.63 sentences/s, 3301.00 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint30-dev.res\n",
            "2025-05-14 11:53:55 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint30.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:53:55 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:53:55 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:53:55 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:53:55 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:53:55 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:53:55 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint30.pt\n",
            "2025-05-14 11:53:58 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:53:58 | INFO | fairseq_cli.generate | Translated 450 sentences (2764 tokens) in 0.7s (612.70 sentences/s, 3763.33 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint310-dev.res\n",
            "2025-05-14 11:54:00 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint310.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:00 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:00 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:00 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:00 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:00 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:00 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint310.pt\n",
            "2025-05-14 11:54:03 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:03 | INFO | fairseq_cli.generate | Translated 450 sentences (2931 tokens) in 1.0s (445.38 sentences/s, 2900.88 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint315-dev.res\n",
            "2025-05-14 11:54:06 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint315.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:06 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:06 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:06 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:06 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:06 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:06 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint315.pt\n",
            "2025-05-14 11:54:09 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:09 | INFO | fairseq_cli.generate | Translated 450 sentences (2933 tokens) in 0.8s (588.26 sentences/s, 3834.17 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint320-dev.res\n",
            "2025-05-14 11:54:10 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint320.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:10 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:10 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:10 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:10 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:10 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:10 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint320.pt\n",
            "2025-05-14 11:54:13 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:13 | INFO | fairseq_cli.generate | Translated 450 sentences (2918 tokens) in 0.7s (609.01 sentences/s, 3949.11 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint325-dev.res\n",
            "2025-05-14 11:54:14 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint325.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:14 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:14 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:14 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:14 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:14 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:14 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint325.pt\n",
            "2025-05-14 11:54:18 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:18 | INFO | fairseq_cli.generate | Translated 450 sentences (2923 tokens) in 1.0s (435.42 sentences/s, 2828.31 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint330-dev.res\n",
            "2025-05-14 11:54:20 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint330.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:20 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:20 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:20 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:20 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:20 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:20 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint330.pt\n",
            "2025-05-14 11:54:23 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:23 | INFO | fairseq_cli.generate | Translated 450 sentences (2928 tokens) in 0.7s (601.26 sentences/s, 3912.18 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint35-dev.res\n",
            "2025-05-14 11:54:24 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint35.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:24 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:24 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:24 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:24 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:24 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:24 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint35.pt\n",
            "2025-05-14 11:54:27 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:27 | INFO | fairseq_cli.generate | Translated 450 sentences (2780 tokens) in 0.7s (612.58 sentences/s, 3784.37 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint40-dev.res\n",
            "2025-05-14 11:54:29 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint40.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:29 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:29 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:29 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:29 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:29 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:29 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint40.pt\n",
            "2025-05-14 11:54:32 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:32 | INFO | fairseq_cli.generate | Translated 450 sentences (2862 tokens) in 0.7s (606.03 sentences/s, 3854.35 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint45-dev.res\n",
            "2025-05-14 11:54:34 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint45.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:34 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:34 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:34 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:34 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:34 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:34 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint45.pt\n",
            "2025-05-14 11:54:37 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:37 | INFO | fairseq_cli.generate | Translated 450 sentences (2886 tokens) in 0.7s (603.81 sentences/s, 3872.46 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint50-dev.res\n",
            "2025-05-14 11:54:38 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint50.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:38 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:38 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:38 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:38 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:38 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:38 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint50.pt\n",
            "2025-05-14 11:54:42 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:42 | INFO | fairseq_cli.generate | Translated 450 sentences (2928 tokens) in 0.9s (484.95 sentences/s, 3155.39 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint55-dev.res\n",
            "2025-05-14 11:54:43 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint55.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:43 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:43 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:43 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:43 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:43 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:43 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint55.pt\n",
            "2025-05-14 11:54:46 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:46 | INFO | fairseq_cli.generate | Translated 450 sentences (2947 tokens) in 0.7s (608.86 sentences/s, 3987.34 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint5-dev.res\n",
            "2025-05-14 11:54:48 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint5.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:48 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:48 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:48 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:48 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:48 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:48 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint5.pt\n",
            "2025-05-14 11:54:51 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:51 | INFO | fairseq_cli.generate | Translated 450 sentences (2159 tokens) in 0.6s (700.45 sentences/s, 3360.60 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint60-dev.res\n",
            "2025-05-14 11:54:52 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint60.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:52 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:52 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:52 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:52 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:52 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:52 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint60.pt\n",
            "2025-05-14 11:54:56 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:54:56 | INFO | fairseq_cli.generate | Translated 450 sentences (2908 tokens) in 0.9s (503.59 sentences/s, 3254.33 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint65-dev.res\n",
            "2025-05-14 11:54:57 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint65.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:54:57 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:54:57 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:54:57 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:54:57 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:54:57 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:54:57 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint65.pt\n",
            "2025-05-14 11:55:01 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:01 | INFO | fairseq_cli.generate | Translated 450 sentences (2856 tokens) in 0.7s (602.74 sentences/s, 3825.40 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint70-dev.res\n",
            "2025-05-14 11:55:02 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint70.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:02 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:02 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:02 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:02 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:02 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:02 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint70.pt\n",
            "2025-05-14 11:55:05 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:05 | INFO | fairseq_cli.generate | Translated 450 sentences (2925 tokens) in 0.8s (592.33 sentences/s, 3850.15 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint75-dev.res\n",
            "2025-05-14 11:55:07 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint75.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:07 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:07 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:07 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:07 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint75.pt\n",
            "2025-05-14 11:55:10 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:10 | INFO | fairseq_cli.generate | Translated 450 sentences (2933 tokens) in 0.8s (599.91 sentences/s, 3910.05 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint80-dev.res\n",
            "2025-05-14 11:55:11 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint80.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:11 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:11 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:11 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:11 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:11 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:11 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint80.pt\n",
            "2025-05-14 11:55:15 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:15 | INFO | fairseq_cli.generate | Translated 450 sentences (2920 tokens) in 0.7s (603.91 sentences/s, 3918.73 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint85-dev.res\n",
            "2025-05-14 11:55:16 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint85.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:16 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:16 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:16 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:16 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:16 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:16 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint85.pt\n",
            "2025-05-14 11:55:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:20 | INFO | fairseq_cli.generate | Translated 450 sentences (2910 tokens) in 1.0s (442.89 sentences/s, 2864.03 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint90-dev.res\n",
            "2025-05-14 11:55:21 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint90.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:21 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:21 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:21 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:21 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint90.pt\n",
            "2025-05-14 11:55:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:24 | INFO | fairseq_cli.generate | Translated 450 sentences (2930 tokens) in 0.8s (566.36 sentences/s, 3687.65 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint95-dev.res\n",
            "2025-05-14 11:55:25 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='valid', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint95.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:25 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:25 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:25 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:25 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:25 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:25 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint95.pt\n",
            "2025-05-14 11:55:29 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:29 | INFO | fairseq_cli.generate | Translated 450 sentences (2927 tokens) in 0.8s (597.58 sentences/s, 3886.92 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint100-test.res\n",
            "2025-05-14 11:55:30 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint100.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:30 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:30 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:30 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:30 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:30 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:30 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint100.pt\n",
            "2025-05-14 11:55:34 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:34 | INFO | fairseq_cli.generate | Translated 450 sentences (2946 tokens) in 0.7s (601.11 sentences/s, 3935.26 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint105-test.res\n",
            "2025-05-14 11:55:35 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint105.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:35 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:35 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:35 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:35 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:35 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:35 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint105.pt\n",
            "2025-05-14 11:55:38 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:38 | INFO | fairseq_cli.generate | Translated 450 sentences (2949 tokens) in 0.7s (610.59 sentences/s, 4001.41 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint10-test.res\n",
            "2025-05-14 11:55:39 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint10.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:39 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:39 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:39 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:39 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:39 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:39 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint10.pt\n",
            "2025-05-14 11:55:43 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:43 | INFO | fairseq_cli.generate | Translated 450 sentences (1638 tokens) in 0.7s (661.17 sentences/s, 2406.65 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint110-test.res\n",
            "2025-05-14 11:55:44 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint110.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:44 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:44 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:44 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:44 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:44 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:44 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint110.pt\n",
            "2025-05-14 11:55:48 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:48 | INFO | fairseq_cli.generate | Translated 450 sentences (2948 tokens) in 0.8s (587.17 sentences/s, 3846.60 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint115-test.res\n",
            "2025-05-14 11:55:49 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint115.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:49 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:49 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:49 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:49 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint115.pt\n",
            "2025-05-14 11:55:52 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:52 | INFO | fairseq_cli.generate | Translated 450 sentences (2953 tokens) in 0.7s (604.16 sentences/s, 3964.64 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint120-test.res\n",
            "2025-05-14 11:55:53 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint120.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:53 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:53 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:53 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:53 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:53 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:53 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint120.pt\n",
            "2025-05-14 11:55:57 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:55:57 | INFO | fairseq_cli.generate | Translated 450 sentences (2952 tokens) in 1.0s (443.01 sentences/s, 2906.15 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint125-test.res\n",
            "2025-05-14 11:55:58 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint125.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:55:58 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:55:58 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:55:58 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:55:58 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:55:58 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:55:58 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint125.pt\n",
            "2025-05-14 11:56:01 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:01 | INFO | fairseq_cli.generate | Translated 450 sentences (2949 tokens) in 0.7s (612.93 sentences/s, 4016.74 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint130-test.res\n",
            "2025-05-14 11:56:03 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint130.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:03 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:03 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:03 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:03 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint130.pt\n",
            "2025-05-14 11:56:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:06 | INFO | fairseq_cli.generate | Translated 450 sentences (2952 tokens) in 0.7s (607.39 sentences/s, 3984.50 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint135-test.res\n",
            "2025-05-14 11:56:07 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint135.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:07 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:07 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:07 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:07 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint135.pt\n",
            "2025-05-14 11:56:11 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:11 | INFO | fairseq_cli.generate | Translated 450 sentences (2947 tokens) in 0.7s (608.38 sentences/s, 3984.22 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint140-test.res\n",
            "2025-05-14 11:56:12 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint140.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:12 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:12 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:12 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:12 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:12 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:12 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint140.pt\n",
            "2025-05-14 11:56:15 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:15 | INFO | fairseq_cli.generate | Translated 450 sentences (2952 tokens) in 0.7s (608.51 sentences/s, 3991.80 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint145-test.res\n",
            "2025-05-14 11:56:16 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint145.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:16 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:16 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:16 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:16 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:16 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:16 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint145.pt\n",
            "2025-05-14 11:56:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:20 | INFO | fairseq_cli.generate | Translated 450 sentences (2945 tokens) in 0.9s (512.68 sentences/s, 3355.19 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint150-test.res\n",
            "2025-05-14 11:56:21 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint150.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:21 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:21 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:21 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:21 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint150.pt\n",
            "2025-05-14 11:56:25 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:25 | INFO | fairseq_cli.generate | Translated 450 sentences (2953 tokens) in 0.8s (573.07 sentences/s, 3760.63 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint155-test.res\n",
            "2025-05-14 11:56:26 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint155.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:26 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:26 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:26 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:26 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:26 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint155.pt\n",
            "2025-05-14 11:56:29 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:29 | INFO | fairseq_cli.generate | Translated 450 sentences (2951 tokens) in 0.7s (609.08 sentences/s, 3994.18 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint15-test.res\n",
            "2025-05-14 11:56:30 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint15.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:30 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:30 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:30 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:30 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:30 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:30 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint15.pt\n",
            "2025-05-14 11:56:34 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:34 | INFO | fairseq_cli.generate | Translated 450 sentences (2498 tokens) in 0.9s (487.33 sentences/s, 2705.23 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint160-test.res\n",
            "2025-05-14 11:56:35 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint160.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:35 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:35 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:35 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:35 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:35 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:35 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint160.pt\n",
            "2025-05-14 11:56:38 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:38 | INFO | fairseq_cli.generate | Translated 450 sentences (2952 tokens) in 0.7s (600.25 sentences/s, 3937.65 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint165-test.res\n",
            "2025-05-14 11:56:40 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint165.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:40 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:40 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:40 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:40 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:40 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:40 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint165.pt\n",
            "2025-05-14 11:56:43 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:43 | INFO | fairseq_cli.generate | Translated 450 sentences (2939 tokens) in 0.7s (603.71 sentences/s, 3942.91 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint170-test.res\n",
            "2025-05-14 11:56:45 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint170.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:45 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:45 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:45 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:45 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint170.pt\n",
            "2025-05-14 11:56:48 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:48 | INFO | fairseq_cli.generate | Translated 450 sentences (2948 tokens) in 0.7s (614.57 sentences/s, 4026.09 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint175-test.res\n",
            "2025-05-14 11:56:49 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint175.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:49 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:49 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:49 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:49 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint175.pt\n",
            "2025-05-14 11:56:52 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:52 | INFO | fairseq_cli.generate | Translated 450 sentences (2943 tokens) in 0.7s (606.59 sentences/s, 3967.09 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint180-test.res\n",
            "2025-05-14 11:56:54 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint180.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:54 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:54 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:54 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:54 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint180.pt\n",
            "2025-05-14 11:56:57 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:56:57 | INFO | fairseq_cli.generate | Translated 450 sentences (2945 tokens) in 1.0s (461.56 sentences/s, 3020.65 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint185-test.res\n",
            "2025-05-14 11:56:59 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint185.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:56:59 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:56:59 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:56:59 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:56:59 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:56:59 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:56:59 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint185.pt\n",
            "2025-05-14 11:57:02 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:02 | INFO | fairseq_cli.generate | Translated 450 sentences (2945 tokens) in 0.7s (603.14 sentences/s, 3947.23 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint190-test.res\n",
            "2025-05-14 11:57:03 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint190.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:03 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:03 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:03 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:03 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint190.pt\n",
            "2025-05-14 11:57:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:06 | INFO | fairseq_cli.generate | Translated 450 sentences (2944 tokens) in 0.7s (601.69 sentences/s, 3936.37 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint195-test.res\n",
            "2025-05-14 11:57:07 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint195.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:07 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:07 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:07 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:07 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:07 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint195.pt\n",
            "2025-05-14 11:57:11 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:11 | INFO | fairseq_cli.generate | Translated 450 sentences (2937 tokens) in 0.8s (588.44 sentences/s, 3840.52 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint200-test.res\n",
            "2025-05-14 11:57:13 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint200.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:13 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:13 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:13 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:13 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:13 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:13 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint200.pt\n",
            "2025-05-14 11:57:16 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:16 | INFO | fairseq_cli.generate | Translated 450 sentences (2954 tokens) in 0.8s (598.81 sentences/s, 3930.84 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint205-test.res\n",
            "2025-05-14 11:57:17 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint205.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:17 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:17 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:17 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:17 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint205.pt\n",
            "2025-05-14 11:57:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:20 | INFO | fairseq_cli.generate | Translated 450 sentences (2944 tokens) in 0.7s (600.75 sentences/s, 3930.23 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint20-test.res\n",
            "2025-05-14 11:57:22 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint20.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:22 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:22 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:22 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:22 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:22 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:22 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint20.pt\n",
            "2025-05-14 11:57:26 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:26 | INFO | fairseq_cli.generate | Translated 450 sentences (2944 tokens) in 1.8s (244.71 sentences/s, 1600.96 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint210-test.res\n",
            "2025-05-14 11:57:28 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint210.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:28 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:28 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:28 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:28 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:28 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:28 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint210.pt\n",
            "2025-05-14 11:57:31 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:31 | INFO | fairseq_cli.generate | Translated 450 sentences (2947 tokens) in 0.7s (605.72 sentences/s, 3966.82 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint215-test.res\n",
            "2025-05-14 11:57:32 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint215.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:32 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:32 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:32 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:32 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:32 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:32 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint215.pt\n",
            "2025-05-14 11:57:36 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:36 | INFO | fairseq_cli.generate | Translated 450 sentences (2944 tokens) in 0.8s (589.36 sentences/s, 3855.73 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint220-test.res\n",
            "2025-05-14 11:57:37 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint220.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:37 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:37 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:37 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:37 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:37 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:37 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint220.pt\n",
            "2025-05-14 11:57:40 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:40 | INFO | fairseq_cli.generate | Translated 450 sentences (2950 tokens) in 0.7s (610.30 sentences/s, 4000.85 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint225-test.res\n",
            "2025-05-14 11:57:41 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint225.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:41 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:41 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:41 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:41 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:41 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:41 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint225.pt\n",
            "2025-05-14 11:57:45 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:45 | INFO | fairseq_cli.generate | Translated 450 sentences (2950 tokens) in 0.7s (605.15 sentences/s, 3967.09 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint230-test.res\n",
            "2025-05-14 11:57:46 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint230.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:46 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:46 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:46 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:46 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:46 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:46 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint230.pt\n",
            "2025-05-14 11:57:50 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:50 | INFO | fairseq_cli.generate | Translated 450 sentences (2948 tokens) in 0.7s (606.25 sentences/s, 3971.62 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint235-test.res\n",
            "2025-05-14 11:57:51 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint235.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:51 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:51 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:51 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:51 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:51 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:51 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint235.pt\n",
            "2025-05-14 11:57:54 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:54 | INFO | fairseq_cli.generate | Translated 450 sentences (2944 tokens) in 0.8s (597.08 sentences/s, 3906.23 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint240-test.res\n",
            "2025-05-14 11:57:55 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint240.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:57:55 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:57:55 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:57:55 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:57:55 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:57:55 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:57:55 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint240.pt\n",
            "2025-05-14 11:57:59 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:57:59 | INFO | fairseq_cli.generate | Translated 450 sentences (2954 tokens) in 1.0s (440.35 sentences/s, 2890.68 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint245-test.res\n",
            "2025-05-14 11:58:00 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint245.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:00 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:00 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:00 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:00 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:00 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:00 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint245.pt\n",
            "2025-05-14 11:58:04 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:04 | INFO | fairseq_cli.generate | Translated 450 sentences (2951 tokens) in 0.7s (606.98 sentences/s, 3980.47 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint250-test.res\n",
            "2025-05-14 11:58:05 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint250.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:05 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:05 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:05 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:05 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:05 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:05 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint250.pt\n",
            "2025-05-14 11:58:08 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:08 | INFO | fairseq_cli.generate | Translated 450 sentences (2959 tokens) in 0.7s (606.51 sentences/s, 3988.16 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint255-test.res\n",
            "2025-05-14 11:58:10 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint255.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:10 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:10 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:10 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:10 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:10 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:10 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint255.pt\n",
            "2025-05-14 11:58:13 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:13 | INFO | fairseq_cli.generate | Translated 450 sentences (2955 tokens) in 0.8s (596.96 sentences/s, 3920.05 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint25-test.res\n",
            "2025-05-14 11:58:14 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint25.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:14 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:14 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:14 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:14 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:14 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:14 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint25.pt\n",
            "2025-05-14 11:58:19 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:19 | INFO | fairseq_cli.generate | Translated 450 sentences (3106 tokens) in 1.8s (250.44 sentences/s, 1728.57 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint260-test.res\n",
            "2025-05-14 11:58:20 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint260.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:20 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:20 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:20 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:20 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:20 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:20 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint260.pt\n",
            "2025-05-14 11:58:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:24 | INFO | fairseq_cli.generate | Translated 450 sentences (2953 tokens) in 1.0s (442.44 sentences/s, 2903.42 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint265-test.res\n",
            "2025-05-14 11:58:25 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint265.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:25 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:25 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:25 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:25 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:25 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:25 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint265.pt\n",
            "2025-05-14 11:58:28 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:28 | INFO | fairseq_cli.generate | Translated 450 sentences (2945 tokens) in 0.8s (597.48 sentences/s, 3910.19 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint270-test.res\n",
            "2025-05-14 11:58:29 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint270.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:29 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:29 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:29 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:29 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:29 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:29 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint270.pt\n",
            "2025-05-14 11:58:33 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:33 | INFO | fairseq_cli.generate | Translated 450 sentences (2945 tokens) in 0.7s (602.68 sentences/s, 3944.20 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint275-test.res\n",
            "2025-05-14 11:58:34 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint275.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:34 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:34 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:34 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:34 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:34 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:34 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint275.pt\n",
            "2025-05-14 11:58:38 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:38 | INFO | fairseq_cli.generate | Translated 450 sentences (2949 tokens) in 0.7s (601.98 sentences/s, 3944.95 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint280-test.res\n",
            "2025-05-14 11:58:39 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint280.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:39 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:39 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:39 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:39 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:39 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:39 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint280.pt\n",
            "2025-05-14 11:58:42 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:42 | INFO | fairseq_cli.generate | Translated 450 sentences (2937 tokens) in 0.8s (592.52 sentences/s, 3867.16 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint285-test.res\n",
            "2025-05-14 11:58:44 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint285.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:44 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:44 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:44 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:44 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:44 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:44 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint285.pt\n",
            "2025-05-14 11:58:48 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:48 | INFO | fairseq_cli.generate | Translated 450 sentences (2946 tokens) in 1.0s (455.34 sentences/s, 2980.93 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint290-test.res\n",
            "2025-05-14 11:58:49 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint290.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:49 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:49 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:49 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:49 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:49 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint290.pt\n",
            "2025-05-14 11:58:52 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:52 | INFO | fairseq_cli.generate | Translated 450 sentences (2948 tokens) in 0.8s (596.98 sentences/s, 3910.86 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint295-test.res\n",
            "2025-05-14 11:58:54 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint295.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:54 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:54 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:54 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:54 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint295.pt\n",
            "2025-05-14 11:58:57 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:58:57 | INFO | fairseq_cli.generate | Translated 450 sentences (2948 tokens) in 0.8s (568.65 sentences/s, 3725.29 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint300-test.res\n",
            "2025-05-14 11:58:58 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint300.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:58:58 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:58:58 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:58:58 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:58:58 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:58:58 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:58:58 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint300.pt\n",
            "2025-05-14 11:59:02 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:02 | INFO | fairseq_cli.generate | Translated 450 sentences (2945 tokens) in 0.8s (596.30 sentences/s, 3902.48 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint305-test.res\n",
            "2025-05-14 11:59:03 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint305.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:03 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:03 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:03 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:03 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:03 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint305.pt\n",
            "2025-05-14 11:59:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:06 | INFO | fairseq_cli.generate | Translated 450 sentences (2949 tokens) in 0.7s (608.40 sentences/s, 3987.07 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint30-test.res\n",
            "2025-05-14 11:59:08 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint30.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:08 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:08 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:08 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:08 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint30.pt\n",
            "2025-05-14 11:59:11 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:11 | INFO | fairseq_cli.generate | Translated 450 sentences (2780 tokens) in 0.7s (615.64 sentences/s, 3803.30 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint310-test.res\n",
            "2025-05-14 11:59:13 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint310.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:13 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:13 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:13 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:13 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:13 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:13 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint310.pt\n",
            "2025-05-14 11:59:16 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:16 | INFO | fairseq_cli.generate | Translated 450 sentences (2944 tokens) in 0.7s (600.68 sentences/s, 3929.81 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint315-test.res\n",
            "2025-05-14 11:59:17 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint315.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:17 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:17 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:17 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:17 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:17 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint315.pt\n",
            "2025-05-14 11:59:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:20 | INFO | fairseq_cli.generate | Translated 450 sentences (2947 tokens) in 0.7s (614.53 sentences/s, 4024.49 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint320-test.res\n",
            "2025-05-14 11:59:21 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint320.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:21 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:21 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:21 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:21 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:21 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint320.pt\n",
            "2025-05-14 11:59:25 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:25 | INFO | fairseq_cli.generate | Translated 450 sentences (2941 tokens) in 1.1s (418.41 sentences/s, 2734.57 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint325-test.res\n",
            "2025-05-14 11:59:27 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint325.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:27 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:27 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:27 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:27 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:27 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:27 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint325.pt\n",
            "2025-05-14 11:59:30 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:30 | INFO | fairseq_cli.generate | Translated 450 sentences (2942 tokens) in 0.8s (592.27 sentences/s, 3872.10 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint330-test.res\n",
            "2025-05-14 11:59:31 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint330.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:31 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:31 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:31 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:31 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:31 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:31 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint330.pt\n",
            "2025-05-14 11:59:34 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:34 | INFO | fairseq_cli.generate | Translated 450 sentences (2942 tokens) in 0.8s (598.81 sentences/s, 3914.90 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint35-test.res\n",
            "2025-05-14 11:59:36 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint35.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:36 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:36 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:36 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:36 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:36 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:36 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint35.pt\n",
            "2025-05-14 11:59:39 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:39 | INFO | fairseq_cli.generate | Translated 450 sentences (2844 tokens) in 0.7s (605.46 sentences/s, 3826.48 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint40-test.res\n",
            "2025-05-14 11:59:40 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint40.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:40 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:40 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:40 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:40 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:40 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:40 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint40.pt\n",
            "2025-05-14 11:59:44 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:44 | INFO | fairseq_cli.generate | Translated 450 sentences (2886 tokens) in 0.7s (603.28 sentences/s, 3869.05 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint45-test.res\n",
            "2025-05-14 11:59:45 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint45.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:45 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:45 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:45 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:45 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:45 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint45.pt\n",
            "2025-05-14 11:59:48 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:48 | INFO | fairseq_cli.generate | Translated 450 sentences (2908 tokens) in 0.9s (502.23 sentences/s, 3245.51 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint50-test.res\n",
            "2025-05-14 11:59:50 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint50.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:50 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:50 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:50 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:50 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:50 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:50 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint50.pt\n",
            "2025-05-14 11:59:53 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:53 | INFO | fairseq_cli.generate | Translated 450 sentences (2954 tokens) in 0.8s (594.28 sentences/s, 3901.14 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint55-test.res\n",
            "2025-05-14 11:59:54 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint55.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:54 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:54 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:54 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:54 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:54 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint55.pt\n",
            "2025-05-14 11:59:58 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 11:59:58 | INFO | fairseq_cli.generate | Translated 450 sentences (2978 tokens) in 1.0s (460.31 sentences/s, 3046.22 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint5-test.res\n",
            "2025-05-14 11:59:59 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint5.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 11:59:59 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 11:59:59 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 11:59:59 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 11:59:59 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 11:59:59 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 11:59:59 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint5.pt\n",
            "2025-05-14 12:00:03 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:03 | INFO | fairseq_cli.generate | Translated 450 sentences (2135 tokens) in 0.8s (598.01 sentences/s, 2837.23 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint60-test.res\n",
            "2025-05-14 12:00:04 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint60.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:04 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:04 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:04 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:04 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:04 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:04 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint60.pt\n",
            "2025-05-14 12:00:07 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:07 | INFO | fairseq_cli.generate | Translated 450 sentences (2939 tokens) in 0.8s (596.85 sentences/s, 3898.10 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint65-test.res\n",
            "2025-05-14 12:00:08 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint65.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:08 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:08 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:08 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:08 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:08 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint65.pt\n",
            "2025-05-14 12:00:12 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:12 | INFO | fairseq_cli.generate | Translated 450 sentences (2899 tokens) in 0.7s (601.15 sentences/s, 3872.77 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint70-test.res\n",
            "2025-05-14 12:00:13 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint70.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:13 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:13 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:13 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:13 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:13 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:13 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint70.pt\n",
            "2025-05-14 12:00:17 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:17 | INFO | fairseq_cli.generate | Translated 450 sentences (2942 tokens) in 0.7s (610.31 sentences/s, 3990.10 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint75-test.res\n",
            "2025-05-14 12:00:18 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint75.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:18 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:18 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:18 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:18 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:18 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:18 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint75.pt\n",
            "2025-05-14 12:00:21 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:21 | INFO | fairseq_cli.generate | Translated 450 sentences (2946 tokens) in 0.8s (597.24 sentences/s, 3909.93 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint80-test.res\n",
            "2025-05-14 12:00:22 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint80.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:22 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:22 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:22 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:22 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:22 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:22 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint80.pt\n",
            "2025-05-14 12:00:26 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:26 | INFO | fairseq_cli.generate | Translated 450 sentences (2941 tokens) in 1.0s (460.25 sentences/s, 3007.97 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint85-test.res\n",
            "2025-05-14 12:00:28 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint85.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:28 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:28 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:28 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:28 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:28 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:28 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint85.pt\n",
            "2025-05-14 12:00:31 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:31 | INFO | fairseq_cli.generate | Translated 450 sentences (2944 tokens) in 0.7s (610.33 sentences/s, 3992.90 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint90-test.res\n",
            "2025-05-14 12:00:32 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint90.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:32 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:32 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:32 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:32 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:32 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:32 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint90.pt\n",
            "2025-05-14 12:00:35 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:35 | INFO | fairseq_cli.generate | Translated 450 sentences (2943 tokens) in 0.8s (598.61 sentences/s, 3914.90 tokens/s)\n",
            "Evaluating into checkpoints/fre-256-.1-s-s/checkpoint95-test.res\n",
            "2025-05-14 12:00:36 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=None, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=True, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/fre-256-.1-s-s/checkpoint95.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1917, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', target_lang='fre.phonemes', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2025-05-14 12:00:36 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:36 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:36 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:36 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/test.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:36 | INFO | fairseq.tasks.translation | data-bin/fre test fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:36 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/fre-256-.1-s-s/checkpoint95.pt\n",
            "2025-05-14 12:00:40 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-05-14 12:00:40 | INFO | fairseq_cli.generate | Translated 450 sentences (2954 tokens) in 0.7s (610.19 sentences/s, 4005.58 tokens/s)\n",
            "2025-05-14 12:00:42 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.1, batch_size=256, batch_size_valid=256, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/fre', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=256, device_id=0, disable_validation=True, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=128, encoder_embed_path=None, encoder_ffn_embed_dim=512, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=5000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/fre-256-.1-s-l', save_interval=5, save_interval_updates=0, scoring='bleu', seed=1917, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fre.graphemes', stop_time_hours=0, target_lang='fre.phonemes', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=1000, weight_decay=0.0, zero_sharding='none')\n",
            "2025-05-14 12:00:42 | INFO | fairseq.tasks.translation | [fre.graphemes] dictionary: 40 types\n",
            "2025-05-14 12:00:42 | INFO | fairseq.tasks.translation | [fre.phonemes] dictionary: 48 types\n",
            "2025-05-14 12:00:42 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:42 | INFO | fairseq.data.data_utils | loaded 450 examples from: data-bin/fre/valid.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:42 | INFO | fairseq.tasks.translation | data-bin/fre valid fre.graphemes-fre.phonemes 450 examples\n",
            "2025-05-14 12:00:42 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(40, 128, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(48, 256, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=256, out_features=48, bias=False)\n",
            "  )\n",
            ")\n",
            "2025-05-14 12:00:42 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
            "2025-05-14 12:00:42 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
            "2025-05-14 12:00:42 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
            "2025-05-14 12:00:42 | INFO | fairseq_cli.train | num. model params: 4762880 (num. trained: 4762880)\n",
            "2025-05-14 12:00:43 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2025-05-14 12:00:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2025-05-14 12:00:43 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.741 GB ; name = Tesla T4                                \n",
            "2025-05-14 12:00:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2025-05-14 12:00:43 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2025-05-14 12:00:43 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 256\n",
            "2025-05-14 12:00:43 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/fre-256-.1-s-l/checkpoint_last.pt\n",
            "2025-05-14 12:00:43 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2025-05-14 12:00:43 | INFO | fairseq.data.data_utils | loaded 3600 examples from: data-bin/fre/train.fre.graphemes-fre.phonemes.fre.graphemes\n",
            "2025-05-14 12:00:43 | INFO | fairseq.data.data_utils | loaded 3600 examples from: data-bin/fre/train.fre.graphemes-fre.phonemes.fre.phonemes\n",
            "2025-05-14 12:00:43 | INFO | fairseq.tasks.translation | data-bin/fre train fre.graphemes-fre.phonemes 3600 examples\n",
            "2025-05-14 12:00:43 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
            "epoch 001:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:43 | INFO | fairseq.trainer | begin training epoch 1\n",
            "/usr/local/envs/task1/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "2025-05-14 12:00:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2025-05-14 12:00:45 | INFO | train | epoch 001 | loss 10.242 | nll_loss 10.238 | ppl 1207.99 | wps 26140.5 | ups 16.61 | wpb 1570.4 | bsz 240 | num_updates 15 | lr 1.50985e-05 | gnorm 8.815 | clip 100 | train_wall 1 | wall 1\n",
            "epoch 002:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:45 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2025-05-14 12:00:46 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2025-05-14 12:00:46 | INFO | train | epoch 002 | loss 8.195 | nll_loss 8.152 | ppl 284.39 | wps 20022.1 | ups 12.75 | wpb 1570.4 | bsz 240 | num_updates 30 | lr 3.0097e-05 | gnorm 5.838 | clip 100 | train_wall 1 | wall 3\n",
            "epoch 003:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:46 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2025-05-14 12:00:47 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2025-05-14 12:00:47 | INFO | train | epoch 003 | loss 6.225 | nll_loss 6.129 | ppl 70 | wps 20262.9 | ups 12.9 | wpb 1570.4 | bsz 240 | num_updates 45 | lr 4.50955e-05 | gnorm 2.389 | clip 100 | train_wall 1 | wall 4\n",
            "epoch 004:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:47 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2025-05-14 12:00:48 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2025-05-14 12:00:48 | INFO | train | epoch 004 | loss 5.227 | nll_loss 5.083 | ppl 33.89 | wps 19528.6 | ups 12.44 | wpb 1570.4 | bsz 240 | num_updates 60 | lr 6.0094e-05 | gnorm 1.275 | clip 66.7 | train_wall 1 | wall 5\n",
            "epoch 005:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:48 | INFO | fairseq.trainer | begin training epoch 5\n",
            "epoch 005:  87% 13/15 [00:01<00:00, 12.71it/s]2025-05-14 12:00:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 12:00:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-l/checkpoint5.pt (epoch 5 @ 75 updates, score None) (writing took 0.353271937000045 seconds)\n",
            "2025-05-14 12:00:50 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2025-05-14 12:00:50 | INFO | train | epoch 005 | loss 4.936 | nll_loss 4.757 | ppl 27.04 | wps 14071.5 | ups 8.96 | wpb 1570.4 | bsz 240 | num_updates 75 | lr 7.50925e-05 | gnorm 1.131 | clip 46.7 | train_wall 1 | wall 7\n",
            "epoch 006:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:50 | INFO | fairseq.trainer | begin training epoch 6\n",
            "2025-05-14 12:00:52 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2025-05-14 12:00:52 | INFO | train | epoch 006 | loss 4.819 | nll_loss 4.624 | ppl 24.65 | wps 14529.4 | ups 9.25 | wpb 1570.4 | bsz 240 | num_updates 90 | lr 9.0091e-05 | gnorm 1.555 | clip 73.3 | train_wall 1 | wall 8\n",
            "epoch 007:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:52 | INFO | fairseq.trainer | begin training epoch 7\n",
            "2025-05-14 12:00:53 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2025-05-14 12:00:53 | INFO | train | epoch 007 | loss 4.7 | nll_loss 4.488 | ppl 22.45 | wps 18473.1 | ups 11.76 | wpb 1570.4 | bsz 240 | num_updates 105 | lr 0.000105089 | gnorm 1.38 | clip 53.3 | train_wall 1 | wall 10\n",
            "epoch 008:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:53 | INFO | fairseq.trainer | begin training epoch 8\n",
            "2025-05-14 12:00:54 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2025-05-14 12:00:54 | INFO | train | epoch 008 | loss 4.615 | nll_loss 4.378 | ppl 20.79 | wps 20545.8 | ups 13.08 | wpb 1570.4 | bsz 240 | num_updates 120 | lr 0.000120088 | gnorm 2.031 | clip 86.7 | train_wall 1 | wall 11\n",
            "epoch 009:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:54 | INFO | fairseq.trainer | begin training epoch 9\n",
            "2025-05-14 12:00:55 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2025-05-14 12:00:55 | INFO | train | epoch 009 | loss 4.361 | nll_loss 4.078 | ppl 16.88 | wps 20537.8 | ups 13.08 | wpb 1570.4 | bsz 240 | num_updates 135 | lr 0.000135087 | gnorm 1.718 | clip 66.7 | train_wall 1 | wall 12\n",
            "epoch 010:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:55 | INFO | fairseq.trainer | begin training epoch 10\n",
            "epoch 010:  87% 13/15 [00:01<00:00, 15.42it/s]2025-05-14 12:00:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2025-05-14 12:00:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fre-256-.1-s-l/checkpoint10.pt (epoch 10 @ 150 updates, score None) (writing took 0.24734224999974685 seconds)\n",
            "2025-05-14 12:00:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2025-05-14 12:00:57 | INFO | train | epoch 010 | loss 4.192 | nll_loss 3.839 | ppl 14.31 | wps 16807.2 | ups 10.7 | wpb 1570.4 | bsz 240 | num_updates 150 | lr 0.000150085 | gnorm 2.617 | clip 73.3 | train_wall 1 | wall 13\n",
            "epoch 011:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:57 | INFO | fairseq.trainer | begin training epoch 11\n",
            "2025-05-14 12:00:58 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
            "2025-05-14 12:00:58 | INFO | train | epoch 011 | loss 3.822 | nll_loss 3.43 | ppl 10.77 | wps 17967.9 | ups 11.44 | wpb 1570.4 | bsz 240 | num_updates 165 | lr 0.000165083 | gnorm 2.845 | clip 100 | train_wall 1 | wall 15\n",
            "epoch 012:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:58 | INFO | fairseq.trainer | begin training epoch 12\n",
            "2025-05-14 12:00:59 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
            "2025-05-14 12:00:59 | INFO | train | epoch 012 | loss 3.286 | nll_loss 2.796 | ppl 6.95 | wps 20912.5 | ups 13.32 | wpb 1570.4 | bsz 240 | num_updates 180 | lr 0.000180082 | gnorm 2.02 | clip 93.3 | train_wall 1 | wall 16\n",
            "epoch 013:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:00:59 | INFO | fairseq.trainer | begin training epoch 13\n",
            "2025-05-14 12:01:00 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
            "2025-05-14 12:01:00 | INFO | train | epoch 013 | loss 2.793 | nll_loss 2.199 | ppl 4.59 | wps 19827.5 | ups 12.63 | wpb 1570.4 | bsz 240 | num_updates 195 | lr 0.00019508 | gnorm 1.57 | clip 86.7 | train_wall 1 | wall 17\n",
            "epoch 014:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:01:00 | INFO | fairseq.trainer | begin training epoch 14\n",
            "2025-05-14 12:01:01 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
            "2025-05-14 12:01:01 | INFO | train | epoch 014 | loss 2.475 | nll_loss 1.801 | ppl 3.48 | wps 20031.1 | ups 12.76 | wpb 1570.4 | bsz 240 | num_updates 210 | lr 0.000210079 | gnorm 1.483 | clip 86.7 | train_wall 1 | wall 18\n",
            "epoch 015:   0% 0/15 [00:00<?, ?it/s]2025-05-14 12:01:01 | INFO | fairseq.trainer | begin training epoch 15\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/task1/bin/fairseq-train\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/fairseq_cli/train.py\", line 352, in cli_main\n",
            "    distributed_utils.call_main(args, main)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/fairseq/distributed_utils.py\", line 301, in call_main\n",
            "    main(args, **kwargs)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/fairseq_cli/train.py\", line 125, in main\n",
            "    valid_losses, should_stop = train(args, trainer, task, epoch_itr)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/contextlib.py\", line 75, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/fairseq_cli/train.py\", line 208, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/contextlib.py\", line 75, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/fairseq/trainer.py\", line 480, in train_step\n",
            "    loss, sample_size_i, logging_output = self.task.train_step(\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/fairseq/tasks/fairseq_task.py\", line 420, in train_step\n",
            "    optimizer.backward(loss)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/fairseq/optim/fairseq_optimizer.py\", line 95, in backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/torch/tensor.py\", line 185, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/envs/task1/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 125, in backward\n",
            "    Variable._execution_engine.run_backward(\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'eval \"$(conda shell.bash hook)\"\nconda activate task1\n\ncd 2020/task1/baselines/transformer/\n\n# Only train and evaluate French\nsed -i.bak '136 s/$(ls data-bin)/fre/' sweep\n\n./sweep --cuda\n' died with <Signals.SIGINT: 2>.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-642101b43c72>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval \"$(conda shell.bash hook)\"\\nconda activate task1\\n\\ncd 2020/task1/baselines/transformer/\\n\\n# Only train and evaluate French\\nsed -i.bak \\'136 s/$(ls data-bin)/fre/\\' sweep\\n\\n./sweep --cuda\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'eval \"$(conda shell.bash hook)\"\nconda activate task1\n\ncd 2020/task1/baselines/transformer/\n\n# Only train and evaluate French\nsed -i.bak '136 s/$(ls data-bin)/fre/' sweep\n\n./sweep --cuda\n' died with <Signals.SIGINT: 2>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat 2020/task1/baselines/transformer/checkpoints/fre-256-.1-s-s/checkpoint330-test.res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhUUaPp9sa74",
        "outputId": "b59fcda0-bd1f-446f-9e0d-b168f40cc922"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER:\t7.11\n",
            "LER:\t1.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline results for French with transformer architecture are given:\n",
        "\n",
        "||WER|LER|\n",
        "|-|||\n",
        "|fre|6.89|1.72|\n"
      ],
      "metadata": {
        "id": "X9nmW2CttAf2"
      }
    }
  ]
}